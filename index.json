[{"categories":["Kubernetes"],"content":"整体流程 部署准备 k8s 集群容器运行时 Containerd 准备 k8s 集群部署 k8s 集群软件 apt 源准备 k8s 集群软件安装 k8s 集群初始化 k8s 集群worker 节点加入 k8s 集群网络插件 Calico 准备 部署应用验证集群可用性 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:1:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"集群环境信息 操作系统Ubuntu22.04 部署 k8s 版本为v1.28 容器运行时为 Containerd 1.7.11 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:2:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"1. 主机准备 虚拟机是通过vmvare 创建的，搭建的k8s 集群是非高可用模式，下方提供部署脚本。 部署过程中由于2024年6月份 docker 镜像仓库不再对大陆提供服务，需要进行离线部署，主要是 calico 这一块会有镜像源缺失,对应章节会有补充说明及解决方案 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:3:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"1.1 操作系统 操作系统 版本 说明 ubuntu ubuntu-22.04.4-live-server-amd64 最小化 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:3:1","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"1.2 主机硬件配置说明 ip CPU 内存 硬盘 角色 主机名 192.168.1.11 2C 4G 30G master k8s-nastert01 192.168.1.7 2C 4G 30G node k8s-node01 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:3:2","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"1.3 主机配置 所有节点执行 1.3.1 主机名配置 #master 节点 hostnamectl set-hostname k8s-nastert01 #ndoe 节点 hostnamectl set-hostname k8s-node01 1.3.2 主机ip 地址配置 vmvare 创建虚拟机网络适配器选择桥接模式(自动)，需要手动配置ip地址，否则当虚拟机重启后ip 地址会发生变化 k8s-master01 节点 sudo cp /etc/netplan/00-installer-config.yaml /etc/netplan/00-installer-config.yaml_before cat \u003c\u003c EOF \u003e /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens33: addresses: - 192.168.1.11/16 nameservers: addresses: - 114.114.114.114 # 国内移动联通 - 8.8.8.8 # 谷歌 search: [] routes: - to: default via: 192.168.1.1 # 电脑本地网关地址 version: 2 EOF # 使配置生效 sudo netplan apply k8s-node01 节点 sudo cp /etc/netplan/00-installer-config.yaml /etc/netplan/00-installer-config.yaml_before cat \u003c\u003c EOF \u003e /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens33: addresses: - 192.168.1.7/16 nameservers: addresses: - 114.114.114.114 # 国内移动联通 - 8.8.8.8 # 谷歌 search: [] routes: - to: default via: 192.168.1.1 version: 2 EOF # 使配置生效 sudo netplan apply 1.3.3 主机名和ip 地址解析 cat \u003e\u003e /etc/hosts \u003c\u003c EOF \u003e 192.168.1.11 k8s-master01 \u003e 192.168.1.7 k8s-node01 \u003e EOF 1.3.4 chrony时间同步配置 k8s-master01 节点执行 $ cp /etc/chrony/chrony.conf /etc/chrony/chrony.conf_bak $ cat \u003e /etc/chrony/chrony.conf \u003c\u003c EOF confdir /etc/chrony/conf.d server ntp.aliyun.com iburst allow 192.168.1.1/24 sourcedir /run/chrony-dhcp sourcedir /etc/chrony/sources.d keyfile /etc/chrony/chrony.keys driftfile /var/lib/chrony/chrony.drift ntsdumpdir /var/lib/chrony logdir /var/log/chrony maxupdateskew 100.0 rtcsync makestep 1 3 leapsectz right/UTC EOF $ date Thu Jun 20 10:10:56 AM CST 2024 # 设置时区 $ timedatectl set-timezone Asia/Shanghai # 部署时间同步服务器，并设置开机自启 $ apt install ntpdate chrony -y $ ntpdate time2.aliyun.com $ systemctl start chrony $ systemctl status chrony $ systemctl enable chrony # 查看 chronyd 时间同步服务的源的统计信息 $ chronyc sourcestats -v k8s-node01 节点执行,修改 server 为 master 节点ip $ cp /etc/chrony/chrony.conf /etc/chrony/chrony.conf_bak $ cat \u003e /etc/chrony/chrony.conf \u003c\u003c EOF confdir /etc/chrony/conf.d server 192.168.1.11 iburst sourcedir /run/chrony-dhcp sourcedir /etc/chrony/sources.d keyfile /etc/chrony/chrony.keys driftfile /var/lib/chrony/chrony.drift ntsdumpdir /var/lib/chrony logdir /var/log/chrony maxupdateskew 100.0 rtcsync makestep 1 3 leapsectz right/UTC EOF $ date Thu Jun 20 10:15:56 AM CST 2024 # 设置时区 $ timedatectl set-timezone Asia/Shanghai # 部署时间同步服务器，并设置开机自启 $ apt install ntpdate chrony -y $ ntpdate time2.aliyun.com $ systemctl start chrony $ systemctl status chrony $ systemctl enable chrony # 查看 chronyd 时间同步服务的源的统计信息 $ chronyc sourcestats -v 1.3.5 配置内核转发及网桥过滤 # 转发IPv4并让iptables看到桥接流量 $ sudo cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # 手动加载 $ modprobe overlay $ modprobe br_netfilter # 检测是否加载 $ lsmod | egrep \"overlay\" $ lsmod | egrep \"br_netfilter\" # 添加网桥过滤及内核转发配置,设置所需的sysctl参数，参数在重新启动后保持不变 $ sudo cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF #检查sysctl是否成功应用： $ sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward # 手动加载 #sudo sysctl -p /etc/sysctl.d/k8s.conf # or $ sudo sysctl --system 1.3.6 安装ipset和ipvsadm $ apt install ipset ipvsadm -y # 配置ipvsadm 内核模块加载 $ cat \u003c\u003c EOF \u003e /etc/modules-load.d/ipvs.conf ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh nf_conntrack EOF # 手动加载模块 $ modprobe -- ip_vs $ modprobe -- ip_vs_rr $ modprobe -- ip_vs_wrr $ modprobe -- ip_vs_sh $ modprobe -- nf_conntrack 1.3.7 关闭SWAP分区 # 临时关闭 $ swapoff -a # 永久关闭 $ sed -i '/swap/ s/^\\(.*\\)$/#\\1/g' /etc/fstab 1.3.8 所有设备允许 root 用户 $ cat \u003e\u003e /etc/ssh/sshd_config \u003c\u003c EOF PermitRootLogin yes PasswordAuthentication yes EOF 1.3.9 关闭防火墙 #查看防火墙状态 $ sudo systemctl status ufw #关闭防火墙 $ sudo systemctl stop ufw #禁止防火墙开机启动 $ sudo systemctl disable ufw ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:3:3","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"2. 部署Conatinerd 服务 所有主机都要执行 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:4:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"2.1 下载及安装 # 部署 containerd $ wget https://github.com/containerd/containerd/releases/download/v1.7.11/cri-containerd-static-1.7.11-linux-amd64.tar.gz #tar Czxvf /usr/local/ cri-containerd-static-1.7.11-linux-amd64.tar.gz $ sudo tar -zxvf cri-containerd-cni-1.7.11-linux-amd64.tar.gz -C / 警告\r这里选择的适配k8s 容器运行时的containerd,有一个前缀cri(container runtime interface)，另外根据自己的操作系统选择对应的架构，常用的是amd64\r","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:4:1","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"2.2 配置Containerd服务 $ mkdir -p /etc/containerd $ containerd config default \u003e /etc/containerd/config.toml # 修改为国内代理镜像仓库 $ sed -i 's/registry.k8s.io\\/pause:3.8/registry.cn-hangzhou.aliyuncs.com\\/google_containers\\/pause:3.9/g' /etc/containerd/config.toml # 驱动使用为SystemdCgroup $ sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml $ sed -i 's/disabled_plugins/#disabled_plugins/g' /etc/containerd/config.toml ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:4:2","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"2.3 设置containerd开机自启动 $ systemctl enable --now containerd #验证版本 $ containerd --version ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:4:3","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"3. k8s集群部署 所有节点都执行 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:5:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"3.1 k8s配置集群软件apt源及安装 #下载用于 Kubernetes 软件包仓库的公共签名密钥。所有仓库都使用相同的签名密钥，因此你可以忽略URL中的版本 curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg # 添加 Kubernetes apt 仓库。 请注意，此仓库仅包含适用于 Kubernetes 1.28 的软件包 echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list # 更新 apt 包索引并安装使用 Kubernetes apt 仓库所需要的包 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl gpg # k8s 集群软件安装 # 3.2.1 更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本(防止自动更新)： $ sudo apt-get update $ apt-get install -y kubelet kubeadm kubectl # 并锁定其版本(防止自动更新) $ apt-cache madison kubeadm $ sudo apt-mark hold kubelet kubeadm kubectl ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:5:1","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"3.2 查看apt 仓库是否缓存k8s 安装组件 apt-cache policy kubeadm|head - 10 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:5:2","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"3.3 部署k8s 集群 master 节点 修改kubeadm 初始化配置文件 #默认初始化配置文件生成 $ kubeadm config print init-defaults \u003e kube-config.yaml # 修改配置文件 $ sed -i \"s/advertiseAddress: 1.2.3.4/advertiseAddress: 192.168.1.11/g\" kube-config.yaml $ sed -i \"s/name: node/name: k8s-master01/g\" kube-config.yaml $ sed -i \"s/imageRepository: k8s.gcr.io/imageRepository: $ registry.cn-hangzhou.aliyuncs.com\\/google_containers/g\" kube-config.yaml $ sed -i \"s/imageRepository: registry.k8s.io/imageRepository: $ registry.cn-hangzhou.aliyuncs.com\\/google_containers/g\" kube-config.yaml # 追加制定pod ip网段 $ sed -i '/serviceSubnet/a\\ podSubnet: 10.244.0.0/16' kube-config.yaml 添加ipvs 和 kubelet 配置,kube-config.yaml为生成的配置文件 $ cat \u003c\u003c EOF \u003e\u003e kube-config.yaml --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: ipvs --- kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 cgroupDriver: systemd EOF 提前下载需要的镜像信息 # 查看kubeadm 所需要的镜像列表 $ kubeadm config images list # 提前下载镜像,使用中国区镜像加速 $ kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers # 查看下载的镜像，镜像保存在k8s.io namesapce 下 $ ctr -n=k8s.io i ls 开始部署，并将log 打印到本地文件中 # 使用部署配置文件初始化k8s 集群 $ kubeadm init --config kube-config.yaml|tee -a kubeadm_init.log #输出内容如下： Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.1.11:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:fb0b8abf6780b7dff4f155edd2ed74a80a085081e25bb5469b906410a7a80398 执行成功后 根据提示还需要再执行以下命令 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config export KUBECONFIG=/etc/kubernetes/admin.conf 技巧\r执行失败查看报错后调整，使用kubeadm reset还原后重新执行\rmaster 节点验证 $ kubectl get node -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8s-master01 Ready control-plane 7d12h v1.28.11 192.168.1.11 \u003cnone\u003e Ubuntu 22.04.4 LTS 5.15.0-94-generic containerd://1.7.11 kube-config.yaml 完成配置文件 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.1.11 # 修改内容 bindPort: 6443 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock # 修改内容 imagePullPolicy: IfNotPresent name: k8s-master01 # 修改内容 taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers # 修改内容 kind: ClusterConfiguration kubernetesVersion: 1.28.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.244.0.0/16 # 添加内容 scheduler: {} # 添加内容 --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: ipvs --- kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 cgroupDriver: systemd node 节点 join 这里手动指定cri-socket kubeadm join 192.168.1.11:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash \\ --cri-socket=unix:///run/containerd/containerd.sock ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:5:3","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"4. k8s集群部署网络插件 calico 常见的网络插件有多种，比如flannel、Calico和Cilium，本次实验使用Calico使用。 首先访问Calico帮助文档https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:6:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"master 节点 calico 部署使用的是operator 的方式，且不再和kube-system 共用一个namespace，另起了一个namesapce calico-system,引入了istio 相关组件服务，详情可以看下calico官网 配置插件需要的环境 wget https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/tigera-operator.yaml kubectl create -f tigera-operator.yaml 下载客户端资源文件并修改pod 网段地址，因为我们的pod的网段和配置文件不一样 # 下载客户端资源文件 curl -LO https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/custom-resources.yaml # 修改pod的网段地址 podSubnet sed -i 's/cidr: 192.168.0.0/cidr: 10.244.0.0/g' custom-resources.yaml kubectl create -f custom-resources.yaml 查看集群 calico pod 创建过程，大约会耗时三分钟,部署成功后，所有node 节点为Ready 状态 watch kubectl get all -o wide -n calico-system 技巧\r以上方法是在dockerhub 网络仓库正常访问情况下执行的，如果dockerhub 网络仓库访问异常可以使用离线部署的方式 2024.6 月份docker hub 被墙了后，就不能方便的下载 docker 镜像了，这里使用离线的方式进行部署。 calico v3.27 相关镜像列表 docker.io/calico/cni:v3.27.2 docker.io/calico/kube-controllers:v3.27.2 docker.io/calico/node:v3.27.2 docker.io/calico/pod2daemon-flexvol:v3.27.2 docker.io/calico/typha:v3.27.2 # 下面三个镜像 release-v3.27.2 没有包含进来 docker.io/calico/csi:v3.27.2 docker.io/calico/apiserver:v3.27 docker.io/calico/node-driver-registrar:v3.27.2 手动镜像导入 sudo ctr -n k8s.io images ls|grep calico sudo ctr -n k8s.io images import calico-cni.tar sudo ctr -n k8s.io images import calico-dikastes.tar sudo ctr -n k8s.io images import calico-flannel-migration-controller.tar sudo ctr -n k8s.io images import calico-kube-controllers.tar sudo ctr -n k8s.io images import calico-node.tar sudo ctr -n k8s.io images import calico-pod2daemon.tar sudo ctr -n k8s.io images import calico-typha.tar # # 下面三个镜像 release-v3.27.2 没有包含进来,需要手动导入 sudo ctr -n k8s.io images import csi.tar sudo ctr -n k8s.io images import apiserver.tar sudo ctr -n k8s.io images import node-driver-registrar.tar 参考：calico_3.27 quick install 官网 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:6:1","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"5. 部署nginx 验证k8s 集群可用性 nginx-deploy yaml 文件 cat \u003c\u003c EOF \u003e nginx-deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-deploy name: nginx-deploy spec: replicas: 1 selector: matchLabels: app: nginx-deploy template: metadata: labels: app: nginx-deploy spec: containers: - image: registry.cn-shenzhen.aliyuncs.com/xiaohh-docker/nginx:1.25.4 name: nginx ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: labels: app: nginx-deploy name: nginx-svc spec: ports: - port: 80 protocol: TCP targetPort: 80 nodePort: 30080 selector: app: nginx-deploy type: NodePort EOF 生效 kubectl apply -f nginx-deploy.yaml # 然后访问你任何一个节点的IP地址加上nodeport 30080就可以访问这个部署的nginx kubectl get service -o wide 浏览器访问http://192.168.1.11:30080 提示 Welcome to nginx! 表示生效成功 ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:7:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"6. 部署crictl(optional) crictl 是Kubelet容器接口（CRI）的CLI和验证工具: 这里部署以下 containerd客户端crictl $ VERSION=\"v1.28.0\" $ wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz $ sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin $ rm -f crictl-$VERSION-linux-amd64.tar.gz $ cat \u003e /etc/crictl.yaml \u003c\u003cEOF runtime-endpoint: unix:///var/run/containerd/containerd.sock image-endpoint: unix:///var/run/containerd/containerd.sock timeout: 10 debug: true EOF # 测试 $ crictl pods $ crictl images 内容 docker.io/calico/apiserver v3.27.2 5d4a0194d5324 94MB docker.io/calico/cni v3.27.2 bbf4b051c5078 195MB docker.io/calico/csi v3.27.2 b2c0fe47b0708 17.4MB docker.io/calico/dikastes v3.27.2 236c3ef9745d9 40.5MB docker.io/calico/flannel-migration-controller v3.27.2 99b8d3ea2440b 125MB docker.io/calico/kube-controllers v3.27.2 849ce09815546 75.6MB docker.io/calico/node-driver-registrar v3.27.2 73ddb59b21918 22.6MB docker.io/calico/node v3.27.2 50df0b2eb8ffe 346MB docker.io/calico/pod2daemon-flexvol v3.27.2 ea79f2d96a361 15.4MB docker.io/calico/typha v3.27.2 2ec97bc370c17 68.4MB .... ","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:8:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"完整部署脚本 以作参考,环境不同，相应参数需要手动调整 #！/bin/bash # 本机名称 HOST_NAME=k8s-master01 # ipv4 地址 HOST_IP=192.168.1.11 HOST_NODE_IP=192.168.1.7 # 设置静态主机ip,手动处理 https://cloud.tencent.com/developer/article/1933335 function ch0_set_static_ip() { echo \"main ch0_set_static_ip start\" sudo apt install net-tools -y ifconfig route -n sudo cp /etc/netplan/00-installer-config.yaml /etc/netplan/00-installer-config.yaml_before cat \u003c\u003c EOF \u003e /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' network: ethernets: ens33: addresses: - 192.168.1.11/16 nameservers: addresses: - 114.114.114.114 - 8.8.8.8 search: [] routes: - to: default via: 192.168.1.1 version: 2 EOF # 使配置生效 sudo netplan apply echo \"main ch0_set_static_ip start\" } # 1、k8s 集群主机准备 function ch1_config_hosts(){ echo \"main ch1_config_hosts start\" # 部署文件目录 mkdir ${HOME}/kubernetes_install cd ${HOME}/kubernetes_install # 1.1 设置主机名称 hostnamectl set-hostname ${HOST_NAME} # 1.2 所有设备允许 root 用户 cat \u003e\u003e /etc/ssh/sshd_config \u003c\u003c EOF PermitRootLogin yes PasswordAuthentication yes EOF # 1.3 关闭swap 分区 swapoff -a sed -i '/swap/ s/^\\(.*\\)$/#\\1/g' /etc/fstab # 1.4 主机名和ip 地址解析配置 sed -i \"2a ${HOST_IP} ${HOST_NAME}\" /etc/hosts sed -i \"3a ${HOST_NODE_IP} k8s-node01\" /etc/hosts # 1.5 时间同步配置,时区 cp /etc/chrony/chrony.conf /etc/chrony/chrony.conf_bak cat \u003e /etc/chrony/chrony.conf \u003c\u003c EOF confdir /etc/chrony/conf.d server ntp.aliyun.com iburst allow 192.168.1.1/24 sourcedir /run/chrony-dhcp sourcedir /etc/chrony/sources.d keyfile /etc/chrony/chrony.keys driftfile /var/lib/chrony/chrony.drift ntsdumpdir /var/lib/chrony logdir /var/log/chrony maxupdateskew 100.0 rtcsync makestep 1 3 leapsectz right/UTC EOF timedatectl set-timezone Asia/Shanghai apt install ntpdate chrony -y ntpdate time2.aliyun.com systemctl start chrony systemctl status chrony systemctl enable chrony # 查看 chronyd 时间同步服务的源的统计信息 chronyc sourcestats -v # 1.6 配置内核转发及网桥过滤 # 转发IPv4并让iptables看到桥接流量 sudo cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # 手动加载 modprobe overlay modprobe br_netfilter # 检测是否加载 lsmod | egrep \"overlay\" lsmod | egrep \"br_netfilter\" # 添加网桥过滤及内核转发配置,设置所需的sysctl参数，参数在重新启动后保持不变 sudo cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF #检查sysctl是否成功应用： sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward # 手动加载 #sudo sysctl -p /etc/sysctl.d/k8s.conf # or sudo sysctl --system # 1.7 安装ipset 及ipvsadm apt install ipset ipvsadm -y # 配置ipvsadm 内核模块加载 cat \u003c\u003c EOF \u003e /etc/modules-load.d/ipvs.conf ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh nf_conntrack EOF # 手动加载模块 modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack # 1.8 关闭防火墙 #查看防火墙状态 sudo systemctl status ufw #关闭防火墙 sudo systemctl stop ufw #禁止防火墙开机启动 sudo systemctl disable ufw echo \"main ch1_config_hosts end\" } # 2、k8s 集群 containerd 准备 function ch2_containerd_init(){ echo \"main ch2_containerd_init start\" # 部署 containerd wget https://github.com/containerd/containerd/releases/download/v1.7.11/cri-containerd-static-1.7.11-linux-amd64.tar.gz #tar Czxvf /usr/local/ cri-containerd-static-1.7.11-linux-amd64.tar.gz sudo tar -zxvf cri-containerd-cni-1.7.11-linux-amd64.tar.gz -C / mkdir -p /etc/containerd containerd config default \u003e /etc/containerd/config.toml sed -i 's/registry.k8s.io\\/pause:3.8/registry.cn-hangzhou.aliyuncs.com\\/google_containers\\/pause:3.9/g' /etc/containerd/config.toml sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml sed -i 's/disabled_plugins/#disabled_plugins/g' /etc/containerd/config.toml # 使用systemd托管containerd # 生成system service文件 cat\u003c\u003cEOF|tee /etc/systemd/system/containerd.service [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target local-fs.target [Service] ExecStartPre=-/sbin/modprobe overlay ExecStart=/usr/local/bin/containerd Type=notify Delegate=yes Ki","date":"2024-06-20","objectID":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/:9:0","tags":["Kubernetes"],"title":"Ubuntu-server部署k8s1.28(containerd版本)集群","uri":"/ubuntu-server%E9%83%A8%E7%BD%B2k8s1.28containerd%E7%89%88%E6%9C%AC%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"问题描述 问题\r在高可用的k8s集群中，当Node节点挂掉，kubelet无法提供工作的时候，pod将会自动调度到其他的节点上去， 而调度到节点上的时间需要我们慎重考量，因为它决定了生产的稳定性、可靠性，更快的迁移可以减少我们业务的影响性， 但是有可能会对集群造成一定的压力，从而造成集群崩溃。\r","date":"2023-09-09","objectID":"/%E8%B0%83%E6%95%B4%E8%8A%82%E7%82%B9pod%E9%A9%B1%E9%80%90%E6%97%B6%E9%97%B4/:1:0","tags":["Kubernetes"],"title":"调整节点pod驱逐时间","uri":"/%E8%B0%83%E6%95%B4%E8%8A%82%E7%82%B9pod%E9%A9%B1%E9%80%90%E6%97%B6%E9%97%B4/"},{"categories":["Kubernetes"],"content":"Kubelet 状态更新的基本流程 kubelet 自身会定期更新状态到 apiserver，通过参数–node-status-update-frequency指定上报频率，默认是 10s 上报一次。 kube-controller-manager 会每隔–node-monitor-period时间去检查 kubelet 的状态，默认是 5s。 当 node 失联一段时间后，kubernetes 判定 node 为 notready 状态，这段时长通过–node-monitor-grace-period参数配置，默认 40s。 当 node 失联一段时间后，kubernetes 判定 node 为 unhealthy 状态，这段时长通过–node-startup-grace-period参数配置，默认 1m0s。 当 node 失联一段时间后，kubernetes 开始删除原 node 上的 pod，这段时长是通过–pod-eviction-timeout参数配置，默认 5m0s。 kube-controller-manager 和 kubelet 是异步工作的，这意味着延迟可能包括任何的网络延迟、apiserver 的延迟、etcd 延迟，一个节点上的负载引起的延迟等等。因此，如果–node-status-update-frequency设置为5s，那么实际上 etcd 中的数据变化会需要 6-7s，甚至更长时间。 如果业务生产认为默认的驱逐时间不能满足业务的及时性，可以手动修改驱逐时间。 在master节点操作： 修改/etc/systemd/system/kube-controller-manager.service文件 增加一行–pod-eviction-timeout=1m （这里是调整为1分钟，具体数值可以根据业务重要实际情况修改） ","date":"2023-09-09","objectID":"/%E8%B0%83%E6%95%B4%E8%8A%82%E7%82%B9pod%E9%A9%B1%E9%80%90%E6%97%B6%E9%97%B4/:2:0","tags":["Kubernetes"],"title":"调整节点pod驱逐时间","uri":"/%E8%B0%83%E6%95%B4%E8%8A%82%E7%82%B9pod%E9%A9%B1%E9%80%90%E6%97%B6%E9%97%B4/"},{"categories":["docker"],"content":"CGroups与Namespaces 摘要\r了解下容器背后的两大核心技术：CGroups 和 Namespace。\r","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:0:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"CGroups 概述 CGroups 全称为 Linux Control Group，其作用是限制一组进程使用的资源（CPU、内存等）上限，CGroups 也是 Containerd 容器技术的核心实现原理之一，首先我们需要先了解几个 CGroups 的基本概念： Task: 在 cgroup 中，task 可以理解为一个进程，但这里的进程和一般意义上的操作系统进程不太一样，实际上是进程 ID 和线程 ID 列表。 CGroup: 即控制组，一个控制组就是一组按照某种标准划分的 Tasks，可以理解为资源限制是以进程组为单位实现的，一个进程加入到某个控制组后，就会受到相应配置的资源限制。 Hierarchy: cgroup 的层级组织关系，cgroup 以树形层级组织，每个 cgroup 子节点默认继承其父 cgroup 节点的配置属性，这样每个 Hierarchy 在初始化会有 root cgroup。 Subsystem: 即子系统，子系统表示具体的资源配置，如 CPU 使用，内存占用等，Subsystem 附加到 Hierarchy 上后可用 CGroups 支持的子系统包含以下几类，即为每种可以控制的资源定义了一个子系统: cpuset: 为 cgroup 中的进程分配单独的 CPU 节点，即可以绑定到特定的 CPU cpu: 限制 cgroup 中进程的 CPU 使用份额 cpuacct: 统计 cgroup 中进程的 CPU 使用情况 memory: 限制 cgroup 中进程的内存使用,并能报告内存使用情况 devices: 控制 cgroup 中进程能访问哪些文件设备(设备文件的创建、读写) freezer: 挂起或恢复 cgroup 中的 task net_cls: 可以标记 cgroups 中进程的网络数据包，然后可以使用 tc 模块(traffic contro)对数据包进行控制 blkio: 限制 cgroup 中进程的块设备 IO perf_event: 监控 cgroup 中进程的 perf 时间，可用于性能调优 hugetlb: hugetlb 的资源控制功能 pids: 限制 cgroup 中可以创建的进程数 net_prio: 允许管理员动态的通过各种应用程序设置网络传输的优先级 通过上面的各个子系统，可以看出使用 CGroups 可以控制的资源有: CPU、内存、网络、IO、文件设备等。CGroups 具有以下几个特点： CGroups 的 API 以一个伪文件系统（/sys/fs/cgroup/）的实现方式，用户的程序可以通过文件系统实现 CGroups 的组件管理 CGroups 的组件管理操作单元可以细粒度到线程级别，用户可以创建和销毁 CGroups，从而实现资源载分配和再利用 所有资源管理的功能都以子系统（cpu、cpuset 这些）的方式实现，接口统一子任务创建之初与其父任务处于同一个 CGroups 的控制组 我们可以通过查看 /proc/cgroups 文件来查找当前系统支持的 CGroups 子系统: $ cat /proc/cgroups #subsys_name hierarchy num_cgroups enabled cpuset 5 153 1 cpu 8 478 1 cpuacct 8 478 1 memory 3 478 1 devices 9 478 1 freezer 4 153 1 net_cls 6 153 1 blkio 10 478 1 perf_event 2 153 1 hugetlb 7 153 1 pids 11 478 1 net_prio 6 153 在使用 CGroups 时需要先挂载，我们可以使用 df -h | grep cgroup 命令进行查看: $ df -h | grep cgroup tmpfs 7.8G 0 7.8G 0% /sys/fs/cgroup 可以看到被挂载到了 /sys/fs/cgroup，cgroup 其实是一种文件系统类型，所有的操作都是通过文件来完成的，我们可以使用 mount –type cgroup命令查看当前系统挂载了哪些 cgroup： $ mount --type cgroup cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd) cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event) cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory) cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer) cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls) cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb) cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu) cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices) cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio) cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids) /sys/fs/cgroup 目录下的每个子目录就对应着一个子系统，cgroup 是以目录形式组织的，/ 是 cgroup 的根目录，但是这个根目录可以被挂载到任意目录，例如 CGroups 的 memory 子系统的挂载点是 /sys/fs/cgroup/memory，那么 /sys/fs/cgroup/memory/ 对应 memory 子系统的根目录，我们可以列出该目录下面的文件： $ ll /sys/fs/cgroup/memory/ total 0 -rw-r--r-- 1 root root 0 Aug 8 2022 cgroup.clone_children --w--w--w- 1 root root 0 Aug 8 2022 cgroup.event_control -rw-r--r-- 1 root root 0 Aug 8 2022 cgroup.procs -r--r--r-- 1 root root 0 Aug 8 2022 cgroup.sane_behavior drwxr-xr-x 5 root root 0 Aug 28 14:38 docker drwxr-xr-x 5 root root 0 Sep 6 14:01 kubepods -rw-r--r-- 1 root root 0 Aug 8 2022 memory.failcnt --w------- 1 root root 0 Aug 8 2022 memory.force_empty -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.failcnt -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 Aug 8 2022 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 Aug 8 2022 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 Aug 8 2022 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 ","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:1:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"CGroup 测试 接下来我们来尝试手动设置下 cgroup，以 CPU 这个子系统为例进行说明，首先我们在 /sys/fs/cgroup/cpu 目录下面创建一个名为 ydzs.test 的目录： $ mkdir -p /sys/fs/cgroup/cpu/ydzs.test $ ls /sys/fs/cgroup/cpu/ydzs.test/ cgroup.clone_children cpuacct.stat cpu.cfs_period_us cpu.rt_runtime_us notify_on_release cgroup.event_control cpuacct.usage cpu.cfs_quota_us cpu.shares tasks cgroup.procs cpuacct.usage_percpu cpu.rt_period_us cpu.stat 我们可以看到目录创建完成后，下面就会已经自动创建 cgroup 的相关文件，这里我们重点关注 cpu.cfs_period_us 和 cpu.cfs_quota_us 这两个文件，前面一个是用来配置 CPU 时间周期长度的，默认为 100000us，后者用来设置在此时间周期长度内所能使用的 CPU 时间数，默认值为-1，表示不受时间限制。 $ cat /sys/fs/cgroup/cpu/ydzs.test/cpu.cfs_period_us 100000 $ cat /sys/fs/cgroup/cpu/ydzs.test/cpu.cfs_quota_us -1 现在我们写一个简单的 Python 脚本来消耗 CPU： # cgroup.py while True: pass 直接执行这个死循环脚本即可： $ python cgroup.py \u0026 [1] 2113 使用 top 命令可以看到进程号 2113 的 CPU 使用率达到了 100% 现在我们将这个进程 ID 写入到 /sys/fs/cgroup/cpu/ydzs.test/tasks 文件下面去，然后设置 /sys/fs/cgroup/cpu/ydzs.test/cpu.cfs_quota_us 为 10000us，因为 cpu.cfs_period_us 默认值为 100000us，所以这表示我们要限制 CPU 使用率为 10%： $ echo 2113 \u003e /sys/fs/cgroup/cpu/ydzs.test/tasks $ echo 10000 \u003e /sys/fs/cgroup/cpu/ydzs.test/cpu.cfs_quota_us 设置完过后上面我们的测试进程 CPU 就会被限制在 10% 左右了，再次使用 top 命令查看该进程可以验证。 如果要限制内存等其他资源的话，同样去对应的子系统下面设置资源，并将进程 ID 加入 tasks 中即可。如果要删除这个 cgroup，直接删除文件夹是不行的，需要使用 libcgroup 工具： $ yum install libcgroup libcgroup-tools $ cgdelete cpu:ydzs.test $ ls /sys/fs/cgroup/cpu/ydzs.test ls: cannot access /sys/fs/cgroup/cpu/ydzs.test: No such file or directory ","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:2:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"在容器中使用 CGroups 上面我们测试了一个普通应用如何配置 cgroup，接下来我们在 Containerd 的容器中来使用 cgroup，比如使用 nerdctl 启动一个 nginx 容器，并限制其使用内存为 50M: $ nerdctl run -d -m 50m --name nginx nginx:alpine 8690c7dba4ffe03d63983555c594e2784c146b5f9939de1195a9626339c9129c $ nerdctl ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8690c7dba4ff docker.io/library/nginx:alpine \"/docker-entrypoint.…\" 53 seconds ago Up nginx 在使用 nerdctl run 启动容器的时候可以使用 -m 或 –memory 参数来限制内存，启动完成后该容器的 cgroup 会出现在 名为 default 的目录下面，比如查看内存子系统的目录： $ ll /sys/fs/cgroup/memory/default/ total 0 drwxr-xr-x 2 root root 0 Oct 21 15:01 8690c7dba4ffe03d63983555c594e2784c146b5f9939de1195a9626339c9129c -rw-r--r-- 1 root root 0 Oct 21 15:01 cgroup.clone_children --w--w--w- 1 root root 0 Oct 21 15:01 cgroup.event_control -rw-r--r-- 1 root root 0 Oct 21 15:01 cgroup.procs ...... 上面我们启动的 nginx 容器 ID 的目录会出现在 /sys/fs/cgroup/memory/default/ 下面，该文件夹下面有很多和内存相关的 cgroup 配置文件，要进行相关的配置就需要在该目录下对应的文件中去操作： $ ll /sys/fs/cgroup/memory/default/8690c7dba4ffe03d63983555c594e2784c146b5f9939de1195a9626339c9129c total 0 -rw-r--r-- 1 root root 0 Oct 21 15:01 cgroup.clone_children --w--w--w- 1 root root 0 Oct 21 15:01 cgroup.event_control -rw-r--r-- 1 root root 0 Oct 21 15:01 cgroup.procs -rw-r--r-- 1 root root 0 Oct 21 15:01 memory.failcnt --w------- 1 root root 0 Oct 21 15:01 memory.force_empty -rw-r--r-- 1 root root 0 Oct 21 15:01 memory.kmem.failcnt 我们这里需要关心的是 memory.limit_in_bytes 文件，该文件就是用来设置内存大小的，正常应该是 50M 的内存限制： $ cat /sys/fs/cgroup/memory/default/8690c7dba4ffe03d63983555c594e2784c146b5f9939de1195a9626339c9129c/memory.limit_in_bytes 52428800 同样我们的 nginx 容器进程 ID 也会出现在上面的 tasks 文件中： $ cat /sys/fs/cgroup/memory/default/8690c7dba4ffe03d63983555c594e2784c146b5f9939de1195a9626339c9129c/tasks 2686 2815 2816 2817 2818 我们可以通过如下命令过滤该进程号，可以看出第一行的 2686 就是 nginx 进程在主机上的进程 ID，下面几个是这个进程下的线程： $ ps -ef | grep 2686 root 2686 2656 0 15:01 ? 00:00:00 nginx: master process nginx -g daemon off; 101 2815 2686 0 15:01 ? 00:00:00 nginx: worker process 101 2816 2686 0 15:01 ? 00:00:00 nginx: worker process 101 2817 2686 0 15:01 ? 00:00:00 nginx: worker process 101 2818 2686 0 15:01 ? 00:00:00 nginx: worker process root 2950 1976 0 15:36 pts/0 00:00:00 grep --color=auto 2686 我们删除这个容器后，/sys/fs/cgroup/memory/default/ 目录下的容器 ID 文件夹也会自动删除。 ","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:3:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"Namespaces namespace 也称命名空间，是 Linux 为我们提供的用于隔离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用个人 PC 时，我们并没有运行多个完全分离的服务器的需求，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这是我们不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。而我们这里的容器其实就通过 Linux 的 Namespaces 技术来实现的对不同的容器进行隔离。 linux 共有 6(7)种命名空间: ipc namespace: 管理对 IPC 资源（进程间通信（信号量、消息队列和共享内存）的访问 net namespace: 网络设备、网络栈、端口等隔离 mnt namespace: 文件系统挂载点隔离 pid namespace: 用于进程隔离 user namespace: 用户和用户组隔离（3.8 以后的内核才支持） uts namespace: 主机和域名隔离 cgroup namespace：用于 cgroup 根目录隔离（4.6 以后版本的内核才支持） 我们可以通过 lsns 命令查看当前系统已经创建的命名空间： # lsns|more NS TYPE NPROCS PID USER COMMAND 4026531836 pid 600 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026531837 user 946 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026531838 uts 629 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026531839 ipc 600 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026531840 mnt 591 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026531856 mnt 1 88 root kdevtmpfs 4026531956 net 643 1 root /usr/lib/systemd/systemd --switched-root --system --deserialize 22 4026532450 mnt 1 6635 chrony /usr/sbin/chronyd 4026532451 mnt 1 6660 root /usr/sbin/NetworkManager --no-daemon 要查看一个进程所属的命名空间信息，可以到 /proc//ns 目录下查看： # ps -ef|grep chronyd chrony 6635 1 0 May11 ? 00:00:50 /usr/sbin/chronyd root 17096 25474 0 17:38 pts/1 00:00:00 grep --color=auto chronyd # ll /proc/6635/ns total 0 lrwxrwxrwx 1 root root 0 Sep 11 17:23 ipc -\u003e ipc:[4026531839] lrwxrwxrwx 1 root root 0 Sep 11 17:23 mnt -\u003e mnt:[4026532450] lrwxrwxrwx 1 root root 0 Sep 11 17:23 net -\u003e net:[4026531956] lrwxrwxrwx 1 root root 0 Sep 11 17:23 pid -\u003e pid:[4026531836] lrwxrwxrwx 1 root root 0 Sep 11 17:23 user -\u003e user:[4026531837] lrwxrwxrwx 1 root root 0 Sep 11 17:23 uts -\u003e uts:[4026531838] 这些 namespace 都是链接文件, 格式为 namespaceType:[inode number]，inode number 用来标识一个 namespace，可以理解为 namespace id，如果两个进程的某个命名空间的链接文件指向同一个，那么其相关资源在同一个命名空间中，也就没有隔离了。比如同样针对上面运行的 nginx 容器，我们查看其命名空间： # lsns |grep nginx 4026533147 mnt 17 25233 10000 nginx: master process nginx -g daemon off 4026533148 uts 17 25233 10000 nginx: master process nginx -g daemon off 4026533149 ipc 17 25233 10000 nginx: master process nginx -g daemon off 4026533150 pid 17 25233 10000 nginx: master process nginx -g daemon off 4026533152 net 17 25233 10000 nginx: master process nginx -g daemon off 4026533313 mnt 17 25604 10000 nginx: master process nginx -g daemon off 4026533314 uts 17 25604 10000 nginx: master process nginx -g daemon off 4026533315 ipc 17 25604 10000 nginx: master process nginx -g daemon off 4026533316 pid 17 25604 10000 nginx: master process nginx -g daemon off 4026533318 net 17 25604 10000 nginx: master process nginx -g daemon off 可以看出 nginx 容器启动后，已经为该容器自动创建了单独的 mtn、uts、ipc、pid、net 命名空间，也就是这个容器在这些方面是独立隔离的，其他容器想要和该容器共享某一个命名空间，那么就需要指向同一个命名空间。 ","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:4:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"参考 https://kubernetes.io/zh-cn/docs/setup/production-environment/container-runtimes/ https://www.infoq.cn/article/docker-resource-management-cgroups/ ","date":"2023-06-26","objectID":"/cgroups%E4%B8%8Enamespaces/:5:0","tags":["docker"],"title":"CGroups与Namespaces","uri":"/cgroups%E4%B8%8Enamespaces/"},{"categories":["docker"],"content":"介绍 Dockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction)，每一条指令 构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 一个简单Dockerfile文件 # VERSION 0.0.1 FROM ubuntu MAINTAINER James Turnbull \"james@example.com\" RUN echo \"deb http://archive.ubuntu.com/ubuntu precise main ↩ universe\" \u003e /etc/apt/sources.list RUN apt-get update RUN apt-get install -y openssh-server RUN mkdir /var/run/sshd RUN echo \"root:password\" | chpasswd EXPOSE 22 可以看的出来Dockerfile 包含一系列命令并附上参数 每个命令都是大写开头，后面是跟着参数 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:0:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"Dockerfile 命令 命令 解释 FROM 指定基础镜像 RUN Dockerfile中的每个指令都会创建一个新的镜像层 CMD 在容器中执行的命令 EXPOSE 暴露端口 ENV 设置环境变量 COPY 拷贝本地文件和目录至镜像 ADD 功能更丰富的添加拷贝指令，COPY优先于ADD ENTRYPOINT ENTRYPOINT指令并不是必须的，ENTRYPOINT是一个脚本 VOLUME 定义镜像中的某个目录为容器卷，会随机生成一个容器卷名 WORKDIR 指定工作目录 ARG 定义了可以通过docker build –build-arg命令传递并在Dockerfile中使用的变量。 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:1:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"Dockerfile 小建议 要使用 tag，但不要 latest。 Debian 挺好的，不要总 Ubuntu。 apt-get update 在前，rm -rf /var/lib/apt/lists/* 在后。 yum install，不忘 yum clean。 多 RUN 要合并，来减少层数。 无用的软件，不要乱安装。 COPY 放最后，缓存很开心。 善用 dockerignore，不浪费传输。 不忘 MAINTAINER，这都是我的。 容器只运行一个应用 摘要\r小结： （FROM）选择合适的基础镜像(alpine版本最好) (RUN)在安装更新时勿忘删除缓存和安装包， 多个命令聚合在一起减少构建时的层数，用不到的软件不要安装 (ADD和COPY)选COPY （LABEL）添加镜像元数据， (MAINTAINER)让我知道是谁维护我 (ENV)设置默认的环境变量 （EXPOSE）说一下暴露的映射端口\r","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:2:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"规约 各团队尽量使用统一的基础镜像。我们建立并维护公司统一的基础镜像列表，请参见: java应用使用的基础镜像 减少Dockerfile的行数，使用\u0026\u0026连接多个命令，因为每一行命令都会生成一个层 将增加文件和清理文件的动作放到一行里面，比如yum install和yum clean all，如果分为两行，第二条清理动作就无法真正删除文件 只复制需要的文件，如果整个目录复制，一定要仔细检查目录下是否有隐藏文件、临时文件等不需要的内容 容器镜像自身有压缩机制，因此把文件压缩成压缩文件然后打入容器，容器启动时解压的方法并不会有什么效果 避免向生产镜像打入一些不必要的工具，比如有的团队打入了sshd，不应该使用这种方案，增加安全风险 尽量精简安装的内容，比如只安装工具的运行时，无须带上帮助文档、源码、样例等等 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:3:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"示例 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:4:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"nginx FROM centos MAINTAINER xianchao RUN yum install wget -y RUN yum install nginx -y # COPY index.html /usr/share/nginx/html/ EXPOSE 80 ENTRYPOINT [\"/usr/sbin/nginx\",\"-g\",\"daemon off;\"] ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:4:1","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"tomcat FROM centos MAINTAINER xianchao RUN yum install wget -y ADD jdk-8u45-linux-x64.rpm /usr/local/ ADD apache-tomcat-8.0.26.tar.gz /usr/local/ RUN cd /usr/local \u0026\u0026 rpm -ivh jdk-8u45-linux-x64.rpm RUN mv /usr/local/apache-tomcat-8.0.26 /usr/local/tomcat8 ENTRYPOINT /usr/local/tomcat8/bin/startup.sh \u0026\u0026 tail -F /usr/local/tomcat8/logs/catalina.out EXPOSE 8080 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:4:2","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"平时较多使用的是docker项目将容器运行时迁移至了containerd，这里整理下相关的操作命令 ","date":"2023-06-26","objectID":"/%E4%BB%8Edocker%E8%87%B3containerd/:0:0","tags":["docker"],"title":"从Docker至Containerd","uri":"/%E4%BB%8Edocker%E8%87%B3containerd/"},{"categories":["docker"],"content":"常用指令对比 ctr是containerd自带的工具，有命名空间的概念 crictl是k8s社区的专用CLI工具，所有操作都在命名空间k8s.io 所以使用ctr操作时注意指定-n k8s.io Docker vs Containerd\r","date":"2023-06-26","objectID":"/%E4%BB%8Edocker%E8%87%B3containerd/:1:0","tags":["docker"],"title":"从Docker至Containerd","uri":"/%E4%BB%8Edocker%E8%87%B3containerd/"},{"categories":["docker"],"content":"清理未被使用的镜像，一般用于释放本地空间 docker 场景 docker image prune -a containerd场景（需要高版本crictl） crictl rmi --prune ","date":"2023-06-26","objectID":"/%E4%BB%8Edocker%E8%87%B3containerd/:2:0","tags":["docker"],"title":"从Docker至Containerd","uri":"/%E4%BB%8Edocker%E8%87%B3containerd/"},{"categories":["docker"],"content":"本地文件和容器内文件间拷贝 docker 场景 docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH 使用kubectl cp Copy files and directories to and from containers. Examples: # !!!Important Note!!! # Requires that the 'tar' binary is present in your container # image. If 'tar' is not present, 'kubectl cp' will fail. # Copy /tmp/foo_dir local directory to /tmp/bar_dir in a remote pod in the default namespace kubectl cp /tmp/foo_dir \u003csome-pod\u003e:/tmp/bar_dir # Copy /tmp/foo local file to /tmp/bar in a remote pod in a specific container kubectl cp /tmp/foo \u003csome-pod\u003e:/tmp/bar -c \u003cspecific-container\u003e # Copy /tmp/foo local file to /tmp/bar in a remote pod in namespace \u003csome-namespace\u003e kubectl cp /tmp/foo \u003csome-namespace\u003e/\u003csome-pod\u003e:/tmp/bar # Copy /tmp/foo from a remote pod to /tmp/bar locally kubectl cp \u003csome-namespace\u003e/\u003csome-pod\u003e:/tmp/foo /tmp/bar Options: -c, --container='': Container name. If omitted, the first container in the pod will be chosen --no-preserve=false: The copied file/directory's ownership and permissions will not be preserved in the container Usage: kubectl cp \u003cfile-spec-src\u003e \u003cfile-spec-dest\u003e [options] Use \"kubectl options\" for a list of global command-line options (applies to all commands). ","date":"2023-06-26","objectID":"/%E4%BB%8Edocker%E8%87%B3containerd/:3:0","tags":["docker"],"title":"从Docker至Containerd","uri":"/%E4%BB%8Edocker%E8%87%B3containerd/"},{"categories":["Kubernetes"],"content":"k8s namespace 无法删除记录 名字空间yaml 文件 kind: Namespace apiVersion: v1 metadata: name: kube-logging 删除卡住 $ sudo kubectl delete -f kube-logging.yaml --wait=true namespace \"kube-logging\" deleted # 长久的等待 强制删除（无效果） sudo kubectl delete ns kube-logging --grace-period=0 --force 排查思路 查看命名空间下的所有资源 kubectl api-resources -o name --verbs=list --namespaced | xargs -n 1 kubectl get --show-kind --ignore-not-found -n kube-logging 输出结果该命名空间下无关联的相关资源 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:0","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"解决方式 一行命令解决，注意替换两处待删命名空间字样 kubectl get namespace \"待删命名空间\" -o json \\ | tr -d \"\\n\" | sed \"s/\\\"finalizers\\\": \\[[^]]\\+\\]/\\\"finalizers\\\": []/\" \\ | kubectl replace --raw /api/v1/namespaces/待删命名空间/finalize -f - ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:1","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"总结 创建namesapce时注入finalizers会导致namespace无法 可以通过edit ns 的方式将finalizers 置空或者上面的一行命令解决的方式，本质是一致的 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:2","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"补充 K8s Finalizers Finalizers 字段属于 Kubernetes GC 垃圾收集器，是一种删除拦截机制，能够让控制器实现异步的删除前（Pre-delete）回调。其存在于任何一个资源对象的 Meta[1] 中，在 k8s 源码中声明为 []string，该 Slice 的内容为需要执行的拦截器名称。 对带有 Finalizer 的对象的第一个删除请求会为其 metadata.deletionTimestamp 设置一个值，但不会真的删除对象。一旦此值被设置，finalizers 列表中的值就只能被移除。 当 metadata.deletionTimestamp 字段被设置时，负责监测该对象的各个控制器会通过轮询对该对象的更新请求来执行它们所要处理的所有 Finalizer。当所有 Finalizer 都被执行过，资源被删除。 metadata.deletionGracePeriodSeconds 的取值控制对更新的轮询周期 当 finalizers 字段为空时，k8s 认为删除已完成。 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:3","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"参考 k8s 如何让 ns 无法删除 kubernetes_Namespace无法删除的解决方法 K8S从懵圈到熟练 - 我们为什么会删除不了集群的命名空间？ k8s问题解决 - 删除命名空间长时间处于terminating状态 熟悉又陌生的 k8s 字段：finalizers ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:1:0","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"故障描述 警告\rPVC 显示创建不成功：kubectl get pvc -n efk 显示 Pending，这是由于版本太高导致的。k8sv1.20 以上版本默认禁止使用 selfLink。 (selfLink：通过 API 访问资源自身的 URL，例如一个 Pod 的 link 可能是 /api/v1/namespaces/ns36aa8455/pods/sc-cluster-test-1-6bc58d44d6-r8hld)。\r","date":"2023-05-23","objectID":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes v1.20创建PVC报错","uri":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/"},{"categories":["Kubernetes"],"content":"故障解决 $ vi /etc/kubernetes/manifests/kube-apiserver.yaml apiVersion: v1 ··· - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key - --feature-gates=RemoveSelfLink=false # 添加这个配置 重启下kube-apiserver.yaml # 如果是二进制安装的 k8s，执行 systemctl restart kube-apiserver # 如果是 kubeadm 安装的 k8s $ ps aux|grep kube-apiserver $ kill -9 [Pid] $ kubectl apply -f /etc/kubernetes/manifests/kube-apiserver.yaml ... $ kubectl get pvc # 查看 pvc 显示 Bound NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE my-pvc Bound pvc-ae9f6d4b-fc4c-4e19-8854-7bfa259a3a04 1Gi RWX example-nfs 13m ","date":"2023-05-23","objectID":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes v1.20创建PVC报错","uri":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/"},{"categories":["Jenkins"],"content":"在了解Jenkins 之前先了解一下CI\u0026CD ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:0:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"cicd 介绍 持续集成(Continous Intergrations) 和持续部署(Continuous Deployment)的区别 持续集成(Continous Intergrations) 和持续部署(Continuous Deployment)是DevOps中域软件交付和 部署相关的两个重要概念 尽管他们的目标是类似的，但在具体含义上存在一些区别 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:1:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"持续集成CI 持续集成(Continous Intergrations) 是一种开发实践，通过将每次的代码改动频繁地集成到 共享代码库中，并进行自动化构建和测试，以确保团队开发的代码能够快速且无误地集成在一起 持续集成的目标是通过频繁的集成代码来快速发现和解决集成问题，减少冲突和错误，提供开发效率和 代码质量 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:1:1","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"持续部署CD 持续部署(Continuous Deployment)是在持续集成的基础上更进一步，指的是将经过 持续集成和测试的代码自动部署到生成环境中，使其可以立即提供用户使用 持续部署强调自动化的部署过程，通过自动化测试和验证确保代码的稳定性和可靠性， 使新功能、修复或者改进能够实时交付给用户 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:1:2","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"Jenkins 介绍 Jenkins是一款开源 CI\u0026CD 软件，用于自动化各种任务，包括构建、测试和部署软件。 Jenkins 支持各种运行方式，可通过系统包、Docker 或者通过一个独立的 Java 程序。 说明 Jenkins 是CI\u0026CD 实现方式的一种，还有其它很多种类似的工具,不过使用于特定的场景，只不过在业界 Jenkins 是使用最广泛的一种 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:2:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"Jenkins 同类CICD工具了解 GitLab CI/CD: GitLab 的集成 CI/CD 功能，可以与 GitLab 代码仓库紧密集成，支持自动化构建、测试和部署流程。它具有易用性和配置简单的优点。 CircleCI: CircleCI 是一个托管的持续集成和部署服务，支持多种语言和框架。它通过配置文件（YAML）定义构建流水线，并提供丰富的插件和集成支持。 Travis CI: Travis CI 是一个面向开源项目的持续集成服务，支持 GitHub 和 GitLab 等代码托管平台。它使用 .travis.yml 文件定义构建步骤和环境设置。 TeamCity: JetBrains 的 TeamCity 是一个功能强大的持续集成和部署服务器，支持多种项目类型和复杂的构建流程配置。它具有良好的可扩展性和集成能力。 GitHub Actions: GitHub Actions 是 GitHub 提供的一种基于事件的自动化工作流服务，可以实现代码检查、测试和部署等操作。它与 GitHub 仓库紧密集成，支持自定义的工作流程定义。 Bamboo: Atlassian 的 Bamboo 是一个企业级的持续集成和部署工具，支持构建和自动化测试、部署到多种环境等。它与其他 Atlassian 产品（如 Jira 和 Bitbucket）集成良好。 Drone: Drone 是一个现代化的持续集成和交付平台，支持 Docker 容器化构建，并提供易用的配置文件和插件系统。它适合于基于容器的项目和微服务架构。 Buildkite: Buildkite 是一个分布式的持续集成和交付平台，注重于灵活性和可扩展性。它通过代理机制实现构建作业的并行执行，适用于大规模和复杂的构建流程。 每个工具都有其独特的优势和适用场景，选择合适的工具通常取决于项目的具体需求、团队的技术栈和预算等因素。 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:2:1","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"安装 在官网的用户手册上提供了多种部署Jenkins的方式，下面提供一下基于Kubernetes 部署的Jenkins jenkins-deploy.yaml --- apiVersion: apps/v1 kind: Deployment metadata: name: jenkins namespace: kube-ops spec: selector: matchLabels: app: jenkins template: metadata: labels: app: jenkins spec: #hostNetwork: true # 解决 updates.jenkins.io 异常问题 terminationGracePeriodSeconds: 10 serviceAccount: jenkins initContainers: - name: fix-permissions image: docker.io/library/busybox:latest # busybox:1.35.0 imagePullPolicy: IfNotPresent command: ['sh', '-c', 'chown -R 1000:1000 /var/jenkins_home'] securityContext: privileged: true volumeMounts: - name: jenkinshome mountPath: /var/jenkins_home containers: - name: jenkins image: localhost/jenkins/jenkins:2.452.2 #v1 -\u003e v2.297 #jenkins/jenkins:lts 生成使用 lts 稳定版本 imagePullPolicy: IfNotPresent ports: - containerPort: 8080 name: web protocol: TCP - containerPort: 50000 name: agent protocol: TCP resources: limits: cpu: 1000m memory: 1Gi requests: cpu: 500m memory: 512Mi livenessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 readinessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 volumeMounts: - name: jenkinshome subPath: jenkins mountPath: /var/jenkins_home securityContext: fsGroup: 1000 volumes: - name: jenkinshome hostPath: path: /opt/jenkins #volumes: #- name: jenkinshome # persistentVolumeClaim: # claimName: opspvc --- apiVersion: v1 kind: Service metadata: name: jenkins namespace: kube-ops labels: app: jenkins spec: selector: app: jenkins type: NodePort ports: - name: web port: 8080 targetPort: web nodePort: 30002 - name: agent port: 50000 targetPort: agent jenkins-rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: name: jenkins namespace: kube-ops --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: jenkins rules: - apiGroups: [\"extensions\", \"apps\"] resources: [\"deployments\"] verbs: [\"create\", \"delete\", \"get\", \"list\", \"watch\", \"patch\", \"update\"] - apiGroups: [\"\"] resources: [\"services\"] verbs: [\"create\", \"delete\", \"get\", \"list\", \"watch\", \"patch\", \"update\"] - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"] - apiGroups: [\"\"] resources: [\"pods/exec\"] verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"] - apiGroups: [\"\"] resources: [\"pods/log\"] verbs: [\"get\",\"list\",\"watch\"] - apiGroups: [\"\"] resources: [\"secrets\"] verbs: [\"get\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: jenkins namespace: kube-ops roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: jenkins subjects: - kind: ServiceAccount name: jenkins namespace: kube-ops 在k8s 中部署的命令 mkdir /opt/jenkins sudo chown -R 1000:1000 /opt/jenkins sudo chmod -R 755 /opt/jenkins kubectl create namespace kube-ops kubectl -n kube-ops create -f rbac.yaml kubectl -n kube-ops create -f jenkins-deploy.yaml kubectl -n kube-ops get pod 注意\r这种是通过直接挂载目录的形式实现的，生产环境是多master 节点，建议使用 nfs 的 pvc 的方式进行挂载\r其它方式安装Jenkins-官网 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:3:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"修改镜像源 由于国内墙的原因，下载一些插件会遇到网络问题，需要修改一下镜像源 系统管控-\u003e 插件管理-\u003e 高级配置 代理镜像源信息： https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json Jenkins\r对应服务器上配置文件 root@k8s-master01:/opt/jenkins/jenkins# cat hudson.model.UpdateCenter.xml \u003c?xml version='1.1' encoding='UTF-8'?\u003e \u003csites\u003e \u003csite\u003e \u003cid\u003edefault\u003c/id\u003e \u003curl\u003ehttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\u003c/url\u003e \u003c/site\u003e ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:4:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"修改 Jenkins 配置 为了方便的使用Jenkins，需要安装一写常用的插件，以下列的有点多，根据需要安装常用的插件，以下基本上都会用得到的，不了解的插件可以到插件市场上 搜索一下看下介绍。 Locale Localization: Chinese Git Git Parameter Git Pipeline for blue Ocean Gitlab Kubernetes Kubernetes CLI Kubernetes Credentials Image Tag Parameter Active Choices Credentials Credentials Binding Blue Ocean (Jenkins 外部UI的页面) Blue Ocean Pineline Editor Blue Ocean Core Js Pipeline SCM API for Blue Ocean Dashboard for Blue Ocean Build with Parameters Dynamic Extended Choice Parameter Extended Choice Parameter List Git Branches Parameter Pipeline Pipelinie: Declarative Publish Over SSH SonarQube Scanner Localization: Chinese(Simplified) Dingtalk Gitlab Plugin (jenkins和Gitlab 建立安全认证) Timestamper AnsiColor SSH SSH Pipeline Steps Jenkins 插件官网 ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:5:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Jenkins"],"content":"参考 https://www.jenkins.io/zh/doc/ ","date":"2023-04-18","objectID":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/:6:0","tags":["Jenkins"],"title":"Jenkins 入门介绍","uri":"/jenkins-%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["Helm"],"content":"Helm 使用一种名为 charts 的包格式，一个 chart 是描述一组相关的 Kubernetes 资源的文件集合，单个 chart 可能用于部署简单的应用，比如 memcached pod，或者复杂的应用，比如一个带有 HTTP 服务、数据库、缓存等等功能的完整 web 应用程序。 Charts 是创建在特定目录下面的文件集合，然后可以将它们打包到一个版本化的存档中来部署。接下来我们就来看看使用 Helm 构建 charts 的一些基本方法。 ","date":"2023-04-17","objectID":"/helm_charts-%E4%BB%8B%E7%BB%8D/:0:0","tags":["Helm"],"title":"Helm Charts 介绍","uri":"/helm_charts-%E4%BB%8B%E7%BB%8D/"},{"categories":["Helm"],"content":"文件结构 chart 被组织为一个目录中的文件集合，目录名称就是 chart 的名称（不包含版本信息），下面是一个 WordPress 的 chart，会被存储在 wordpress/ 目录下面，基本结构如下所示： wordpress/ Chart.yaml # 包含当前 chart 信息的 YAML 文件 LICENSE # 可选：包含 chart 的 license 的文本文件 README.md # 可选：一个可读性高的 README 文件 values.yaml # 当前 chart 的默认配置 values values.schema.json # 可选: 一个作用在 values.yaml 文件上的 JSON 模式 charts/ # 包含该 chart 依赖的所有 chart 的目录 crds/ # Custom Resource Definitions templates/ # 模板目录，与 values 结合使用时，将渲染生成 Kubernetes 资源清单文件 templates/NOTES.txt # 可选: 包含简短使用使用的文本文件 ","date":"2023-04-17","objectID":"/helm_charts-%E4%BB%8B%E7%BB%8D/:1:0","tags":["Helm"],"title":"Helm Charts 介绍","uri":"/helm_charts-%E4%BB%8B%E7%BB%8D/"},{"categories":["Helm"],"content":"Chart.yaml 文件 对于一个 chart 包来说 Chart.yaml 文件是必须的，它包含下面的这些字段： apiVersion: chart API 版本 (必须) name: chart 名 (必须) version: SemVer 2版本 (必须) kubeVersion: 兼容的 Kubernetes 版本 (可选) description: 一句话描述 (可选) type: chart 类型 (可选) keywords: - 当前项目关键字集合 (可选) home: 当前项目的 URL (可选) sources: - 当前项目源码 URL (可选) dependencies: # chart 依赖列表 (可选) - name: chart 名称 (nginx) version: chart 版本 (\"1.2.3\") repository: 仓库地址 (\"https://example.com/charts\") maintainers: # (可选) - name: 维护者名字 (对每个 maintainer 是必须的) email: 维护者的 email (可选) url: 维护者 URL (可选) icon: chart 的 SVG 或者 PNG 图标 URL (可选). appVersion: 包含的应用程序版本 (可选). 不需要 SemVer 版本 deprecated: chart 是否已被弃用 (可选, boolean) ","date":"2023-04-17","objectID":"/helm_charts-%E4%BB%8B%E7%BB%8D/:2:0","tags":["Helm"],"title":"Helm Charts 介绍","uri":"/helm_charts-%E4%BB%8B%E7%BB%8D/"},{"categories":["Helm"],"content":"TEMPLATES 和 VALUES Helm Chart 模板是用 Go template 语言 进行编写的，另外还额外增加了(【Sprig】](https://github.com/Masterminds/sprig)库中的50个左右的附加模板函数和一些其他专用函数。 所有模板文件都存储在 chart 的 templates/ 目录下面，当 Helm 渲染 charts 的时候，它将通过模板引擎传递该目录中的每个文件。模板的 Values 可以通过两种方式提供： Chart 开发人员可以在 chart 内部提供一个名为 values.yaml 的文件，该文件可以包含默认的 values 值内容。 Chart 用户可以提供包含 values 值的 YAML 文件，可以在命令行中通过 helm install 来指定该文件 当用户提供自定义 values 值的时候，这些值将覆盖 chart 中 values.yaml 文件中的相应的值。 ","date":"2023-04-17","objectID":"/helm_charts-%E4%BB%8B%E7%BB%8D/:3:0","tags":["Helm"],"title":"Helm Charts 介绍","uri":"/helm_charts-%E4%BB%8B%E7%BB%8D/"},{"categories":["Kubernetes"],"content":"背景 k8s 容器运行时是docker和containerd结合使用，且生产环境是离线环境将需要的containerd和docker版本相关的rpm包通过yum 进行升级，升级过程涉及到docker的重启，docker容器将会导致所有的容器进行重启，故升级前需要将k8s该节点先设置成维护状态，待升级结束再解除，本文对离线运行时升级进行一个记录，至于为什么需要将Docker和containerd进行结合使用参考下面补充介绍 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:1:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级前提和影响 docker 版本低于 19.03.xx containerd 版本低于 1.3.9 升级后的版本 $ sudo docker version Client: Docker Engine - Community Version: 19.03.11 API version: 1.40 Go version: go1.13.10 Git commit: 42e35e61f3 Built: Mon Jun 1 09:13:48 2020 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.11 API version: 1.40 (minimum version 1.12) Go version: go1.13.10 Git commit: 42e35e61f3 Built: Mon Jun 1 09:12:26 2020 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.3.9 GitCommit: ea765aba0d05254012b0b9e595e995c09186427f runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec3683 $ containerd --version containerd containerd.io 1.3.9 ea765aba0d05254012b0b9e595e995c09186427f ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:2:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级操作 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:3:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"获取升级前集群所有节点状态 $ kubectl get nodes \u003e before-update-node-status.txt ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:3:1","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级过程 升级原则，升级 1 个，检查 OK 后，再升级另外 1 个节点 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:3:2","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级前操作 将准备的升级介质上传至yum源 # rpm 包指定文件夹 /repos/zcm-custom/centos/7/x86_64/ mv docker-ce-19.03.11.tar.gz /repos/zcm-custom/centos/7/x86_64/ cd /repos/zcm-custom/centos/7/x86_64/ tar zxvf docker-ce-19.03.11.tar.gz cd /repos/zcm-custom/centos/7/ createrepo --update x86_64/ # 更新yum源仓库 yum makecache # #重新生成缓存 yum list docker-ce 检查 $ sudo yum list docker-ce Loaded plugins: product-id, search-disabled-repos Repodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast Installed Packages docker-ce.x86_64 3:19.03.11-3.el7 @zcm-custom 能看到 19.03.11 说明 yum 源更新成功 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:3:3","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级步骤 将被升级节点置为非调度状态；对被升级节点执行驱逐操作，将该节点上的业务容器飘到其它节点 $ /usr/local/bin/kubectl cordon 10.45.80.44 $ /usr/local/bin/kubectl drain 10.45.80.44 --ignore-daemonsets 停止 kubelet 服务、停止 kube-proxy 服务 $ sudo systemctl stop kube-proxy $ sudo systemctl stop kubelet 停止 docker/containerd 服务 $ sudo systemctl stop docker $ sudo systemctl stop containerd $ sudo ps aux | grep docker # 检查该机器上所有与 docker 相关的进程 # 如果存在，则 kill 掉 $ sudo ps -ef|grep docker|grep -v dockerd|awk '{print $2}'|xargs kill -9 containerd 升级 $ yum install -y containerd 启动升级后的 docker/containerd 服务 $ sudo systemctl start containerd $ sudo systemctl start docker $ sudo systemctl enable docker $ sudo systemctl enable containerd 启动 kubelet 服务、启动 kube-proxy 服务 $ sudo systemctl start kube-proxy $ sudo systemctl start kubelet 登录 master 节点将升级节点状态设置为允许调度状态 $ sudo kubectl get nodes $ sudo kubectl uncordon 10.45.80.44 被升级节点的状态检查 检查被升级节点的状态 在 k8s master 节点上，执行 kubectl get nodes |grep 被升级节点的 IP 看看是否处于 Ready 状态。 检查被升级节点的容器网络，在升级完后的节点上 ping 一下其它机器上的容器 IP，ping 通的话，容器网络正常 该节点升级完成 依次升级其它节点，按前面的升级步骤位次升级后续的节点，在升级后续节点的过程中，业务容器会在前面升级完成后的节点上调度 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:3:4","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"升级后的节点状态检查 $ kubectl get nodes ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:4:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"补充-为什么要将Docker和containerd进行结合使用？ 更轻量级：containerd是一个更轻量级且专注于容器操作的运行时工具，相比于Docker具有更小的内存占用和更快的启动时间。 更稳定和可靠：containerd是由Docker开源社区开发和维护的，因此可以受益于Docker社区的经验和反馈，从而获得更稳定和可靠的容器技术。 更灵活的集成：containerd被设计为模块化的容器运行时，可以与其他容器生态系统中的工具和服务集成，例如Kubernetes、CRI-O等。 更高性能：由于containerd比Docker更轻量级，因此可以获得更高的性能。它可以快速创建和销毁容器，并提供更低的延迟和更高的吞吐量。 兼容性：通过使用Docker作为容器镜像格式，containerd能够与Docker生态系统中的工具和服务无缝集成，而无需进行任何修改。 综上所述，使用Docker和containerd结合可以提供更轻量级、更稳定可靠、更灵活集成、更高性能和更好的兼容性。这使得它成为一个强大的容器运行时组合，适用于各种不同的容器化场景。 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:5:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Kubernetes"],"content":"参考 Docker 与 Containerd 并用配置 手把手教你搭建Linux离线YUM源环境 ","date":"2023-04-17","objectID":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/:6:0","tags":["Kubernetes"],"title":"k8s容器运行时 containerd 版本升级","uri":"/k8s%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6containerd%E5%8D%87%E7%BA%A7/"},{"categories":["Jenkins"],"content":"要实现在 Jenkins 中的构建工作，可以有多种方式，我们这里采用比较常用的 Pipeline 这种方式。 Pipeline，简单来说，就是一套运行在 Jenkins 上的工作流框架，将原来独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排和可视化的工作。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:0:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline是什么？ Pipeline是Jenkins的核心功能，提供一组可扩展的工具。 通过Pipeline 的DSL语法可以完成从简单到复杂的交付流水线实现。 jenkins的Pipeline是通过Jenkinsfile（文本文件）来实现的。 这个文件可以定义Jenkins的执行步骤，例如检出代码。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:1:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Jenkins file Jenkinsfile使用两种语法进行编写，分别是声明式和脚本式。 声明式和脚本式的流水线从根本上是不同的。 声明式是jenkins流水线更友好的特性。 脚本式的流水线语法，提供更丰富的语法特性。 声明式流水线使编写和读取流水线代码更容易设计。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:2:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"为什么要使用Pipeline? 本质上，jenkins是一个自动化引擎，它支持许多自动模式。流水线向Jenkins添加了一组强大的工具，支持用例、简单的持续集成到全面的持续交付流水线。 通过对一系列的发布任务建立标准的模板，用户可以利用更多流水线的特性，比如： 代码化: 流水线是在代码中实现的，通常会存放到源代码控制，使团队具有编辑、审查和更新他们项目的交付流水线的能力。 耐用性：流水线可以从Jenkins的master节点重启后继续运行。 可暂停的：流水线可以由人功输入或批准继续执行流水线。 解决复杂发布： 支持复杂的交付流程。例如循环、并行执行。 可扩展性： 支持扩展DSL和其他插件集成。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:3:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Jenkins Pipeline 几个核心概念 Node：节点，一个 Node 就是一个 Jenkins 节点，Master 或者 Agent，是执行 Step 的具体运行环境 Stage：阶段，一个 Pipeline 可以划分为若干个 Stage，每个 Stage 代表一组操作，比如：Build、Test、Deploy，Stage 是一个逻辑分组的概念，可以跨多个 Node Step：步骤，Step 是最基本的操作单元，可以是打印一句话，也可以是构建一个 Docker 镜像，由各类 Jenkins 插件提供，比如命令：sh ‘make’，就相当于我们平时 shell 终端中执行 make 命令一样。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:4:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"创建Jenkins Pipeline Pipeline 脚本是由 Groovy 语言实现的，但是我们没必要单独去学习 Groovy，当然你会的话最好 Pipeline 支持两种语法：Declarative(声明式)和 Scripted Pipeline(脚本式)语法 Pipeline 也有两种创建方法：可以直接在 Jenkins 的 Web UI 界面中输入脚本；也可以通过创建一个 Jenkinsfile 脚本文件放入项目源码库中 Jenkins\r一般我们都推荐在 Jenkins 中直接从源代码控制(SCMD)中直接载入 Jenkinsfile Pipeline 这种方法，正常项目中会将 Jenkinsfile 流水线文件放到项目目录下，可以选择Pipeline script from SCM Jenkins\r参考项目 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:5:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline 模板 可以根据以下模板进行动态的填充和修改 // 所有的脚步命令都放在pipeline 中 pipeline{ // 在任一节点都可以使用 agent any // parameters { // string{name:'DEPLOY_ENV',defaultValue:'staging',description:''}, // booleanParam{name:'DEBUG_BUID',defaultValue:true,description:''} // } // 定义全局变量 environment{ key = 'value' } options { //timestamps() // 日志会有时间，依赖Timestamper 插件 // skipDefaultCheckout() // 删除隐式checkout scm 语句 disableConcurrentBuilds() // 禁止并行 timeout(time: 1,unit:'HOURS') // 流水线超时设置1h } stages{ // Example stage('Input 交换的方式'){ steps { timeout(time:5,unit:\"MINUTES\"){ script{ echo \"nice to meet you\" //input id: 'Id', message: 'message', ok: '是否继续', parameters: [choice(choices: ['a', 'b', 'c'], name: 'abc')], submitter: 'lushuan,admin' println(\"hello\") } } } } // 下载代码 stage('拉取git 仓库代码'){ steps { timeout(time:5,unit:\"MINUTES\"){ echo '拉取代码成功-SUCCESS' } } } stage('通过maven构建项目'){ steps { timeout(time:20,unit:\"MINUTES\"){ sh \"/var/jenkins_home/maven/bin/mvn clean package -DskipTests\" } } } stage('通过SnoarQube做代码质量检测'){ steps { timeout(time:30,unit:\"MINUTES\"){ echo '通过SnoarQube做代码质量检测-SUCCESSS' } } } stage('通过Docker制作自定义镜像'){ steps { timeout(time:10,unit:\"MINUTES\"){ //sh \"docker build -t my-spring-boot-app:latest .\" sshPublisher(publishers: [sshPublisherDesc(configName: 'mytest', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: '''cd /opt/jenkins/jenkins/workspace/mytest docker build -t my-spring-boot-app:latest . docker stop mytest docker rm mytest docker run -it -d --name mytest -p 8080:8080 my-spring-boot-app:latest''', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) echo '通过Docker制作自定义镜像-SUCCESSS' } } } stage('将自定义镜像推送至Harbor'){ steps { timeout(time:10,unit:\"MINUTES\"){ echo '将自定义镜像推送至Harbor-SUCCESSS' } } } stage('通过Publish Over SSH 通知目标服务器'){ steps { timeout(time:10,unit:\"MINUTES\"){ echo '通过Publish Over SSH 通知目标服务器-SUCCESSS' } } } } // 构建后操作 post { // 无论成功失败总是执行 always{ script{ println(\"always\") } } success { script{ currentBuild.description += \"\\n 构建成功!\" } // 需要安装 dingtalk 插件 // dingtalk( // robot: \"钉钉自定义名称\", // type: 'MARKDOWN', // title: \"success: ${JOB_NAME}\" // text: [\"- 成功构建:${JOB_NAME}! \\n-版本:${tag} \\n-持续时间:${currentBuild.durationString}\"] // ) } failure { script{ currentBuild.description += \"\\n 构建失败!\" } // dingtalk( // robot: \"钉钉自定义名称\", // type: 'MARKDOWN', // title: \"failure: ${JOB_NAME}\" // text: [\"- 失败构建:${JOB_NAME}! \\n-版本:${tag} \\n-持续时间:${currentBuild.durationString}\"] // ) } aborted { script{ currentBuild.description += \"\\n 构建取消!\" } } } } ","date":"2023-04-16","objectID":"/jenkins-pipeline/:6:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"流水线基础语法 以下是简要的对流水线语法进行粗浅的人生，更详细的请登录官网流水线语法参考进行查看 简介pipeline 基础语法，声明式脚步式，节点步骤 安装声明式插件 Pipeline: Declarative Jenkinsfile 组成 指定node 节点/workspace 指定运行选项 指定stages 阶段 指定构建后操作 Pipeline 的语法分为两种，一种是声明式的，另外一种是脚步式的，声明式编写更加友好，声明式内可以嵌入脚本式 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline定义- post 指定构建后操作 介绍 always{}: 总是执行脚本片段 success{}: 成功后执行 failure{}: 失败后执行 aborted{}: 取消后执行 changed 只有当流水线或者阶段完成状态与之前不同时 unstable 只有当流水线或者阶段状态为\"unstable运行\"，例如测试失败 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:1","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- agent agent 指定了流水线的执行节点 参数： - any 在任何可用的节点上执行pipeling - none 没有指定agent 的时候默认 - lable 在指定的标签上的节点上运行Pipeline - node 允许额外的选项 两种是一样的\ragent { node {label 'labelname'}}\ragent { label 'labelname'}\r","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:2","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- option buildDiscarder:为最近的流水线运行的特定数量保存组件和控制台输出。 disableConcurrentBuilds:不允许同时执行流水线。可被用来防止同时访问共享资源等 overridelndexTriggers: 允许覆盖分支索引触发器的默认处理。 skipDefaultCheckout: 在agent 指令中,跳过从源代码控制中检出代码的默认情况。 skipStagesAfterUnstable:一旦构建状态变得UNSTABLE,跳过该阶段。 checkoutToSubdirectory: 在工作空间的子目录中自动地执行源代码控制检出。 timeout: 设置流水线运行的超时时间,在此之后,Jenkins将中止流水线。 retry:在失败时,重新尝试整个流水线的指定次数。 timestamps 预测所有由流水线生成的控制台输出,与该流水线发出的时间一致。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:3","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- parameters 添加参数时，可以在jenkins 脚本中获取到 parameters { string{name:'DEPLOY_ENV',defaultValue:'staging',description:''}, booleanParam{name:'DEBUG_BUID',defaultValue:true,description:''} } ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:4","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- trigger 触发器 triggers { cron('H */4 * * 1-5') } ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:5","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- tool 主要是用来指定全局工具 tools { maven 'apache-maven-3.0.1' } 如在pipeline 中集成maven时使用 stage(\"build\"){ mvHome=\"/usr/local/apache-maven-3.5.0/bin\" sh \"${mvHome}/mvn clean package\" } // 或者通过 tool 引用 stage(\"build\"){ mvHome = tool 'M3' // M3: /usr/local/apache-maven-3.5.0/bin sh \"${mvHome}/mvn clean package\" } ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:6","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- input input 用户在执行各个阶段的时候，由人工确认是否继续执行 message 呈现给用户的提示信息。 id 可选,默认为stage名称。 ok 默认表单上的ok文本。 submitter 可选的,以逗号分隔的用户列表或允许提交的外部组名。默认允许任何用户。 submitterParameter环境变量的可选名称。如果存在,用submitter 名称设置。 parameters 提示提交者提供的一个可选的参数列表。 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:7","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- when when 指令允许流水线根据给定的条件决定是否应该执行阶段。when 指令必须包含至少一个条件。如果when 指令包含多个条件，所有的条件必须返回True，阶段才能执行。 语法和在stage 平级 内置条件 branch: 当正在构建的分支与模式给定的分支匹配是，执行这个阶段，这只适用于多分支流水线例如： when { branch 'master'} environment:当指定的环境变量是给定的值时，执行这个步骤，例如： when { environment name:'DEPLOY_TO',value: 'production'} not 当嵌套的条件错误时，执行这个阶段，必须包含一个条件，例如 when { not {branch 'master'}} anyof when { anyof {branch 'master';branch 'staging'}} ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:8","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"Pipeline语法- parallel 并行 声明式流水线的阶段可以在他们内部声明多隔嵌套阶段, 它们将并行执行。 另外, 通过添加 failFast true 到包含parallel的 stage中， 当其中一个进程失败时，可以强制所有的 parallel 阶段都被终止。 pipeline { agent any stages { stage('Non-Parallel Stage') { steps { echo 'This stage will be executed first.' } } stage('Parallel Stage') { when { branch 'master' } failFast true parallel { stage('Branch A') { agent { label \"for-branch-a\" } steps { echo \"On Branch A\" } } stage('Branch B') { agent { label \"for-branch-b\" } steps { echo \"On Branch B\" } } } } } } ","date":"2023-04-16","objectID":"/jenkins-pipeline/:7:9","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"参考 Jenkins 流水线 ","date":"2023-04-16","objectID":"/jenkins-pipeline/:8:0","tags":["Jenkins"],"title":"Jenkins Pipeline","uri":"/jenkins-pipeline/"},{"categories":["Jenkins"],"content":"什么是 Blue Ocean? Blue Ocean 是Jenkins的开源子项目，在保证原有强大的功能不变的基础下，对持续交付(CD)Pipeline过程的可视化方面相较于Jenkins 之前的经典界面有了很大的提升。 Blue Ocean 重新思考Jenkins的用户体验，从头开始设计Jenkins Pipeline, 但仍然与自由式作业兼容，Blue Ocean减少了混乱而且进一步明确了团队中每个成员 Blue Ocean 的主要特性包括： 持续交付(CD)Pipeline的 复杂可视化 ，可以让您快速直观地理解管道状态。 Pipeline 编辑器 - 引导用户通过直观的、可视化的过程来创建Pipeline，从而使Pipeline的创建变得平易近人。 个性化 以适应团队中每个成员不同角色的需求。 在需要干预和/或出现问题时 精确定位 。 Blue Ocean 展示 Pipeline中需要关注的地方， 简化异常处理，提高生产力 本地集成分支和合并请求, 在与GitHub 和 Bitbucket中的其他人协作编码时实现最大程度的开发人员生产力。 ","date":"2023-04-14","objectID":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/:1:0","tags":["Jenkins"],"title":"使用Blue Ocean创建一个简单的流水线","uri":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"categories":["Jenkins"],"content":"访问Blue Ocean 在系统管理\u003e插件管理\u003e可选插件中搜索 Blue Ocean \u003e安装,安装成功之后，就可以在页面上看到Blue Ocean的图标,打开后注册git 仓库地址 认证后就可以创建流水线了。 Blue Ocean\r","date":"2023-04-14","objectID":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/:2:0","tags":["Jenkins"],"title":"使用Blue Ocean创建一个简单的流水线","uri":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"categories":["Jenkins"],"content":"创建流水线 创建流水线前需要先安装对应的插件 Blue Ocean 这边使用的git 仓库是gitee，使用gitlab 也是一样的方式，有两种认证的方式 通过账号口令 通过生成 ssh 公钥在gitlab 或者gitee 仓库上进行注册 Blue Ocean\r首先先进行证书认证，然后再创建流水线，如果项目中没有 Jenkinsfile 文件，会自动生成一个文件并默认推到 master 分支。 ","date":"2023-04-14","objectID":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/:3:0","tags":["Jenkins"],"title":"使用Blue Ocean创建一个简单的流水线","uri":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"categories":["Jenkins"],"content":"在Blue Ocean 查看任务进度视图 点击对应的工作节点，可以查询任务运行过程中的日志详情 Blue Ocean\rblue ocean 反向生成的pipeline 代码 pipeline { agent any stages { stage('gitlab pull code') { parallel { stage('gitlab pull code') { steps { sh 'echo \\'gitlab pull code\\'' } } stage('code test') { steps { sh 'echo \\'code test\\'' } } } } stage('docker build') { parallel { stage('docker build') { steps { sh 'echo \\'docker build\\'' } } stage('docker test') { steps { sh 'echo \\'docker test\\'' } } } } stage('deployment') { steps { sh 'echo \\'deployment\\'' } } stage('sanity test') { steps { sh 'echo \\'sanity test\\'' } } } } ","date":"2023-04-14","objectID":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/:3:1","tags":["Jenkins"],"title":"使用Blue Ocean创建一个简单的流水线","uri":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"categories":["Jenkins"],"content":"参考 https://www.jenkins.io/zh/doc/book/blueocean/ ","date":"2023-04-14","objectID":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/:4:0","tags":["Jenkins"],"title":"使用Blue Ocean创建一个简单的流水线","uri":"/%E4%BD%BF%E7%94%A8blue-ocean%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B5%81%E6%B0%B4%E7%BA%BF/"},{"categories":["Kubernetes"],"content":"现象 k8s 某台主机的/var/lib/kubelet目录存储使用率超过80% 使用了40多G存储 ","date":"2023-04-04","objectID":"/kubelet%E7%9B%AE%E5%BD%95%E6%BB%A1%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:1:0","tags":["Kubernetes"],"title":"kubelet目录满问题记录","uri":"/kubelet%E7%9B%AE%E5%BD%95%E6%BB%A1%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["Kubernetes"],"content":"分析 申请root权限 cd /var/lib/kubelet 执行du -h -d 1 发现 pod目录占据大量存储 cd pod 继续执行du -h -d 1 定位到pod 2753dcf9-4113-4e65-a944-278bcbd8d6d8 按上面方法继续执行 发现最终路径为 /var/lib/kubelet/pods/2753dcf9-4113-4e65-a944-278bcbd8d6d8/volumes/kubernetes.io~empty-dir/storage-volume docker ps|grep 2753dcf9-4113-4e65-a944-278bcbd8d6d8 定位容器为prometheus docker inspect 122ec2fbbd1e kubelet\r该容器使用了empty-dir挂载内部的/data ","date":"2023-04-04","objectID":"/kubelet%E7%9B%AE%E5%BD%95%E6%BB%A1%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:2:0","tags":["Kubernetes"],"title":"kubelet目录满问题记录","uri":"/kubelet%E7%9B%AE%E5%BD%95%E6%BB%A1%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["Kubernetes"],"content":"kube-dns切换为coredns k8s版本及其dns适配版本 k8s版本 coredns版本 镜像 镜像yaml 1.17 1.6.7 coredns-1.6.7.tar.gz coredns-1.6.7.yaml 1.22 1.8.4 coredns-1.8.4.tar.gz coredns-1.8.4.yaml coredns/coredns:1.6.7/1.8.4 ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:1:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"操作 根据版本选择对应的dns镜像以及yaml文件上传到其中一台master主机，以1.8.4 版本为例 如果是内网则将coredns-1.6.7/1.8.4.tar.gz 压缩包进行解压并上传至现场的harbor仓库，如果可以连接外网则直接修改 coredns-1.8.4.yaml 文件，将站位符{{ image_address }} 进行修改 ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:2:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"将原有的 kube-dns 停止 $ kubectl scale deploy kube-dns --replicas=0 -n kube-system $ kubectl scale deploy kube-dns-autoscaler --replicas=0 -n kube-system ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:3:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"部署coredns $ kubectl apply -f coredns.yaml ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:4:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"补充: kube-dns vs CoreDNS CoreDNS和kube-dns都是用于Kubernetes集群中的DNS解析服务，它们在不同方面有一些区别，适用于不同的场景。 另外还有一个方面是早期版本的 kube-dns 在 Kubernetes 中主要支持 IPv4。IPv6 的支持不如 CoreDNS 完善，并且在实际应用中可能会遇到限制。 CoreDNS： CoreDNS是一个开源的、轻量级的、灵活的DNS服务器，它是一个通用的DNS服务器，可以用于各种不同的环境和场景，不仅限于Kubernetes集群。 CoreDNS是一个插件驱动的DNS服务器，可以通过插件的方式支持各种功能，例如反向代理、负载均衡、缓存、DNSSEC等。 CoreDNS在Kubernetes集群中可以作为集群的默认DNS插件，用于提供内部服务发现和外部域名解析。它可以动态地解析Kubernetes集群内部的服务和Pod，并提供DNS记录。 kube-dns： kube-dns是Kubernetes集群中的默认DNS解析服务，是一种基于SkyDNS的插件，与Kubernetes紧密集成。 kube-dns使用了一个集群内部的DNS服务器和一个外部的DNS服务器配合工作。集群内部的DNS服务器负责解析集群内的服务和Pod，并提供DNS记录。外部的DNS服务器负责解析集群外的域名，并提供DNS记录。 kube-dns的优点是它是Kubernetes的默认解析器，易于配置和使用，可以满足大多数基本的服务发现和域名解析需求。 综上所述，CoreDNS适用于更通用的环境和场景，可以满足更多的功能需求，而kube-dns是Kubernetes集群中的默认解析器，适用于基本的服务发现和域名解析需求。具体使用哪个取决于特定的需求和场景。 ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:5:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"参考 【kubernetes】部署-CoreDNS-服务 ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:6:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"coredns-1.6.7.yaml apiVersion: v1 kind: ServiceAccount metadata: name: coredns namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: kubernetes.io/bootstrapping: rbac-defaults name: system:coredns rules: - apiGroups: - \"\" resources: - endpoints - services - pods - namespaces verbs: - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" labels: kubernetes.io/bootstrapping: rbac-defaults name: system:coredns roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:coredns subjects: - kind: ServiceAccount name: coredns namespace: kube-system --- apiVersion: v1 kind: ConfigMap metadata: name: coredns namespace: kube-system data: Corefile: | .:53 { errors health { lameduck 5s } ready kubernetes cluster.local in-addr.arpa ip6.arpa { fallthrough in-addr.arpa ip6.arpa } template ANY AAAA { rcode NXDOMAIN } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } --- apiVersion: apps/v1 kind: Deployment metadata: name: coredns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/name: \"CoreDNS\" spec: # replicas: not specified here: # 1. Default is 1. # 2. Will be tuned in real time if DNS horizontal auto-scaling is turned on. strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 selector: matchLabels: k8s-app: kube-dns template: metadata: labels: k8s-app: kube-dns spec: priorityClassName: system-cluster-critical serviceAccountName: coredns tolerations: - key: \"CriticalAddonsOnly\" operator: \"Exists\" - key: node.kubernetes.io/unschedulable effect: NoSchedule nodeSelector: kubernetes.io/role: master affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: k8s-app operator: In values: [\"kube-dns\"] topologyKey: kubernetes.io/hostname containers: - name: coredns image: {{ image_address }}/coredns/coredns:1.6.7 imagePullPolicy: IfNotPresent resources: limits: memory: 170Mi requests: cpu: 100m memory: 70Mi args: [ \"-conf\", \"/etc/coredns/Corefile\" ] volumeMounts: - name: config-volume mountPath: /etc/coredns readOnly: true ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9153 name: metrics protocol: TCP securityContext: allowPrivilegeEscalation: false capabilities: add: - NET_BIND_SERVICE drop: - all readOnlyRootFilesystem: true livenessProbe: httpGet: path: /health port: 8080 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: httpGet: path: /ready port: 8181 scheme: HTTP dnsPolicy: Default volumes: - name: config-volume configMap: name: coredns items: - key: Corefile path: Corefile --- apiVersion: v1 kind: Service metadata: name: kube-dns namespace: kube-system annotations: prometheus.io/port: \"9153\" prometheus.io/scrape: \"true\" labels: k8s-app: kube-dns kubernetes.io/cluster-service: \"true\" kubernetes.io/name: \"CoreDNS\" spec: selector: k8s-app: kube-dns clusterIP: 10.254.0.2 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP - name: metrics port: 9153 protocol: TCP ","date":"2023-03-29","objectID":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/:7:0","tags":["Kubernetes"],"title":"kube-dns切换为coredns实践","uri":"/kube-dns%E5%88%87%E6%8D%A2%E4%B8%BAcoredns%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":" 当Kubernetes创建Pod时发生了什么-全景图 https://github.com/jamiehannaford/what-happens-when-k8s/tree/master/zh-cn what-happens-when-k8s\r","date":"2023-03-26","objectID":"/%E5%BD%93-kubernetes-%E5%88%9B%E5%BB%BA-pod-%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/:0:0","tags":["Kubernetes"],"title":"当 Kubernetes 创建 Pod 时发生了什么","uri":"/%E5%BD%93-kubernetes-%E5%88%9B%E5%BB%BA-pod-%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"},{"categories":["Helm"],"content":"预置条件 适用于Kubernetes v1.12.1及以上，Helm v3.4.2及以上。 以test-cmdb应用为例进行说明,test-cmdb为部署在k8s中的web 应用 ","date":"2023-03-20","objectID":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/:1:0","tags":["Helm"],"title":"Helm charts 编写模板说明","uri":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/"},{"categories":["Helm"],"content":"目录结构 test-cmdb ├── Chart.yaml ├── files │ └── application.properties ├── templates │ ├── configmap.yaml │ ├── deployment.yaml │ ├── _helpers.tpl │ ├── ingress.yaml │ ├── NOTES.txt │ └── service.yaml └── values.yaml ​ 2 directories, 9 files 目录及文件描述： 类型 名称 描述 D test-cmdb 应用名称，根据实际业务应用进行命名。 F Chart.yaml 文件包含了该chart的描述。 D files 配置文件目录 F application.properties 配置文件 D templates 目录包括了模板文件。当Helm评估chart时，会通过模板渲染引擎将所有文件发送到templates/目录中。 然后收集模板的结果并发送给Kubernetes。 F configmap.yaml configmap模板 F deployment.yaml deployment模板 F _helpers.tpl 放置可以通过chart复用的模板辅助对象 F ingress.yaml ingress模板。 F NOTES.txt chart的\"帮助文本\"。会在用户执行helm install时展示。 F service.yaml service模板。 F values.yaml chart的默认值。会在用户执行helm install 或 helm upgrade时被覆盖。 其中，类型：D，目录；F，文件。 ","date":"2023-03-20","objectID":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/:2:0","tags":["Helm"],"title":"Helm charts 编写模板说明","uri":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/"},{"categories":["Helm"],"content":"配置资源 一个完整的应用部署通常由应用名称、镜像名称及tag、环境变量、资源限额、端口监听、端口映射、目录/文件挂载、配置文件、网关规则等组成。通过helm将应用模板化，仅需要简单配置些许地方即可。 应用名称 文件名 key Chart.yaml name values.yaml fullnameOverride 镜像名称及tag 文件名 key values.yaml image.repository values.yaml image.tag 当前的模板默认是以镜像名称与应用名称保持一致为前提的，如镜像10.45.80.1/iplatform/test-cmdb:C_20220214144619的名称为test-cmdb与应用名称test-cmdb保持一致。假如实际的应用名与镜像名称不一致，请自行修改_helpers.tpl中的fullimage部分。 修改前 {{- define \"zcm-tpl.fullimage\" -}} {{- .Values.global.repository }}/{{ .Values.image.repository }}:{{ index .Values .Chart.Name \"image\" \"tag\" | default .Chart.AppVersion }} {{- end }} 修改后 {{- define \"zcm-tpl.fullimage\" -}} {{- .Values.global.repository }}/{{ .Values.image.repository }}:{{ index .Values \"name-template\" \"image\" \"tag\" | default .Chart.AppVersion }} {{- end }} 其中，name-template为实际的镜像名称，该镜像信息配置在$HELM_PATH/charts/values.yaml中，如果该文件中没有匹配的信息，当在部署时会提示异常。 环境变量 文件名 key values.yaml env.name values.yaml env.value values.yaml env.valueFrom.configMapKeyRef.name values.yaml env.valueFrom.configMapKeyRef.key 资源限额 文件名 key values.yaml resources.requests.cpu values.yaml resources.requests.memory values.yaml resources.limits.cpu values.yaml resources.limits.memory 端口监听 文件名 key values.yaml ports.containerPort values.yaml ports.protocol values.yaml ports.name 端口映射 文件名 key values.yaml service.ports.name values.yaml service.ports.port values.yaml service.ports.targetPort 目录/文件挂载 文件名 key values.yaml volumeMounts.name values.yaml volumeMounts.mountPath values.yaml volumeMounts.readOnly values.yaml volumeMounts.subPath values.yaml volumes.name values.yaml volumes.hostpath.path 配置文件 文件名 key values.yaml cm.name values.yaml cm.configmap.name 网关规则 文件名 key values.yaml ingress.annotations values.yaml ingress.tls values.yaml ingress.hosts.paths.path values.yaml ingress.hosts.paths.pathType values.yaml ingress.hosts.paths.port ","date":"2023-03-20","objectID":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/:3:0","tags":["Helm"],"title":"Helm charts 编写模板说明","uri":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/"},{"categories":["Helm"],"content":"部署测试 将准备好的chart放到ZCM部署主机$HELM_PATH/charts目录下，镜像推送到对应环境的镜像仓库中，并在$HELM_PATH/charts/values.yaml中配置镜像信息， 如镜像10.45.80.1/iplatform/zcm-crms:T_20220411015401，需配置对应的信息如下： zcm-crms: image: tag: T_20220411015401 执行部署操作 cd $HELM_PATH/charts helm install zcm-crms ./zcm-crms -f values.yaml -n backend 也可执行其他相关操作 升级 helm upgrade zcm-crms ./zcm-crms -f values.yaml -n backend 卸载 helm uninstall zcm-crms -n backend ","date":"2023-03-20","objectID":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/:4:0","tags":["Helm"],"title":"Helm charts 编写模板说明","uri":"/helm_charts%E7%BC%96%E5%86%99%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E/"},{"categories":["Kubernetes"],"content":"记录一下kuberntes 遇到的问题场景及排查方向 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:0:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"DNS 解析异常 5 秒延时 如果DNS查询经常延时5秒才返回，通常是遇到内核 conntrack 冲突导致的丢包 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"解析超时 如果容器内报 DNS 解析超时，先检查下集群 DNS 服务 (kube-dns/coredns) 的 Pod 是否 Ready，如果不是，查看日志信息。如果运行正常，再具体看下超时现象。 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:1:1","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"Service 无法解析 集群 DNS 没有正常运行(kube-dns或CoreDNS) 检查集群 DNS 是否运行正常: kubelet 启动参数 –cluster-dns 可以看到 dns 服务的 cluster ip: $ ps -ef | grep kubelet ... /usr/bin/kubelet --cluster-dns=172.16.14.217 ... 或者放置配置文件中 $ cat /var/lib/kubelet/config.yaml|grep clusterDNS -A 2 clusterDNS: - 172.16.0.10 clusterDomain: cluster.local 找到 dns 的 service: $ kubectl get svc -n kube-system | grep 172.16.14.217 kube-dns ClusterIP 172.16.14.217 \u003cnone\u003e 53/TCP,53/UDP 47d 看是否存在 endpoint: $ kubectl -n kube-system describe svc kube-dns | grep -i endpoints Endpoints: 172.16.0.156:53,172.16.0.167:53 Endpoints: 172.16.0.156:53,172.16.0.167:53 检查 endpoint 的 对应 pod 是否正常: $ kubectl -n kube-system get pod -o wide | grep 172.16.0.156 kube-dns-898dbbfc6-hvwlr 3/3 Running 0 8d 172.16.0.156 10.0.0.3 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"Pod 与 DNS 服务之间网络不通 检查下 pod 是否连不上 dns 服务，可以在 pod 里 telnet 一下 dns 的 53 端口: # 连 dns service 的 cluster ip $ telnet 172.16.14.217 53 如果检查到是网络不通，就需要排查下网络设置: 检查节点的安全组设置，需要放开集群的容器网段 检查是否还有防火墙规则，检查 iptables ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:2:1","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["prometheus"],"content":"\rPromQL\r","date":"2022-08-29","objectID":"/promql/:0:0","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"介绍 PromQL 是 Prometheus 内置的数据查询语言，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。 并且被广泛应用在 Prometheus 的日常应用当中，包括对数据查询、可视化、告警处理。可以这么说，PromQL 是 Prometheus 所有应用场景的基础，理解和掌握 PromQL 是我们使用 Prometheus 必备的技能。 ","date":"2022-08-29","objectID":"/promql/:1:0","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"PromQL 简介 Prometheus Query Language (PromQL) 是一个专为Prometheus监控系统设计的强大查询语言， 它允许用户对收集的时间序列数据进行高效、灵活的查询和分析。PromQL的设计哲学在于提供简洁而强大的语法，以支持复杂的数据检索和实时监控场景 Prometheus和PromQL的关系 Prometheus是一个开源的系统监控和警报工具包，广泛用于云原生环境中。它通过收集和存储时间序列数据，支持实时监控和警报。 PromQL作为Prometheus的核心组件，允许用户通过强大的查询语言对这些数据进行检索和分析。无论是简单的数据查看还是复杂的性能分析， PromQL都能够提供必要的工具来满足用户的需求。 PromQL的设计哲学 PromQL的设计哲学围绕着几个关键点：灵活性、表现力和性能。它旨在提供足够的灵活性，以支持从简单到复杂的各种查询需求， 同时保持查询表达式的简洁性。此外，PromQL经过优化以支持高效的数据处理和检索，这对于实时监控系统来说至关重要。 ","date":"2022-08-29","objectID":"/promql/:1:1","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"PromQL基础概念 ","date":"2022-08-29","objectID":"/promql/:2:0","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"数据类型和结构 在PromQL中，主要操作以下几种数据类型： 即时向量（Instant Vector） 即时向量是一个时间点上的一组时间序列，每个时间序列具有一个唯一的标签集合和一个数值。它通常用于表示某一瞬间的系统状态。 假设我们有一个监控系统的CPU使用率的时间序列，其查询表达式可能如下： cpu_usage{host=\"server01\"} 该查询返回“server01”主机上最新的CPU使用率数据。 区间向量（Range Vector） 区间向量是在一段时间范围内的一组时间序列，它可以用来分析时间序列的变化趋势或计算时间序列的移动平均等。 要查询过去5分钟内server01主机的CPU使用率数据： cpu_usage{host=\"server01\"}[5m] 标量（Scalar） 标量是一个简单的数值类型，它不带有时间戳，通常用于数学计算或与时间序列数据的比较。 假设我们想要将server01主机的CPU使用率与一个固定阈值进行比较： cpu_usage{host=\"server01\"} \u003e 80 这里“80”就是一个标量值。 字符串（String） 字符串类型在PromQL中用得较少，主要用于标签值的展示。 ","date":"2022-08-29","objectID":"/promql/:2:1","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"时间序列（Time Series）和指标（Metrics） 时间序列 在时间序列中的每一个点称为一个样本（sample），样本由以下三部分组成： 指标(metric)：metric name 和描述当前样本特征的 labelsets 时间戳(timestamp)：一个精确到毫秒的时间戳 样本值(value)： 一个 float64 的浮点型数据表示当前样本的值 示例 \u003c--------------- metric ---------------------\u003e\u003c-timestamp -\u003e\u003c-value-\u003e http_request_total{status=\"200\", method=\"GET\"}@1434417560938 =\u003e 94355 http_request_total{status=\"200\", method=\"GET\"}@1434417561287 =\u003e 94334 http_request_total{status=\"404\", method=\"GET\"}@1434417560938 =\u003e 38473 http_request_total{status=\"404\", method=\"GET\"}@1434417561287 =\u003e 38544 http_request_total{status=\"200\", method=\"POST\"}@1434417560938 =\u003e 4748 http_request_total{status=\"200\", method=\"POST\"}@1434417561287 =\u003e 4785 指标类型 从存储上来讲所有的监控指标 metric 都是相同的，但是在不同的场景下这些 metric 又有一些细微的差异。 例如，在 Node Exporter 返回的样本中指标 node_load1 反应的是当前系统的负载状态，随着时间的变化这个指标返回的样本数据是在不断变化的。 而指标 node_cpu_seconds_total 所获取到的样本数据却不同，它是一个持续增大的值，因为其反应的是 CPU 的累计使用时间，从理论上讲只要系统不关机，这个值是会一直变大。 为了能够帮助用户理解和区分这些不同监控指标之间的差异，Prometheus 定义了 4 种不同的指标类型： Counter（计数器） Gauge（仪表盘） Histogram（直方图） Summary（摘要） 在 node-exporter 返回的样本数据中，其注释中也包含了该样本的类型。例如： # HELP node_cpu_seconds_total Seconds the cpus spent in each mode. # TYPE node_cpu_seconds_total counter node_cpu_seconds_total{cpu=\"cpu0\",mode=\"idle\"} 362812.7890625 Counter Counter (只增不减的计数器) 类型的指标其工作方式和计数器一样，只增不减。常见的监控指标，如 http_requests_total、node_cpu_seconds_total 都是 Counter 类型的监控指标。 Counter 是一个简单但又强大的工具，例如我们可以在应用程序中记录某些事件发生的次数，通过以时间序列的形式存储这些数据，我们可以轻松的了解该事件产生的速率变化。PromQL 内置的聚合操作和函数可以让用户对这些数据进行进一步的分析，例如，通过 rate() 函数获取 HTTP 请求量的增长率： rate(prometheus_http_requests_total[5m]) or rate(http_requests_total[5m]) Gauge 与 Counter 不同，Gauge（可增可减的仪表盘）类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree_bytes（主机当前空闲的内存大小）、node_memory_MemAvailable_bytes（可用内存大小）都是 Gauge 类型的监控指标。 通过 Gauge 指标，用户可以直接查看系统的当前状态： node_memory_MemFree_bytes Histogram 和 Summary 除了 Counter 和 Gauge 类型的监控指标以外，Prometheus 还定义了 Histogram 和 Summary 的指标类型。Histogram 和 Summary 主用用于统计和分析样本的分布情况。 在大多数情况下人们都倾向于使用某些量化指标的平均值，例如 CPU 的平均使用率、页面的平均响应时间，这种方式也有很明显的问题，以系统 API 调用的平均响应时间为例：如果大多数 API 请求都维持在 100ms 的响应时间范围内，而个别请求的响应时间需要 5s，那么就会导致某些 WEB 页面的响应时间落到中位数上，而这种现象被称为长尾问题。 为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在 0~10ms 之间的请求数有多少而 10~20ms 之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram 和 Summary 都是为了能够解决这样的问题存在的，通过 Histogram 和Summary 类型的监控指标，我们可以快速了解监控样本的分布情况。 例如，指标 prometheus_tsdb_wal_fsync_duration_seconds 的指标类型为 Summary。它记录了 Prometheus Server 中 wal_fsync 的处理时间，通过访问 Prometheus Server 的 /metrics 地址，可以获取到以下监控样本数据： # HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync. # TYPE prometheus_tsdb_wal_fsync_duration_seconds summary prometheus_tsdb_wal_fsync_duration_seconds{quantile=\"0.5\"} 0.012352463 prometheus_tsdb_wal_fsync_duration_seconds{quantile=\"0.9\"} 0.014458005 prometheus_tsdb_wal_fsync_duration_seconds{quantile=\"0.99\"} 0.017316173 prometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002 prometheus_tsdb_wal_fsync_duration_seconds_count 216 从上面的样本中可以得知当前 Prometheus Server 进行 wal_fsync 操作的总次数为 216 次，耗时 2.888716127000002s。其中中位数（quantile=0.5）的耗时为 0.012352463，9 分位数（quantile=0.9）的耗时为 0.014458005s。 在 Prometheus Server 自身返回的样本数据中，我们还能找到类型为 Histogram 的监控指标prometheus_tsdb_compaction_chunk_range_seconds_bucket： # HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on their first compaction # TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"100\"} 71 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"400\"} 71 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"1600\"} 71 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"6400\"} 71 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"25600\"} 405 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"102400\"} 25690 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"409600\"} 71863 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"1.6384e+06\"} 115928 prometheus_tsdb_compaction_chunk_range_seconds_bucket{le=\"6.5536e+06\"} 2.5687892e+07 promet","date":"2022-08-29","objectID":"/promql/:2:2","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"查询 ","date":"2022-08-29","objectID":"/promql/:3:0","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"简单查询和表达式 PromQL Web UI 的 Graph 选项卡提供了简单的用于查询数据的入口 输入 up，然后点击 Execute，就能查到监控正常的 Target 通过标签选择器过滤出 job 为 kubernetes-pods 的监控 up{job=\"kubernetes-pods\"} 注意此时是 up{job=“node-exporter”}属于绝对匹配，PromQL 也支持如下表达式： !=：不等于； =~：表示等于符合正则表达式的指标； !~：和=~类似，=~表示正则匹配，!~表示正则不匹配。 如果想要查看主机监控的指标有哪些，可以输入 node，会提示所有主机监控的指标： 查询\r假 如 想 要 查 询 Kubernetes 集 群 中 每 个 宿 主 机 的 磁 盘 总 量 ， 可 以 使 用node_filesystem_size_bytes 查询指定分区大小 node_filesystem_size_bytes{mountpoint=\"/\"}： 或者是查询分区不是/boot，且磁盘是/dev/开头的分区大小（结果不再展示）： node_filesystem_size_bytes{device=~\"/dev/.*\", mountpoint!=\"/boot\"} 查询主机 192.168.1.11 在最近 5 分钟可用的磁盘空间变化： node_filesystem_size_bytes{mountpoint=\"/\",instance=\"192.168.1.11:9100\"}[5m] 目前支持的范围单位如下： s：秒 m：分钟 h：小时 d：天 w：周 y：年 查询 10 分钟之前磁盘可用空间，只需要指定 offset 参数即可 node_filesystem_avail_bytes{instance=\"192.168.1.11:9100\", mountpoint=\"/\", device=\"/dev/mapper/centos-root\"} offset 10m 查询 10 分钟之前，5 分钟区间的磁盘可用空间的变化 node_filesystem_avail_bytes{instance=\"192.168.1.11:9100\", mountpoint=\"/\", device=\"/dev/mapper/centos-root\"}[5m] offset 10m ","date":"2022-08-29","objectID":"/promql/:3:1","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"使用标签选择器（Label Selectors）过滤数据 多个标签通过逗号进行分隔 kubelet_http_requests_total{method=\"GET\",path =~ \"metrics.*\"} 查看主机过去5分钟已使用内存 node_memory_Active_bytes[5m] 查询结果 Label Selectors\r查看10.10.192.220主机一小时前的使用内存 node_memory_Active_bytes{instance=\"10.10.192.220:9100\"} offset 1h ","date":"2022-08-29","objectID":"/promql/:3:2","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["prometheus"],"content":"高级查询 使用PromQL除了能够方便的按照查询和过滤时间序列以外，PromQL还支持丰富的操作符，用户可以使用这些操作符对进一步的对事件序列进行二次加工。这些操作符包括：数学运算符，逻辑运算符，布尔运算符等等。 数学运算 例如，我们可以通过指标node_memory_MemFree_bytes获取当前主机可用的内存空间大小，其样本单位为Bytes。这是如果客户端要求使用MB作为单位响应数据，那只需要将查询到的时间序列的样本值进行单位换算即可 node_memory_MemFree_bytes / 1024 / 1024 PromQL支持的所有数学运算符如下所示： 使用布尔运算过滤时间序列 查看free 内存值大于512M的主机 (node_memory_MemFree_bytes / 1024 / 1024) \u003e 512 目前，Prometheus支持以下布尔运算符如下： != (不相等) \u003e (大于) \u003c (小于) \u003e= (大于等于) \u003c= (小于等于) 使用集合运算符 使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，我们称为瞬时向量。 通过集合运算，可以在两个瞬时向量与瞬时向量之间进行相应的集合操作。 如时钟未同步告警 min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds \u003e= 16 目前，Prometheus支持以下集合运算符： and (并且) or (或者) unless (排除) 操作符优先级 对于复杂类型的表达式，需要了解运算操作的运行优先级 例如，查询主机的CPU使用率，可以使用表达式： 100-(avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) by(instance,job)* 100) \u003e 80 其中irate是PromQL中的内置函数，用于计算区间向量中时间序列每秒的即时增长率。 内置函数 Prometheus还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。 sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准差异) count (计数) count_values (对value进行计数) bottomk (后n条时序) topk (前n条时序) quantile (分布统计) 使用聚合操作的语法如下： \u003caggr-op\u003e([parameter,] \u003cvector expression\u003e) [without|by (\u003clabel list\u003e)] 其中只有count_values, quantile, topk, bottomk支持参数(parameter) without用于从计算结果中移除列举的标签，而保留其它标签。 by则正好相反，结果向量中只保留列出的标签，其余标签则移除。通过without和by可以按照样本的问题对数据进行聚合。 例如： sum(http_requests_total) without (instance) 等价于 sum(http_requests_total) by (code,handler,job,method) 如果只需要计算整个应用的HTTP请求总量，可以直接使用表达式： sum(http_requests_total) count_values用于时间序列中每一个样本值出现的次数。count_values会为每一个唯一的样本值输出一个时间序列，并且每一个时间序列包含一个额外的标签。 例如： count_values(\"count\", http_requests_total) topk和bottomk则用于对样本值进行排序，返回当前样本值前n位，或者后n位的时间序列。 获取HTTP请求数前5位的时序样本数据，可以使用表达式： topk(5, http_requests_total) quantile用于计算当前样本数据值的分布情况quantile(φ, express)其中0 ≤ φ ≤ 1。 例如，当φ为0.5时，即表示找到当前样本数据中的中位数： quantile(0.5, http_requests_total) ","date":"2022-08-29","objectID":"/promql/:3:3","tags":["prometheus"],"title":"PromQL","uri":"/promql/"},{"categories":["Kubernetes"],"content":"使用 kubernetes 经常会用到命令行，这里对命令行进行分类整理 集群管理 kubectl cluster-info kubectl config kubectl version kubectl api-versions 查看当前集群支持的api版本 kubectl get node kubectl get pod kubectl get service kubectl cordon 命令：用于标记某个节点不可调度 kubectl uncordon 命令：用于标签节点可以调度 kubectl drain 命令： 用于在维护期间排除节点。 kubectl taint 命令：用于给某个Node节点设置污点 Pod 管理 kubectl create pod kubectl get pod kubectl get pod pod_name –show-labels kubectl describe pod kubectl logs kubectl exec kubectl delete pod 资源监测 kubectl top node kubectl top pods kubectl get quota kubectl describe Service管理 kubectl create service kubectl get service kubectl expose kubectl describe service kubectl delete service kubectl port-forwad 配置和加密 kubectl create configmap kubectl get configmap kubectl create secret kubectl get secret kubectl describe configmap kubectl describe secret Deployment管理 kubectl create deployment kubectl get deployment kubectl scale deployment sudo kubectl scale deployment deploy-name –replicas=0 不删除应用暂停服务 kubectl autoscale deployment kubectl rollout status kubectl rollout history kubectl delete deployment 名字空间管理 kubectl create namespace kubectl get namespace kubectl describe namespace kubectl delete namespace kubectl apply -n kubectl switch -n kubeadm管理 kubeadm init 启动引导一个 Kubernetes 主节点 kubeadm join 启动引导一个 Kubernetes 工作节点并且将其加入到集群 kubeadm upgrade 更新 Kubernetes 集群到新版本 kubeadm config 如果你使用 kubeadm v1.7.x 或者更低版本，你需要对你的集群做一些配置以便使用 kubeadm upgrade 命令 kubeadm token 使用 kubeadm join 来管理令牌 kubeadm reset 还原之前使用 kubeadm init 或者 kubeadm join 对节点所作改变 kubeadm version 打印出 kubeadm 版本 kubeadm alpha 预览一组可用的新功能以便从社区搜集反馈 kubeadm token create –print-join-command 创建node加入口令 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:0:0","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"命令说明 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:0","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"1. kubectl expose 和 kubectl port-forwad 的区别 kubectl expose 和 kubectl port-forward 是两个不同的命令，它们在 Kubernetes 中有不同的作用和用法。 kubectl expose 命令用于创建一个新的 Service 对象来暴露 Deployment、ReplicationController 或 ReplicaSet 等其他资源。它会为指定的资源创建一个新的 ClusterIP 类型的 Service，在集群内部通过 Service IP 和端口号来访问暴露的资源。这个 Service 对象可以是临时的，也可以是永久的，它根据指定的参数设置来控制其行为。 kubectl port-forward 命令用于在本地机器和 Kubernetes 集群之间建立一个临时的协议转发，将本地的端口与 Kubernetes Pod 或 Service 的端口进行绑定。这样可以直接通过本地机器上的端口来访问 Kubernetes 集群中的服务或应用。该命令通常用于开发和调试，比如在本地机器上直接访问运行在集群中的应用程序或服务的日志。 总结来说，kubectl expose 用于创建一个新的 Service 对象来暴露 Kubernetes 资源，而 kubectl port-forward 则用于建立本地与集群之间的临时端口转发，方便本地机器访问集群中的服务或应用程序。 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:1","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"2. kubectl apply 和 kubectl switch 的区别 kubectl apply 用于在 Kubernetes 集群上部署或更新资源对象，可以通过文件或目录进行声明。它会读取文件中的资源定义，并在集群中创建或更新相应的资源对象。kubectl switch 是一个非官方的插件，用于切换当前上下文的集群。Kubernetes 集群允许存在多个上下文，每个上下文对应一个集群。 kubectl switch 可以方便地在多个集群之间切换，目的是为了方便用户在不同的集群之间进行操作。因此，kubectl apply 用于部署和更新资源对象，而 kubectl switch 用于切换当前操作的集群。它们是两个不同的命令，用途和功能不同。 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:2","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"3. kubectl scale 和 kubectl autoscale的区别 kubectl scale和kubectl autoscale是用于扩容或缩容Kubernetes Deployment或ReplicaSet的命令，但它们有一些区别。 kubectl scale命令允许通过手动指定副本数量来更新Deployment或ReplicaSet的副本数量。例如，可以使用以下命令将副本数量设置为3： kubectl scale deployment/my-deployment --replicas=3 kubectl autoscale命令则是根据指定的CPU使用率来自动扩容或缩容Deployment。它会创建一个HorizontalPodAutoscaler(HPA)对象，该对象会根据CPU的使用情况动态地增加或减少Pod的副本数量以满足指定的CPU目标使用率。例如，可以使用以下命令将Pod的副本数量自动调整为至少2个，当CPU使用率超过50%时： kubectl autoscale deployment/my-deployment --min=2 --max=10 --cpu-percent=50 总结起来，kubectl scale用于手动指定副本数量来更新Deployment或ReplicaSet的副本数量，而kubectl autoscale用于根据CPU使用率自动扩容或缩容Pod的副本数量。 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:3","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"4. kubectl exec和kubectl attach 的区别 kubectl exec和kubectl attach是用于与正在运行的Pod进行交互的命令，但它们在使用方式和功能上有一些区别。 kubectl exec命令用于在正在运行的Pod中执行命令。它可以连接到正在运行的容器，并在容器中执行指定的命令。例如，可以使用以下命令在名为my-pod的Pod中执行echo命令： kubectl exec -it my-pod -- echo \"Hello, World!\" kubectl attach命令用于将本地终端连接到正在运行的Pod中的某个容器的标准输入、输出和错误流。它可以与容器建立交互式会话。例如，可以使用以下命令将本地终端连接到名为my-pod的Pod中的第一个容器： kubectl attach -it my-pod 总结起来，kubectl attach命令类似于kubectl exec，但它附加到容器中运行的主进程，而不是运行额外的进程。 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:4","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Kubernetes"],"content":"5. kubectl patch和kubectl replace的区别 kubectl patch和kubectl replace是用于部分更新和替换更新Kubernetes资源的命令，但它们在更新方式和行为上有一些区别。 kubectl patch命令用于部分更新Kubernetes资源的特定字段。它可以通过提供一个JSON或YAML文件、一个JSON或YAML字符串，或者使用特定的操作类型（如add、remove、replace等）来更新资源的字段。例如，可以使用以下命令将名为my-deployment的Deployment资源的labels字段添加一个新的标签： kubectl patch deployment/my-deployment -p '{\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"new-label\":\"value\"}}}}}' kubectl replace命令用于替换更新整个Kubernetes资源。它会基于提供的配置文件完全替换现有资源的内容。例如，可以使用以下命令将名为my-deployment的Deployment资源替换为一个新的配置文件： kubectl replace -f new-deployment.yaml 总结起来，kubectl patch用于部分更新Kubernetes资源的特定字段，而kubectl replace用于完全替换更新整个Kubernetes资源。 ","date":"2022-08-20","objectID":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/:1:5","tags":["Kubernetes"],"title":"kubernetes常用命令整理","uri":"/kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"},{"categories":["Grafana"],"content":"Grafana简介 Grafana 是一个监控仪表系统，它是由 Grafana Labs 公司开源的的一个系统监测 (System Monitoring) 工具。它可以大大帮助你简化监控的复杂度，你只需要提供你需要监控的数据，它就可以帮你生成各种可视化仪表。同时它还有报警功能，可以在系统出现问题时通知你。 Grafana 本身是非常轻量级的，不会占用大量资源，此外 Grafana 需要一个数据库来存储其配置数据，比如用户、数据源和仪表盘等，目前 Grafana 支持 SQLite、MySQL、PostgreSQL 3 种数据库，默认使用的是 SQLite，该数据库文件会存储在 Grafana 的安装位置，所以需要对 Grafana 的安装目录进行持久化。 当然如果我们想要部署一个高可用版本的 Grafana 的话，那么使用 SQLite 数据库就不行了，需要切换到 MySQL 或者 PostgreSQL，我们可以在 Grafana 配置的 [database] 部分找到数据库的相关配置，Grafana 会将所有长期数据保存在数据库中，然后部署多个 Grafana 实例使用同一个数据库即可实现高可用。 ","date":"2022-08-17","objectID":"/grafana/:1:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"Grafana的核心功能和架构 Grafana提供了一个丰富的图表库，包括时序数据图、柱状图、饼图等多种类型，使其能够展示各种指标数据。 用户可以通过拖放的方式自定义仪表板，实现对数据的实时监控和分析。Grafana的前端界面使用AngularJS和React构建，后端则主要采用Go语言开发，确保了其高性能和灵活性。 ","date":"2022-08-17","objectID":"/grafana/:1:1","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"Grafana的安装与初步配置 Grafana支持多种安装方式，包括Docker容器、预编译的二进制包、源代码编译等，可以满足不同用户的需求。 ","date":"2022-08-17","objectID":"/grafana/:2:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"Docker 安装 使用Docker安装Grafana是一种快速而便捷的方法。用户只需要准备一个Docker环境，然后运行以下命令即可： docker run -d --name grafana -p 3000:3000 grafana/grafana:9.2.20 此命令会下载Grafana的Docker镜像，并在容器中启动Grafana服务，监听本地的3000端口。 安装完成后，需要对Grafana进行初步配置，包括设置监听端口、配置数据库等。这些配置可以在Grafana的配置文件grafana.ini中进行。 ","date":"2022-08-17","objectID":"/grafana/:2:1","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"kubernetes 安装 kubernetes 部署并切换数据源为MySQL,这样容器重建后配置的大屏不会丢失且企业生产环境也是通过这种方式来使用，方便dashboard大屏脚本在数据库中的管理。 grafana-configmap.yaml，数据库中配置MySQL 数据源连接信息，Grafana 默认使用的数据库是 sqlite3,这里做一下变更 apiVersion: v1 kind: ConfigMap metadata: name: grafana namespace: monitoring data: grafana.ini: | #################################### Database #################################### [database] # You can configure the database connection by specifying type, host, name, user and password # as separate properties or as on string using the url properties. # Either \"mysql\", \"postgres\" or \"sqlite3\", it's your choice type = mysql host = 192.168.1.11:3306 name = grafana user = root # If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\" password = abc@123A # Use either URL or the previous fields to configure the database # Example: mysql://user:secret@host:port/database url = mysql://root:password@192.168.1.11:3306/grafana grafana-deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: grafana namespace: monitoring labels: app: grafana component: core spec: replicas: 1 selector: matchLabels: app: grafana template: metadata: labels: app: grafana component: core spec: containers: - image: grafana/grafana:9.2.20 name: grafana imagePullPolicy: IfNotPresent #securityContext: # runAsUser: 0 # fsGroup: 0 # env: resources: # keep request = limit to keep this container in guaranteed class limits: cpu: 100m memory: 256Mi requests: cpu: 100m memory: 100Mi env: # The following env variables set up basic auth twith the default admin user and admin password. - name: GF_AUTH_BASIC_ENABLED value: \"true\" - name: GF_AUTH_ANONYMOUS_ENABLED value: \"false\" - name: GF_PATHS_DATA value: \"/var/lib/grafana\" - name: GF_PATHS_CONFIG value: \"/etc/grafana/grafana.ini\" # - name: GF_AUTH_ANONYMOUS_ORG_ROLE # value: Admin # does not really work, because of template variables in exported dashboards: # - name: GF_DASHBOARDS_JSON_ENABLED # value: \"true\" readinessProbe: httpGet: path: /login port: 3000 initialDelaySeconds: 30 timeoutSeconds: 1 volumeMounts: # 数据持久化 - name: config-volume mountPath: /etc/grafana # - name: grafana-persistent-storage # mountPath: /var volumes: - name: config-volume configMap: name: grafana #- name: grafana-persistent-storage # hostPath: # path: /grafana-data # type: DirectoryOrCreate #- name: grafana-persistent-storage # emptyDir: {} grafana-service.yaml apiVersion: v1 kind: Service metadata: name: grafana namespace: monitoring labels: app: grafana component: core spec: type: NodePort ports: - port: 3000 targetPort: 3000 nodePort: 30009 selector: app: grafana component: core 部署 kubectl create namespace monitoring kubectl create -f grafana-configmap.yaml kubectl create -f grafana-deploy.yaml kubectl create -f grafana-service.yaml 部署成功 # kubectl -n monitoring get pod,svc NAME READY STATUS RESTARTS AGE pod/grafana-5d8c7d5c8c-znffb 1/1 Running 0 6m18s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/grafana NodePort 10.110.17.117 \u003cnone\u003e 3000:30009/TCP 11m 成功部署后，数据库会反向生成相关的表信息 grafana\r","date":"2022-08-17","objectID":"/grafana/:2:2","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"访问功能界面 http://ip:30009 登录是默认账号口令为admin/admin,第一次登录时提示修改密码 grafana\r登录成功界面 grafana\r","date":"2022-08-17","objectID":"/grafana/:3:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"数据源深入集成 grafana\r在Grafana中，数据源的集成是构建有效监控和分析系统的关键步骤。Grafana支持众多流行的数据存储和监控工具作为数据源，包括时序数据库Prometheus, InfluxDB，日志和文档存储如Elasticsearch，以及传统的SQL数据库如MySQL和PostgreSQL。 ","date":"2022-08-17","objectID":"/grafana/:4:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"导入 Dashboard 为了能够快速对系统进行监控，我们可以直接复用别人的 Grafana Dashboard，在 Grafana 的官方网站上就有很多非常优秀的第三方 Dashboard，我们完全可以直接导入进来即可。 比如我们想要对所有的集群节点进行监控，也就是 node-exporter 采集的数据进行展示，这里我们就可以导入 https://grafana.com/grafana/dashboards/8919 这个 Dashboard。 在侧边栏点击 “+\"，选择 Import，在 Grafana Dashboard 的文本框中输入 8919 即可导入： grafana\r注意\r在导入之前需要先创建数据源，大屏是适配的Prometheus 数据源\r通过部署Prometheus 和 Node Exporter 采集的实时数据大屏 grafana\r","date":"2022-08-17","objectID":"/grafana/:5:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"Grafana 相关组件概念了解 ","date":"2022-08-17","objectID":"/grafana/:6:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"面板介绍 面板（Panel）是 Grafana 中基本可视化构建块，每个面板都有一个特定于面板中选择数据源的查询编辑器，每个面板都有各种各样的样式和格式选项，面板可以在仪表板上拖放和重新排列，它们也可以调整大小。 Panel 是 Grafana 中最基本的可视化单元，每一种类型的面板都提供了相应的查询编辑器(Query Editor)，让用户可以从不同的数据源（如 Prometheus）中查询出相应的监控数据，并且以可视化的方式展现，Grafana 中所有的面板均以插件的形式进行使用。 目前内置支持的面板包括：Time series（时间序列）是默认的也是主要的图形可视化面板、State timeline（状态时间表）状态随时间变化 、Status history（状态历史记录）、Bar chart（条形图）、Histogram（直方图）、Heatmap（热力图）、Pie chart（饼状图）、Stat（统计数据）等 图表 Time series 数据统计 stat 仪表盘 gauge 表格 table 饼状图 Pie Chart 热图 Heatmap ","date":"2022-08-17","objectID":"/grafana/:6:1","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"图形面板 数据源（Data Source） 添加面板（Add Panel） 添加参数（Dashboard settings） ","date":"2022-08-17","objectID":"/grafana/:6:2","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"图形定制 多个查询(query editor) 转换(Transform) 模板变量 ","date":"2022-08-17","objectID":"/grafana/:6:3","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"文本面板 # 这是一级标题 ## 这是二级标题 这是正文内容，**我是加粗**，`我是强调`。 \u003e 还可以添加引用的内容 ![这是一张图片](https://p8s.io/docs/assets/img/illustration.png \"grafana\") 渲染后的图片 grafana\r","date":"2022-08-17","objectID":"/grafana/:6:4","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"其它 安全与维护 用户认证与授权 数据备份与恢复 注释 Grafana 中提供了一个 Annotations 注释的方法，通过该方式可以在图形上标记一个点，当将鼠标悬停在上面的时候，可以获得该注释的具体信息，我们可以在 Panel 面板中某一个点添加注释，也可以在某一个区域内添加注释。 告警 Grafana 除了支持丰富的数据源和图表功能之外，还支持告警功能，该功能也使得 Grafana 从一个数据可视化工具成为了一个真正的监控利器。Grafana 可以通过 Alerting 模块的配置把监控数据中的异常信息进行告警，告警的规则可以直接基于现有的数据图表进行配置，在告警的时候也会把出现异常的图表进行通知，使得我们的告警通知更加友好。 ","date":"2022-08-17","objectID":"/grafana/:6:5","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Grafana"],"content":"参考 Grafana 官网 Grafana Dashboard模板-官网 ","date":"2022-08-17","objectID":"/grafana/:7:0","tags":["Grafana"],"title":"Grafana","uri":"/grafana/"},{"categories":["Helm"],"content":"记录一下helm 在生产中的实践 Helm 可以帮助我们管理 Kubernetes 应用程序 - Helm Charts 可以定义、安装和升级复杂的 Kubernetes 应用程序，Charts 包很容易创建、版本管理、分享和分布。 Helm 对于 Kubernetes 来说就相当于 yum 对于 Centos 来说，如果没有 yum 的话，我们在 Centos 下面要安装一些应用程序是极度麻烦的，同样的，对于越来越复杂的 Kubernetes 应用程序来说，如果单纯依靠我们去手动维护应用程序的 YAML 资源清单文件来说，成本也是巨大的。 ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:0:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Helm"],"content":"安装 由于 Helm V2 版本必须在 Kubernetes 集群中安装一个 Tiller 服务进行通信，这样大大降低了其安全性和可用性，所以在 V3 版本中移除了服务端，采用了通用的 Kubernetes CRD 资源来进行管理，这样就只需要连接上 Kubernetes 即可，而且 V3 版本已经发布了稳定版 这里使用的是helm v3版本 ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:1:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Helm"],"content":"示例 Helm 其实就是读取的 kubeconfig 文件来访问集群的。 # 查看版本 $ helm version version.BuildInfo{Version:\"v3.8.1\", GitCommit:\"5cb9af4b1b271d11d7a97a71df3ac337dd94ad37\", GitTreeState:\"clean\", GoVersion:\"go1.17.5\"} # 添加一个 chart 仓库 $ helm repo add stable http://mirror.azure.cn/kubernetes/charts/ \"stable\" has been added to your repositories $ helm repo list NAME URL stable http://mirror.azure.cn/kubernetes/charts/ # 用 search 命令来搜索可以安装的 chart 包，已经集成了将近300个可安装的chart包 zoms@crms-10-10-192-220[/tmp]$ helm search repo stable|more NAME CHART VERSION APP VERSION DESCRIPTION stable/acs-engine-autoscaler 2.2.2 2.1.1 DEPRECATED Scales worker nodes within agent pools stable/aerospike 0.3.5 v4.5.0.5 DEPRECATED A Helm chart for Aerospike in Kubern... stable/airflow 7.13.3 1.10.12 DEPRECATED - please use: https://github.com/air... # 安装之前先进行更新 $ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"stable\" chart repository Update Complete. ⎈Happy Helming!⎈ # 安装一个mysql 应用 helm install stable/mysql --generate-name # 了解 MySQL 这个 chart 包的一些特性 helm show chart stable/mysql # 了解 MySQL 这个 chart 包更多的特性 helm show all stable/mysql # 查看已安装的release helm ls # 删除release helm uninstall mysql-1575619811 # 删除release 时保留历史记录，方便取消删除 release（使用 helm rollback 命令） helm uninstall mysql-1575619811 --keep-history ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:2:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Helm"],"content":"定制 helm show values 命令来查看一个 chart 包的所有可配置的参数选项 查看本地chart包可配置的参数选项 $ helm show values ./nms-grafana/ -n zcm9 # Default values for nms-grafana. # This is a YAML-formatted file. # Declare variables to be passed into your templates fullnameOverride: nms-grafana replicaCount: 1 restartPolicy: Always .... 查看仓库chart包的所有可配置的参数选项,安装之前先看下镜像源是否可先pull下来，以及镜像的版本号 $ helm show values stable/mysql ## mysql image version ## ref: https://hub.docker.com/r/library/mysql/tags/ ## image: \"mysql\" imageTag: \"5.7.30\" strategy: type: Recreate busybox: image: \"busybox\" 上面我们看到的所有参数都是可以用自己的数据来覆盖的，可以在安装的时候通过 YAML 格式的文件来传递这些参数 $ cat config.yaml mysqlUser: user0 mysqlPassword: user0pwd mysqlDatabase: user0db persistence: enabled: false $ helm install -f config.yaml mysql stable/mysql NAME: mysql LAST DEPLOYED: Fri Dec 6 17:46:56 2019 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: MySQL can be accessed via port 3306 on the following DNS name from within your cluster: mysql.default.svc.cluster.local release 安装成功后查看对应的Pod信息 $ kubectl get pod -l release=mysql NAME READY STATUS RESTARTS AGE mysql-ddd798f48-gnrzd 0/1 PodInitializing 0 119s $ kubectl describe pod mysql-ddd798f48-gnrzd ...... Environment: MYSQL_ROOT_PASSWORD: \u003cset to the key 'mysql-root-password' in secret 'mysql'\u003e Optional: false MYSQL_PASSWORD: \u003cset to the key 'mysql-password' in secret 'mysql'\u003e Optional: false MYSQL_USER: user0 MYSQL_DATABASE: user0db ...... 可以看到环境变量 MYSQL_USER=user0，MYSQL_DATABASE=user0db 的值和我们上面配置的值是一致的 在安装过程中，有两种方法可以传递配置数据： –values（或者 -f）：指定一个 YAML 文件来覆盖 values 值，可以指定多个值，最后边的文件优先 –set：在命令行上指定覆盖的配置 ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:3:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Helm"],"content":"更多安装方式 helm install 命令可以从多个源进行安装： chart 仓库（类似于上面我们提到的） 本地 chart 压缩包（helm install foo-0.1.1.tgz） 本地解压缩的 chart 目录（helm install foo path/to/foo） 在线的 URL（helm install fool https://example.com/charts/foo-1.2.3.tgz） ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:4:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Helm"],"content":"升级和回滚 当新版本的 chart 包发布的时候，或者当你要更改 release 的配置的时候，你可以使用 helm upgrade 命令来操作。升级需要一个现有的 release，并根据提供的信息对其进行升级。因为 Kubernetes charts 可能很大而且很复杂，Helm 会尝试以最小的侵入性进行升级，它只会更新自上一版本以来发生的变化： $ helm upgrade -f config.yaml mysql stable/mysql Release \"mysql\" has been upgraded. Happy Helming! NAME: mysql LAST DEPLOYED: Fri Dec 6 21:06:11 2019 NAMESPACE: default STATUS: deployed REVISION: 2 ... 查看升级后的新设置是否生效 $ helm get values mysql USER-SUPPLIED VALUES: mysqlDatabase: user0db mysqlPassword: user0pwd mysqlRootPassword: passw0rd mysqlUser: user0 persistence: enabled: false 另外如生产基本上是只替换镜像tag $ sudo helm get values nms-grafana -n zcm9 USER-SUPPLIED VALUES: global: nodeSelector: aik: zcm9 repository: 10.10.192.220:52800 nms-activemq: image: tag: C_20220628200611 nms-grafana: image: tag: C_20220726192751-v9.0.1 ... 查看当前release 当前版本信息以及查看某个release 的历史 $ sudo helm -n zcm9 ls NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION minio zcm9 1 2022-08-11 19:27:49.792207699 +0800 CST failed minio-10.0.4 2022.1.8 nms-activemq zcm9 1 2022-11-09 13:31:42.996290693 +0800 CST deployed nms-activemq-0.1.0 9.0.44 nms-grafana zcm9 29 2023-05-04 20:34:46.578214434 +0800 CST deployed nms-grafana-0.1.0 aik ... $ sudo helm -n zcm9 history nms-grafana REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 20 Thu May 4 19:52:14 2023 superseded nms-grafana-0.1.0 aik Upgrade complete 21 Thu May 4 19:53:14 2023 superseded nms-grafana-0.1.0 aik Upgrade complete 22 Thu May 4 19:58:59 2023 superseded nms-grafana-0.1.0 aik Upgrade complete ... 回滚 # 上面可知本地安装的应用nms-grafana 迭代至了版本29,如果要回滚至指定版本可以通过一下方式 $ helm -n zcm9 rollback nms-grafana 21 ","date":"2022-07-21","objectID":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:5:0","tags":["Helm"],"title":"Helm 生产实践记录","uri":"/helm%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/"},{"categories":["Django"],"content":"Docker 是一个用于构建、运行和分发应用程序的平台。它允许您将应用程序及其所有依赖项打包到一个容器中，然后可以在任何安装了 Docker 的服务器上运行。 这使得 Docker 成为部署 Web 应用程序的理想选择，因为它可以轻松地将应用程序从一个环境移动到另一个环境，而无需担心任何兼容性问题。 另一方面，Django 是一个 Python Web 框架，可以轻松创建强大且可扩展的 Web 应用程序。 Django 提供了许多开箱即用的功能，例如用户身份验证系统、数据库抽象层和模板引擎。 这使得 Django 的入门变得容易，并且快速、轻松地构建复杂的 Web 应用程序。 Docker 化和部署 Django 应用程序是一个相对简单的过程。涉及的主要步骤是： 为您的 Django 应用程序创建 Dockerfile。 从 Dockerfile 构建 Docker 映像。 将Docker镜像部署到生产环境。 ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:0:0","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["Django"],"content":"准备 基于 Python 3.9、Django 3.2、docker 20.10.13 ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:1:0","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["Django"],"content":"软件安装 Docker Python3 ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:1:1","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["Django"],"content":"创建Django项目 pip install django==3.2 django-admin startproject django-demo 这行代码将会在当前目录下创建一个 simplesite 目录 让我们看看 startproject 创建了些什么: django-demo/ manage.py django-demo/ __init__.py settings.py urls.py asgi.py wsgi.py 这些目录和文件的用处是： 最外层的 mysite/ 根目录只是你项目的容器， 根目录名称对 Django 没有影响，你可以将它重命名为任何你喜欢的名称。 manage.py: 一个让你用各种方式管理 Django 项目的命令行工具。 里面一层的 mysite/ 目录包含你的项目，它是一个纯 Python 包。 mysite/init.py：一个空文件，告诉 Python 这个目录应该被认为是一个 Python 包。 mysite/settings.py：Django 项目的配置文件。 mysite/urls.py：Django 项目的 URL 声明，就像你网站的“目录”。 mysite/asgi.py：作为你的项目的运行在 ASGI 兼容的 Web 服务器上的入口。 mysite/wsgi.py：作为你的项目的运行在 WSGI 兼容的Web服务器上的入口。 如果你的当前目录不是外层的 mysite 目录的话，请切换到此目录，然后运行下面的命令： $ python manage.py runserver ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:1:2","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["Django"],"content":"Dockerfile # 使用官方Python运行时作为父镜像 FROM python:3.9-alpine LABEL maintainer=\"lushuan2071@126.com\" # 设置 python 环境变量 ENV PYTHONUNBUFFERED 1 # 设置工作目录 WORKDIR /app # 将代码复制到容器中 COPY . /app # 添加 pip 清华镜像源 RUN pip install pip -U -i https://pypi.tuna.tsinghua.edu.cn/simple # 安装依赖 RUN pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple # 暴露端口 EXPOSE 8000 # 运行Django应用 CMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"] 构建镜像 docker build -t mydjangoapp:v1.0 . -f Dockerfile 运行容器 docker run --name mydjangoapp -p 8000:8000 -d mydjangoapp:v1.0 构建记录 # docker build -t mydjangoapp:v1.0 . -f Dockerfile Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. STEP 1/7: FROM localhost/python:3.9-alpine STEP 2/7: LABEL maintainer=\"lushuan2071@126.com\" --\u003e bf70fc48b6d STEP 3/7: WORKDIR /app --\u003e 45b9db8d767 STEP 4/7: COPY . /app --\u003e 7df5ef439ea STEP 5/7: RUN pip install --no-cache-dir -r requirements.txt Collecting asgiref==3.8.1 Downloading asgiref-3.8.1-py3-none-any.whl (23 kB) Collecting Django==3.2.25 Downloading Django-3.2.25-py3-none-any.whl (7.9 MB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 139.1 kB/s eta 0:00:00 Collecting mysql-connector-python==8.4.0 Downloading mysql_connector_python-8.4.0-py2.py3-none-any.whl (565 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 565.1/565.1 kB 119.1 kB/s eta 0:00:00 Collecting sqlparse==0.5.0 Downloading sqlparse-0.5.0-py3-none-any.whl (43 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 124.3 kB/s eta 0:00:00 Collecting typing_extensions==4.11.0 Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB) Collecting tzdata==2024.1 Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.4/345.4 kB 136.4 kB/s eta 0:00:00 Collecting pytz Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 kB 182.8 kB/s eta 0:00:00 Installing collected packages: pytz, tzdata, typing_extensions, sqlparse, mysql-connector-python, asgiref, Django Successfully installed Django-3.2.25 asgiref-3.8.1 mysql-connector-python-8.4.0 pytz-2024.1 sqlparse-0.5.0 typing_extensions-4.11.0 tzdata-2024.1 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv [notice] A new release of pip is available: 23.0.1 -\u003e 24.1.2 [notice] To update, run: pip install --upgrade pip --\u003e dd901d2c952 STEP 6/7: EXPOSE 8000 --\u003e f1884d94f8e STEP 7/7: CMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"] COMMIT mydjangoapp:v1.0 --\u003e 9253897f89f Successfully tagged localhost/mydjangoapp:v1.0 9253897f89fa29c91253cdb28e8494453dd2cf330b66a51968ec817e35faf19b # docker images|grep django Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. localhost/mydjangoapp v1.0 9253897f89fa 13 seconds ago 100 MB # docker run --name mydjangoapp -p 8000:8000 -d mydjangoapp:v1.0 Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. 49c212881ab19348ccb12f492a7e6f32f545efeff67daf27df6e2b9c7bf074ee # # docker ps Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 49c212881ab1 localhost/mydjangoapp:v1.0 python manage.py ... 6 seconds ago Up 7 seconds 0.0.0.0:8000-\u003e8000/tcp mydjangoapp # docker ps Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 49c212881ab1 localhost/mydjangoapp:v1.0 python manage.py ... 8 seconds ago Up 8 seconds 0.0.0.0:8000-\u003e8000/tcp mydjangoapp ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:2:0","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["Django"],"content":"参考 Python 镜像的全方位指南 原创 ","date":"2022-07-20","objectID":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/:3:0","tags":["Django"],"title":"Django 应用容器化构建","uri":"/django-%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E6%9E%84%E5%BB%BA/"},{"categories":["linux"],"content":"监控系统资源和进程工具 top 命令 快捷键及使用场景 1：显示每个 CPU 核心的详细信息。当你需要查看系统中每个 CPU 核心的负载和使用情况时，可以按下 1 键。 E：切换累计模式（Cumulative Mode）。在累计模式下，CPU 使用率和内存占用等指标会显示所有进程的累计值而不是单个进程的值。 M：按内存使用排序。按下 M 键后，top 命令会按照内存使用量的大小对进程进行排序，并显示最高的内存使用进程。 P：按 CPU 使用排序。按下 P 键后，top 命令会按照 CPU 使用率的大小对进程进行排序，并显示最高的 CPU 使用进程。 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:0:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"内存 内存相关名词释义 1）Working Set Size(WSS)是指一个app保持正常运行所须的内存。比如一个应用在初始阶段申请了100G主存，在实际正常运行时每秒只需要50M，那么这里的50M就是一个WSS 2）RES：resident memory usage。常驻内存 3）RSS Resident Set Size 实际使用物理内存，（包含共享库占用的内存） 4）CACHE，是一种特殊的内存，因为主内存速度不够快，用少量的特别快的但特别昂贵的内存来做缓存加速,就是cache。简单来说，buffer是即将要被写入磁盘的，而cache是被从磁盘中读出来的。 5）SWAP 交换区间，内存不够用使用磁盘充当内存 查看占用内存较高的10个进程 ps -aux | sort -k4nr | head 查看进程占用的内存大小 # 通过端口获取进程号 netstat -anp|grep 9100 tcp6 0 0 :::9100 :::* LISTEN 5505/node_exporter # 通过进程id获取进程占用内存大小 cat /proc/5505/status|grep VmRSS VmRSS: 31500 kB 技巧\r注意：VmRSS对应的值就是物理内存占用\r","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:1:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"IO 查看磁盘io及传递状态 iostat -x 1 3 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:2:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"如何判断磁盘 io 性能达到瓶颈？ iostat 是一个用于监控系统磁盘IO使用情况的工具，可以显示每个磁盘的IO操作、IO延迟和数据吞吐量等信息。当磁盘IO达到瓶颈时，可以通过 iostat 来判断。 有以下几个指标可以帮助你判断磁盘IO是否达到瓶颈： %util：这是磁盘IO利用率的百分比，表示磁盘正在处理IO请求所占用的时间比例。当 %util 高于 80% 或 90% 时，磁盘IO可能已经达到瓶颈状态。 await：这是平均每个IO请求在队列中等待被处理的时间，表示系统平均IO响应时间。当 await 较高(通常大于 10ms)时，说明磁盘IO负载过重，也可能意味着磁盘IO已达到瓶颈。 svctm：这是平均每个IO请求的服务时间，表示磁盘处理IO请求的平均时间。当 svctm 较高时，系统处理IO请求的速度较慢，可能代表磁盘IO已经达到瓶颈状态。 总之，当磁盘IO利用率高、IO等待时间长或服务时间长时，磁盘IO可能已达到瓶颈状态。通常还需要综合考虑诸如系统性能需求、磁盘类型和配置等因素，才能确定是否对系统进行优化或升级。 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:2:1","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"查看磁盘io占用较高的几个进程 可以使用 iotop 命令来查看磁盘IO占用较高的几个进程 $ iotop -oP Total DISK READ : 577.97 K/s | Total DISK WRITE : 115.06 K/s Actual DISK READ: 64.22 K/s | Actual DISK WRITE: 1934.59 K/s PID PRIO USER DISK READ DISK WRITE SWAPIN IO\u003e COMMAND 574 be/4 root 577.97 K/s 0.00 B/s 0.00 % 8.68 % [xfsaild/dm-0] 73282 be/4 root 0.00 B/s 45.49 K/s 0.00 % 0.47 % influxd 53910 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.02 % [kworker/7:0] 55873 be/4 systemd- 0.00 B/s 2.68 K/s 0.00 % 0.02 % mysqld ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:2:2","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"监控进程使用情况 pidstat 是一个用于监控进程资源使用情况的工具，可以提供有关 CPU、内存、磁盘IO、网络和上下文切换等方面的统计信息。以下是 pidstat 常用命令及其使用场景： 1.查看特定进程的资源使用情况： pidstat -p 该命令可用于监控指定 PID 的进程的资源使用情况，包括 CPU 占用率、内存使用量、上下文切换次数、磁盘IO等。 2.实时监控整个系统中进程的资源使用情况： pidstat -r 该命令可实时显示所有进程的内存使用情况，包括虚拟内存大小、物理内存大小、共享内存大小等。 3.监控进程的CPU使用情况： pidstat -u 通过设置 和 参数，该命令可定期显示进程的 CPU 使用情况，包括用户空间和内核空间的 CPU 使用时间、CPU 使用百分比等。 pidstat 命令常用于性能分析和资源监控，可以帮助定位和解决系统性能问题。具体使用场景包括但不限于： 查找 CPU 密集型进程、监测内存泄漏、检测磁盘IO瓶颈、分析网络传输情况等。 最佳实践 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:3:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"手动清理缓存buffer/cache 1.清理pagecache(页面缓存) echo 1 \u003e /proc/sys/vm/drop_caches #或者 sysctl -w vm.drop_caches=1 2.清理目录缓存 echo 2 \u003e /proc/sys/vm/drop_caches #或者 sysctl -w vm.drop_caches=2 3.清理pagecache、dentries和inodes echo 3 \u003e /proc/sys/vm/drop_caches #或者 sysctl -w vm.drop_caches=3 上面三种方式都是临时释放缓存的方法，想要永久释放缓存，需要在/etc/sysctl.conf文件中配置： vm.drop_caches=1/2/3,然后sysctl -p生效即可 温馨提示： 上面操作在大多数情况下都不会对系统造成伤害，只会有助于释放不用的内存 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:4:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"查看僵尸进程并kill掉 查看 ps -ef | grep defunct kill kill -9 父进程号 在linux系统中，进程有如下几种状态，它们随时可能处于以上状态中的一种： D = 不可中断的休眠 I = 空闲 R = 运行中 S = 休眠 T = 被调度信号终止 t = 被调试器终止 Z = 僵尸状态 我们可以在命令终端中通过top命令来查看系统进程和它的当前状态。 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:4:1","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"查看进程占用的的物理内存大小指令 cat /proc/`ps -ef|grep grafana|grep -v grep|awk '{print $2}'`/status |grep VmRSS 指令分解 # 通过关键词xxx确认进程id，进程关键词如grafana $ ps -ef|grep grafana|grep -v grep|awk '{print $2}' 118581 # 通过进程标识查看服务器物理内存占用 $ cat /proc/118581/status |grep VmRSS VmRSS: 100788 kB # 动态查看进程资源占用 top -p 118581 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:5:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["linux"],"content":"查看TCP连接数 netstat -n | awk '/^tcp/ {++state[$NF]} END {for(key in state) print key,\"\\t\",state[key]}' 总结 Linux 服务器性能资源排查思路 在排查 Linux 服务器性能问题时，可以按照以下思路进行操作： 1.监测系统资源使用情况： 使用命令 top 或 htop 实时监视 CPU、内存和交换空间的使用情况。 使用命令 df 查看磁盘空间使用情况。 使用命令 free 查看内存使用情况。 使用命令 iostat 查看磁盘IO使用情况。 使用命令 sar 查看系统整体的资源利用率。 2.检查进程和服务： 使用命令 ps 或 top 查看正在运行的进程和它们的资源占用情况。 使用命令 systemctl status 检查服务的状态。 3.定位高负载进程： 使用命令 top 或 htop 查看 CPU 使用率最高的进程，并观察其 PID 和资源消耗情况。 使用命令 pidstat 监测指定 PID 的进程的资源使用情况。 4.分析日志信息： 查看系统日志（如 /var/log/messages）以了解系统运行期间发生的错误或异常情况。 查看应用程序日志，特别是与性能相关的日志，以寻找可能的瓶颈或错误。 5.检查网络连接和流量： 使用命令 netstat 或 ss 查看网络连接状态。 使用命令 iftop 或 nethogs 实时监测网络流量和使用情况。 6.进行性能调优： 调整系统内核参数，如文件句柄数、内存分配等，以提高性能。 优化关键应用程序的配置，如数据库、Web 服务器等。 7.使用性能分析工具： 使用工具如 perf、strace、tcpdump 等进行更深入的性能分析和故障排查。 这些步骤可以帮助你定位服务器的性能问题，并找出潜在的瓶颈或异常。根据具体的问题，你可能需要进一步深入研究和分析，以找到解决方案。同时，及时备份数据是必要的，以免在调优过程中发生数据丢失或其他意外。 ","date":"2022-06-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/:6:0","tags":["linux"],"title":"Linux 系统性能问题定位","uri":"/linux%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"categories":["prometheus"],"content":"监控策略 目标 服务发现模式 监控方法 数据源 从集群各节点kubelet组件中获取节点kubelet的基本运行状态的监控指标 node 白盒监控 kubelet 从集群各节点kubelet内置的cAdvisor中获取，节点中运行的容器的监控指标 node 白盒监控 kubelet 从部署到各个节点的Node Exporter中采集主机资源相关的运行资源 node 白盒监控 node exporter 对于内置了Promthues支持的应用，需要从Pod实例中采集其自定义监控指标 pod 白盒监控 custom pod 获取API Server组件的访问地址，并从中获取Kubernetes集群相关的运行监控指标 endpoints 白盒监控 api server 获取集群中Service的访问地址，并通过Blackbox Exporter获取网络探测指标 service 黑盒监控 blackbox exporter 获取集群中Ingress的访问信息，并通过Blackbox Exporter获取网络探测指标 ingress 黑盒监控 blackbox exporter ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:1:0","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"k8s 插件采集指标说明 包含夜莺指标做横向对比参考 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:0","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"Cadvisor 指标说明 cpu 指标 指标名 含义 prometheus metrics或计算方式 说明 cpu.util 容器cpu使用占其申请的百分比 sum (rate (container_cpu_usage_seconds_total[1m])) by( container) /( sum (container_spec_cpu_quota) by(container) /100000) * 100 0-100的范围 cpu.idle 容器cpu空闲占其申请的百分比 100 - cpu.util 0-100的范围 cpu.user 容器cpu用户态使用占其申请的百分比 sum (rate (container_cpu_user_seconds_total[1m])) by( container) /( sum (container_spec_cpu_quota) by(container) /100000) * 100 0-100的范围 cpu.sys 容器cpu内核态使用占其申请的百分比 sum (rate (container_cpu_sys_seconds_total[1m])) by( container) /( sum (container_spec_cpu_quota) by(container) /100000) * 100 0-100的范围 cpu.cores.occupy 容器cpu使用占用机器几个核 rate(container_cpu_usage_seconds_total[1m]) 0到机器核数上限,结果为1就是占用1个核 cpu.spec.quota 容器的CPU配额 container_spec_cpu_quota 为容器指定的CPU个数*100000 cpu.throttled.util 容器CPU执行周期受到限制的百分比 未录入 0-100的范围 cpu.periods 容器生命周期中度过的cpu周期总数 counter型无需计算 使用rate/increase 查看 cpu.throttled.periods 容器生命周期中度过的受限的cpu周期总数 counter型无需计算 使用rate/increase 查看 cpu.throttled.time 容器被节流的总时间 ) counter型无需计算 单位(纳秒 mem 指标 夜莺指标名 含义 prometheus metrics或计算方式 说明 mem.bytes.total 容器的内存限制 无需计算 单位byte 对应pod yaml中resources.limits.memory mem.bytes.used 当前内存使用情况，包括所有内存，无论何时访问 container_memory_rss + container_memory_cache + kernel memory 单位byte mem.bytes.used.percent 容器内存使用率 container_memory_usage_bytes/container_spec_memory_limit_bytes *100 范围0-100 mem.bytes.workingset 容器真实使用的内存量，也是limit限制时的 oom 判断依据 container_memory_max_usage_bytes \u003e container_memory_usage_bytes \u003e= container_memory_working_set_bytes \u003e container_memory_rss 单位byte mem.bytes.workingset.percent 容器真实使用的内存量百分比 container_memory_working_set_bytes/container_spec_memory_limit_bytes *100 范围0-100 mem.bytes.cached 容器cache内存量 container_memory_cache 单位byte mem.bytes.rss 容器rss内存量 container_memory_rss 单位byte mem.bytes.swap 容器cache内存量 container_memory_swap 单位byte filesystem \u0026\u0026 disk.io 指标 夜莺指标名 含义 prometheus metrics或计算方式 说明 disk.bytes.total 容器可以使用的文件系统总量 container_fs_limit_bytes (单位：字节) disk.bytes.used 容器已经使用的文件系统总量 container_fs_usage_bytes (单位：字节) disk.bytes.used.percent 容器文件系统使用百分比 container_fs_usage_bytes/container_fs_limit_bytes *100 范围0-100 disk.io.read.bytes 容器io.read qps rate(container_fs_reads_bytes_total)[1m] (单位：bps) disk.io.write.bytes 容器io.write qps rate(container_fs_write_bytes_total)[1m] (单位：bps) network 指标 夜莺指标名 含义 prometheus metrics或计算方式 说明 net.in.bytes 容器网络接收数据总数 rate(container_network_receive_bytes_total)[1m] (单位：bytes/s) net.out.bytes 容器网络积传输数据总数） rate(container_network_transmit_bytes_total)[1m] (单位：bytes/s) net.in.pps 容器网络接收数据包pps rate(container_network_receive_packets_total)[1m] (单位：p/s) net.out.pps 容器网络发送数据包pps rate(container_network_transmit_packets_total)[1m] (单位：p/s) net.in.errs 容器网络接收数据错误数 rate(container_network_receive_errors_total)[1m] (单位：bytes/s) net.out.errs 容器网络发送数据错误数 rate(container_network_transmit_errors_total)[1m] (单位：bytes/s) net.in.dropped 容器网络接收数据包drop pps rate(container_network_receive_packets_dropped_total)[1m] (单位：p/s) net.out.dropped 容器网络发送数据包drop pps rate(container_network_transmit_packets_dropped_total)[1m] (单位：p/s) container_network_{tcp,udp}_usage_total 默认不采集是因为 –disable_metrics=tcp, udp ,因为开启cpu压力大 system 指标 夜莺指标名 含义 prometheus metrics或计算方式 说明 sys.ps.process.count 容器中running进程个数 container_processes (单位：个) sys.ps.thread.count 容器中进程running线程个数 container_threads (单位：个) sys.fd.count.used 容器中打开文件描述符个数 container_file_descriptors (单位：个) sys.fd.soft.ulimits 容器中root process Soft ulimit container_ulimits_soft (单位：个) sys.socket.count.used 容器中打开套接字个数 container_sockets (单位：个) sys.task.state 容器中task 状态分布 container_tasks_state (单位：个) ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:1","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"kube-apiserver metrics 指标说明 指标名 类型 含义 说明 apiserver_request_total counter 对APIServer不同请求的计数。 apiserver_request_duration_seconds_sum gauge 统计APIServer客户端对APIServer的访问时延。对APIServer不同请求的时延分布。 apiserver_request_duration_seconds_count gauge 请求延迟记录数 计算平均延迟:apiserver_request_duration_seconds_sum/apiserver_request_duration_seconds_count apiserver_admission_controller_admission_duration_seconds_bucket Gauge 准入控制器（Admission Controller）的处理延时。标签包括准入控制器名字、操作（CREATE、UPDATE、CONNECT等）、API资源、操作类型（validate或admit）和请求是否被拒绝（true或false）。 apiserver_admission_webhook_admission_duration_seconds_bucket Gauge 准入Webhook（Admission Webhook）的处理延时。标签包括准入控制器名字、操作（CREATE、UPDATE、CONNECT等）、API资源、操作类型（validate或admit）和请求是否被拒绝（true或false）。 apiserver_admission_webhook_admission_duration_seconds_count Counter 准入Webhook（Admission Webhook）的处理请求统计。标签包括准入控制器名字、操作（CREATE、UPDATE、CONNECT等）、API资源、操作类型（validate或admit）和请求是否被拒绝（true或false）。 apiserver_response_sizes_sum counter 请求响应大小记录和 apiserver_response_sizes_count counter 请求响应大小记录数 authentication_attempts counter 认证尝试数 authentication_duration_seconds_sum counter 认证耗时记录和 authentication_duration_seconds_count counter 认证耗时记录数 apiserver_tls_handshake_errors_total counter tls握手失败计数 apiserver_client_certificate_expiration_seconds_sum gauge 证书过期时间总数 apiserver_client_certificate_expiration_seconds_count gauge 证书过期时间记录个数 apiserver_client_certificate_expiration_seconds_bucket gauge 证书过期时间分布 apiserver_current_inflight_requests gauge APIServer当前处理的请求数。包括ReadOnly和Mutating两种 apiserver_current_inqueue_requests gauge 是一个表向量， 记录最近排队请求数量的高水位线 apiserver请求限流 apiserver_flowcontrol_current_executing_requests gauge 记录包含执行中（不在队列中等待）请求的瞬时数量 APF api的QOS APIPriorityAndFairness apiserver_flowcontrol_current_inqueue_requests gauge 记录包含排队中的（未执行）请求的瞬时数量 workqueue_adds_total counter wq 入队数 workqueue_retries_total counter wq retry数 workqueue_longest_running_processor_seconds gauge wq中最长运行时间 workqueue_queue_duration_seconds_sum gauge wq中等待延迟记录和 workqueue_queue_duration_seconds_count gauge wq中等待延迟记录数 workqueue_work_duration_seconds_sum gauge wq中处理延迟记录和 workqueue_work_duration_seconds_count gauge wq中处理延迟记录数 up Gauge 服务可用性，1 表示服务可用，0 表示服务不可用 关键指标： $interval 表示间隔时间，例如 5m $quantile 0 ≤ 值 ≤ 1，用于计算当前样本数据值的分布情况，当值为 0.5 时，即表示找到当前样本数据中的中位数 名称 PromQL 说明 API QPS sum (irate(apiserver_request_total[$interval])) APIServer总QPS 读请求成功率 sum(irate(apiserver_request_total{code=~“20.*\",verb=~“GET|LIST”}[$interval]))/sum(irate(apiserver_request_total{verb=~“GET|LIST”}[$interval])) APIServer读请求成功率。 写请求成功率 sum(irate(apiserver_request_total{code=~“20.*\",verb!~“GET|LIST|WATCH|CONNECT”}[$interval]))/sum(irate(apiserver_request_total{verb!~“GET|LIST|WATCH|CONNECT”}[$interval])) APIServer写请求成功率。 在处理读请求数量 sum(apiserver_current_inflight_requests{request_kind=“readOnly”}) 所有 APIServer 当前在处理读请求数量; 不加 sum() 显示每个 apiserver 在处理的读请求数量 在处理写请求数量 sum(apiserver_current_inflight_requests{request_kind=“mutating”}) APIServer当前在处理写请求数量（老版本 k8s requestKind） GET读请求时延 histogram_quantile($quantile, sum(irate(apiserver_request_duration_seconds_bucket{verb=“GET”,resource!=”\",subresource!~“log|proxy”}[$interval])) by (pod, verb, resource, subresource, scope, le)) 展示GET请求的响应时间，维度包括APIServer Pod、Verb(GET)、Resources（例如Configmaps、Pods、Leases等）、Scope（范围例如Namespace级别、Cluster级别）。 LIST读请求时延 histogram_quantile($quantile, sum(irate(apiserver_request_duration_seconds_bucket{verb=“LIST”}[$interval])) by (pod_name, verb, resource, scope, le)) 展示LIST请求的响应时间，维度包括APIServer Pod、Verb(GET)、Resources（例如Configmaps、Pods、Leases等）、Scope（范围例如Namespace级别、Cluster级别）。 写请求时延 histogram_quantile($quantile, sum(irate(apiserver_request_duration_seconds_bucket{verb!~“GET|WATCH|LIST|CONNECT”}[$interval])) by (cluster, pod_name, verb, resource, scope, le)) 展示Mutating请求的响应时间，维度包括APIServer Pod、Verb(GET)、Resources（例如Configmaps、Pods、Leases等）、Scope（范围例如Namespace级别、Cluster级别）。 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:2","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"etcd metrics 指标说明 指标名 类型 含义 说明 etcd_db_total_size_in_bytes gauge db物理文件大小 etcd_object_counts gauge etcd对象按种类计数 etcd_request_duration_seconds_sum gauge etcd请求延迟记录和 etcd_request_duration_seconds_count gauge etcd请求延迟记录数 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:3","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"kube-scheduler 指标说明 指标名 类型 含义 说明 scheduler_e2e_scheduling_duration_seconds_sum gauge 端到端调度延迟记录和 scheduler_e2e_scheduling_duration_seconds_count gauge 端到端调度延迟记录数 scheduler_pod_scheduling_duration_seconds_sum gauge 调度延迟记录和 分析次数 scheduler_pod_scheduling_duration_seconds_count gauge 调度延迟记录数 scheduler_pending_pods gauge 调度队列pending pod数 scheduler_queue_incoming_pods_total counter 进入调度队列pod数 scheduler_scheduling_algorithm_duration_seconds_sum gauge 调度算法延迟记录和 scheduler_scheduling_algorithm_duration_seconds_count gauge 调度算法延迟记录数 scheduler_pod_scheduling_attempts_sum gauge 成功调度一个pod 的尝试次数记录和 scheduler_pod_scheduling_attempts_count gauge 成功调度一个pod 的尝试次数记录数 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:4","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"coredns 指标说明 指标名 类型 含义 说明 coredns_dns_requests_total counter 解析请求数 A记录，AAAA记录，other记录 coredns_dns_responses_total counter 解析响应数 NOERROR，NXDOMAIN，REFUSED coredns_cache_entries gauge 缓存记录数 成功或失败 coredns_cache_hits_total counter 缓存命中数 成功或失败 coredns_cache_misses_total counter 缓存未命中数 成功或失败 coredns_dns_request_duration_seconds_sum gauge 解析延迟记录和 coredns_dns_request_duration_seconds_count gauge 解析延迟记录数 coredns_dns_response_size_bytes_sum gauge 解析响应大小记录和 coredns_dns_response_size_bytes_count gauge 解析响应大小记录数 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:5","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"kube-stats-metrics 指标说明 pod metrics 指标名 类型 含义 kube_pod_status_phase gauge pod状态统计:Pending，Succeeded，Failed，Running，Unknown kube_pod_container_status_waiting counter pod处于waiting状态，值为1代表waiting kube_pod_container_status_waiting_reason gauge pod处于waiting状态原因：ContainerCreating，CrashLoopBackOff pod启动崩溃,再次启动然后再次崩溃，CreateContainerConfigError，ErrImagePull，ImagePullBackOff，CreateContainerError，InvalidImageName kube_pod_container_status_terminated gauge pod处于terminated状态，值为1代表terminated kube_pod_container_status_terminated_reason gauge pod处于terminated状态原因：OOMKilled，Completed，Error，ContainerCannotRun，DeadlineExceeded，Evicted kube_pod_container_status_restarts_total counter pod中的容器重启次数 kube_pod_container_resource_requests_cpu_cores gauge pod容器cpu limit kube_pod_container_resource_requests_memory_bytes gauge pod容器mem limit(单位:字节) deployment metrics 指标名 类型 含义 kube_deployment_status_replicas gauge dep中的pod num kube_deployment_status_replicas_available gauge dep中的 可用pod num kube_deployment_status_replicas_unavailable gauge dep中的 不可用pod num daemonSet metrics 指标名 类型 含义 kube_daemonset_status_number_available gauge ds 可用数 kube_daemonset_status_number_unavailable gauge ds 不可用数 kube_daemonset_status_number_ready gauge ds ready数 kube_daemonset_status_number_misscheduled gauge 未经过调度运行ds的节点数 kube_daemonset_status_current_number_scheduled gauge ds目前运行节点数 kube_daemonset_status_desired_number_scheduled gauge 应该运行ds的节点数 daemonSet metrics 指标名 类型 含义 kube_statefulset_status_replicas gauge ss副本总数 kube_statefulset_status_replicas_current gauge ss当前副本数 kube_statefulset_status_replicas_updated gauge ss已更新副本数 kube_statefulset_replicas gauge ss目标副本数 Job metrics 指标名 类型 含义 kube_job_status_active gauge job running pod数 kube_job_status_succeeded gauge job 成功 pod数 kube_job_status_failed gauge job 失败 pod数 kube_job_complete gauge job 是否完成 kube_job_failed gauge job 是否失败 CronJob metrics 指标名 类型 含义 kube_cronjob_status_active gauge job running pod数 kube_cronjob_spec_suspend gauge =1代表 job 被挂起 kube_cronjob_next_schedule_time gauge job 下次调度时间 kube_cronjob_status_last_schedule_time gauge job 下次调度时间 PersistentVolume metrics 指标名 类型 含义 kube_persistentvolume_capacity_bytes gauge pv申请大小 kube_persistentvolume_status_phase gauge pv状态:Pending，Available，Bound，Released，Failed PersistentVolumeClaim metrics 指标名 类型 含义 kube_persistentvolumeclaim_resource_requests_storage_bytes gauge pvc request大小 kube_persistentvolumeclaim_status_phase gauge pvc状态:Lost，Bound，Pending ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:6","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["prometheus"],"content":"node metrics 指标说明 指标名 类型 含义 kube_node_status_condition gauge condition:NetworkUnavailable，MemoryPressure，DiskPressure，PIDPressure，Ready kube_node_status_allocatable_cpu_cores gauge 节点可以分配cpu核数 kube_node_status_allocatable_memory_bytes gauge 节点可以分配内存总量(单位：字节) kube_node_spec_taint gauge 节点污点情况 kube_node_status_capacity_memory_bytes gauge 节点内存总量(单位：字节) kube_node_status_capacity_cpu_cores gauge 节点cpu核数 kube_node_status_capacity_pods gauge 节点可运行的pod总数 ","date":"2022-06-29","objectID":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/:2:7","tags":["prometheus"],"title":"Prometheus 监控k8s 组件指标梳理","uri":"/prometheus%E7%9B%91%E6%8E%A7k8s%E6%8C%87%E6%A0%87%E5%92%8C%E7%9B%91%E6%8E%A7%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5/"},{"categories":["Kubernetes"],"content":"理解ConfigMap 为了能够准确和深刻理解Kubernetes ConfigMap的功能和价值，我们需要从Docker说起。我们知道，Docker通过将程序、依赖库、数据及配置文件“打包固化”到一个不变的镜像文件中的做法，解决了应用的部署的难题，但这同时带来了棘手的问题，即配置文件中的参数在运行期如何修改的问题。我们不可能在启动Docker容器后再修改容器里的配置文件，然后用新的配置文件重启容器里的用户主进程。为了解决这个问题，Docker提供了两种方式： 在运行时通过容器的环境变量来传递参数； 通过Docker Volume将容器外的配置文件映射到容器内。 这两种方式都有其优势和缺点，在大多数情况下，后一种方式更合适我们的系统，因为大多数应用通常从一个或多个配置文件中读取参数。但这种方式也有明显的缺陷：我们必须在目标主机上先创建好对应的配置文件，然后才能映射到容器里。上述缺陷在分布式情况下变得更为严重，因为无论采用哪种方式，写入（修改）多台服务器上的某个指定文件，并确保这些文件保持一致，都是一个很难完成的目标。此外，在大多数情况下，我们都希望能集中管理系统的配置参数，而不是管理一堆配置文件。针对上述问题，Kubernetes给出了一个很巧妙的设计实现，如下所述。 首先，把所有的配置项都当作keyvalue字符串，当然value可以来自某个文本文件，比如配置项password=123456、user=root、host=192.168.8.4用于表示连接FTP服务器的配置参数。这些配置项可以作为Map表中的一个项，整个Map的数据可以被持久化存储在Kubernetes的Etcd数据库中，然后提供API以方便Kubernetes相关组件或客户应用CRUD操作这些数据，上述专门用来保存配置参数的Map就是Kubernetes ConfigMap资源对象。 ","date":"2022-06-13","objectID":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/:1:0","tags":["Kubernetes"],"title":"Kubernetes ConfigMap多文件挂载至同一个pod内目录实践","uri":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"痛点改进 接下来，Kubernetes提供了一种内建机制，将存储在etcd中的ConfigMap通过Volume映射的方式变成目标Pod内的配置文件，不管目标Pod被调度到哪台服务器上，都会完成自动映射。进一步地，如果ConfigMap中的key/value数据被修改，则映射到Pod中的“配置文件”也会随之自动更新。于是，Kubernetes ConfigMap就成了分布式系统中最为简单（使用方法简单，但背后实现比较复杂）且对应用无侵入的配置中心。 ","date":"2022-06-13","objectID":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/:2:0","tags":["Kubernetes"],"title":"Kubernetes ConfigMap多文件挂载至同一个pod内目录实践","uri":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/"},{"categories":["Kubernetes"],"content":"实践 需求 将一个configmap 内的两个文件挂载在一个pod的不同目录下 /app/conf/grafanaoracle.properties /app/start-timeshift.sh 创建一个configmap apiVersion: v1 data: grafanaoracle.properties: | name=kevin nage=19 start-timeshift.sh: | #!/bin/sh cd /app/influxdb-timeshift-proxy INFLUXDB=nms-influxdb:8086 /usr/bin/npm run start kind: ConfigMap metadata: labels: app.kubernetes.io/managed-by: Helm name: test-config 创建一个 deploy apiVersion: apps/v1 kind: Deployment metadata: labels: zcm-app: test-configmap name: test-configmap spec: replicas: 1 selector: matchLabels: zcm-app: test-configmap template: metadata: labels: zcm-app: test-configmap spec: containers: - env: - name: CLOUD_APP_NAME value: paas_test-configmap image: nginx imagePullPolicy: IfNotPresent name: test-configmap ports: - containerPort: 9999 name: http-oracle protocol: TCP volumeMounts: # 关键配置 开始 - mountPath: /app/start-timeshift.sh name: properties readOnly: true subPath: start-timeshift.sh - mountPath: /app/conf/grafanaoracle.properties name: properties readOnly: true subPath: grafanaoracle.properties dnsPolicy: ClusterFirst restartPolicy: Always volumes: - configMap: defaultMode: 420 items: - key: grafanaoracle.properties # key 和 path 同名即可 path: grafanaoracle.properties - key: start-timeshift.sh path: start-timeshift.sh name: test-configmap name: properties # 关键配置 结束 ","date":"2022-06-13","objectID":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/:3:0","tags":["Kubernetes"],"title":"Kubernetes ConfigMap多文件挂载至同一个pod内目录实践","uri":"/kubernetes-configmap%E5%A4%9A%E6%96%87%E4%BB%B6%E6%8C%82%E8%BD%BD%E8%87%B3%E5%90%8C%E4%B8%80%E4%B8%AApod%E5%86%85%E7%9B%AE%E5%BD%95%E5%AE%9E%E8%B7%B5/"},{"categories":["Django"],"content":"Django 模板语法 模板引擎是一种可以让开发者把服务端数据填充到html网页中完成渲染效果的技术。它实现了把前端代码和服务端代码分离的作用，让项目中的业务逻辑代码和数据表现代码分离，让前端开发者和服务端开发者可以更好的完成协同开发。 信息\r静态网页：页面上的数据都是写死的，万年不变 动态网页：页面上的数据是从后端动态获取的（比如后端获取当前时间；后端获取数据库数据然后传递给前端页面） Django框架中内置了web开发领域非常出名的一个DjangoTemplate模板引擎（DTL）。DTL官方文档 要在django框架中使用模板引擎把视图中的数据更好的展示给客户端，需要完成3个步骤： 信息\r在项目配置文件中指定保存模板文件的模板目录。一般模板目录都是设置在项目根目录或者主应用目录下。 在视图中基于django提供的渲染函数绑定模板文件和需要展示的数据变量 在模板目录下创建对应的模板文件，并根据模板引擎内置的模板语法，填写输出视图传递过来的数据。 配置模板目录：在当前项目根目录下创建了模板目录templates. 然后在settings.py, 模板相关配置，找到TEMPLATES配置项，填写DIRS设置模板目录。 # 模板引擎配置 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [ BASE_DIR / \"templates\", # 路径拼接 ], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] ","date":"2022-05-20","objectID":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/:1:0","tags":["Django"],"title":"Django 模板语法","uri":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/"},{"categories":["Django"],"content":"简单案例 为了方便接下里的演示内容，我这里创建创建一个新的子应用myapp python manage.py startapp myapp settings.py，注册子应用，代码： INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'myapp', # 开发者创建的子应用，这填写就是子应用的导包路径 ] 总路由加载子应用路由,urls.py，代码： from django.contrib import admin from django.urls import path,include urlpatterns = [ path('admin/', admin.site.urls), # path(\"路由前缀/\", include(\"子应用目录名.路由模块\")) path(\"users/\", include(\"users.urls\")), path(\"tem/\", include(\"myapp.urls\")), ] 在子应用目录下创建urls.py子路由文件，代码如下： \"\"\"子应用路由\"\"\" from django.urls import path, re_path from . import views urlpatterns = [ path(\"index\", views.index), ] myapp.views.index，代码： from django.shortcuts import render def index(request): # 要显示到客户端的数据 name = \"hello DTL!\" # return render(request, \"模板文件路径\",context={字典格式：要在客户端中展示的数据}) return render(request, \"index.html\",context={\"name\":name}) ","date":"2022-05-20","objectID":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/:1:1","tags":["Django"],"title":"Django 模板语法","uri":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/"},{"categories":["Django"],"content":"render函数内部本质 django render函数内部本质\rfrom django.shortcuts import render from django.template.loader import get_template from django.http.response import HttpResponse def index(request): name = \"hello world!\" # 1. 初始化模板,读取模板内容,实例化模板对象 # get_template会从项目配置中找到模板目录，我们需要填写的参数就是补全模板文件的路径 template = get_template(\"myapp/index.html\") # 2. 识别context内容, 和模板内容里面的标记[标签]替换,针对复杂的内容,进行正则的替换 context = {\"name\": name} content = template.render(context, request) # render中完成了变量替换成变量值的过程，这个过程使用了正则。 print(content) # 3. 通过response响应对象,把替换了数据的模板内容返回给客户端 return HttpResponse(content) # 上面代码的简写,直接使用 django.shortcuts.render # return render(request, \"index.html\",context={\"name\":name}) # return render(request,\"index.html\", locals()) # data = {} # data[\"name\"] = \"xiaoming\" # data[\"message\"] = \"你好！\" # return render(request,\"index.html\", data) DTL模板文件与普通html文件的区别在哪里？ DTL模板文件是一种带有特殊语法的HTML文件，这个HTML文件可以被Django编译，可以传递参数进去，实现数据动态化。在编译完成后，生成一个普通的HTML文件，然后发送给客户端。 开发中，我们一般把开发中的文件分2种，分别是静态文件和动态文件。 技巧\r静态文件，数据保存在当前文件，不需要经过任何处理就可以展示出去。普通html文件，图片，视频，音频等这一类文件叫静态文件。 动态文件，数据并不在当前文件，而是要经过服务端或其他程序进行编译转换才可以展示出去。 编译转换的过程往往就是使用正则或其他技术把文件内部具有特殊格式的变量转换成真实数据。 动态文件，一般数据会保存在第三方存储设备，如数据库中。django的模板文件，就属于动态文件。 ","date":"2022-05-20","objectID":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/:1:2","tags":["Django"],"title":"Django 模板语法","uri":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/"},{"categories":["Django"],"content":"模板语法 变量渲染（深度查询、过滤器） {{val}} {{val|filter_name:参数}} 标签 嵌套和继承 变量渲染之深度查询 def index(request): name = \"root\" age = 13 sex = True lve = [\"swimming\", \"shopping\", \"coding\", \"game\"] bookinfo = {\"id\": 1, \"price\": 9.90, \"name\": \"Django 3天入门到挣扎\", } book_list = [ {\"id\": 10, \"price\": 9.90, \"name\": \"Django 3天入门到挣扎\", }, {\"id\": 11, \"price\": 19.90, \"name\": \"Django 7天入门到垂死挣扎\", }, ] return render(request, 'index.html', locals()) 模板代码，templates/index.html： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003ename={{ name }}\u003c/p\u003e \u003cp\u003e{{ age }}\u003c/p\u003e \u003cp\u003e{{ sex }}\u003c/p\u003e \u003cp\u003e列表成员\u003c/p\u003e \u003cp\u003e{{ lve }}\u003c/p\u003e \u003cp\u003e{{ lve.0 }}\u003c/p\u003e \u003cp\u003e{{ lve | last }}\u003c/p\u003e \u003cp\u003e字典成员\u003c/p\u003e \u003cp\u003eid={{ bookinfo.id }}\u003c/p\u003e \u003cp\u003eprice={{ bookinfo.price }}\u003c/p\u003e \u003cp\u003ename={{ bookinfo.name }}\u003c/p\u003e \u003cp\u003e复杂列表\u003c/p\u003e \u003cp\u003e{{ book_list.0.name }}\u003c/p\u003e \u003cp\u003e{{ book_list.1.name }}\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 变量渲染之内置过滤器 语法： {{obj|过滤器名称:过滤器参数}} 内置过滤器 过滤器 用法 代码 last 获取列表/元组的最后一个成员 {{liast | last}} first 获取列表/元组的第一个成员 {{list|first}} length 获取数据的长度 {{list | length}} defualt 当变量没有值的情况下, 系统输出默认值, {{str|default=“默认值”}} safe 让系统不要对内容中的html代码进行实体转义 {{htmlcontent| safe}} upper 字母转换成大写 {{str | upper}} lower 字母转换成小写 {{str | lower}} title 每个单词首字母转换成大写 {{str | title}} date 日期时间格式转换 `{{ value cut 从内容中截取掉同样字符的内容 {{content | cut:“hello”}} list 把内容转换成列表格式 {{content | list}} add 加法 {{num| add}} filesizeformat 把文件大小的数值转换成单位表示 {{filesize | filesizeformat}} join 按指定字符拼接内容 {{list| join(\"-\")}} random 随机提取某个成员 {list | random}} slice 按切片提取成员 {{list | slice:\":-2\"}} truncatechars 按字符长度截取内容 {{content | truncatechars:30}} truncatewords 按单词长度截取内容 同上 过滤器的使用 视图代码 myapp.views.py; def index(request): \"\"\"过滤器 filters\"\"\" content = \"Django template\" # content1 = '\u003cscript\u003ealert(1);\u003c/script\u003e' from datetime import datetime now = datetime.now() content2= \"hello wrold!\" return render(request,\"myapp/index.html\",locals()) # 模板代码,myapp/templates/index.html: {{ content | safe }} {{ content1 | safe }} {# 过滤器本质就是函数,但是模板语法不支持小括号调用,所以需要使用:号分割参数 #} \u003cp\u003e{{ now | date:\"Y-m-d H:i:s\" }}\u003c/p\u003e \u003cp\u003e{{ conten1 | default:\"默认值\" }}\u003c/p\u003e {# 一个数据可以连续调用多个过滤器 #} \u003cp\u003e{{ content2 | truncatechars:6 | upper }}\u003c/p\u003e 自定义过滤器 虽然官方已经提供了许多内置的过滤器给开发者,但是很明显,还是会有存在不足的时候。例如:希望输出用户的手机号码时, 13912345678 —-» 139*****678，这时我们就需要自定义过滤器。要声明自定义过滤器并且能在模板中正常使用,需要完成2个前置的工作: # 1. 当前使用和声明过滤器的子应用必须在setting.py配置文件中的INSTALLED_APPS中注册了!!! INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'myapp', ] # 2. 自定义过滤器函数必须被 template.register进行装饰使用. # 而且过滤器函数所在的模块必须在templatetags包里面保存 # 在myapp子应用下创建templatetags包[必须包含__init__.py], 在包目录下创建任意py文件 # myapp.templatetags.my_filters.py代码: from django import template register = template.Library() # 自定义过滤器 @register.filter(\"mobile\") def mobile(content): return content[:3]+\"*****\"+content[-3:] # 3. 在需要使用的模板文件中顶部使用load标签加载过滤器文件my_filters.py并调用自定义过滤器 # myapp.views.py,代码: def index(request): \"\"\"自定义过滤器 filters\"\"\" moblie_number = \"13312345678\" return render(request,\"index2.html\",locals()) # templates/index2.html,代码: \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e {{ moblie_number| mobile }} \u003c/body\u003e \u003c/html\u003e 标签 if 视图代码,myapp.views.py: def index(request): name = \"xiaoming\" age = 19 sex = True lve = [\"swimming\", \"shopping\", \"coding\", \"game\"] user_lve = \"sleep\" bookinfo = {\"id\": 1, \"price\": 9.90, \"name\": \"python3天入门到挣扎\", } book_list = [ {\"id\": 10, \"price\": 9.90, \"name\": \"python3天入门到挣扎\", }, {\"id\": 11, \"price\": 19.90, \"name\": \"python7天入门到垂死挣扎\", }, ] return render(request, 'index.html', locals()) 模板代码,templates/index.html，代码： 路由代码： \"\"\"子应用路由\"\"\" from django.urls import path, re_path from . import views urlpatterns = [ # .... path(\"index\", views.index), ] for 视图代码, myapp.views.py: def index7(request): book_list1 = [ {\"id\": 11, \"name\": \"python基础入门\", \"price\": 130.00}, {\"id\": 17, \"name\": \"Go基础入门\", \"price\": 230.00}, {\"id\": 23, \"name\": \"PHP基础入门\", \"price\": 330.00}, {\"id\": 44, \"name\": \"Java基础入门\", \"price\": ","date":"2022-05-20","objectID":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/:1:3","tags":["Django"],"title":"Django 模板语法","uri":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/"},{"categories":["Django"],"content":"静态文件 开发中在开启了debug模式时，django可以通过配置，允许用户通过对应的url地址访问django的静态文件。 setting.py，代码： STATIC_ROOT = BASE_DIR / 'static' STATIC_URL = '/static/' # django模板中，可以引用{{STATIC_URL}}变量避免把路径写死。 总路由，urls.py，代码： from django.views.static import serve as serve_static urlpatterns = [ path('admin/', admin.site.urls), # 对外提供访问静态文件的路由，serve_static 是django提供静态访问支持的映射类。依靠它，客户端才能访问到django的静态文件。 path(r'static/\u003cpath:path\u003e', serve_static, {'document_root': settings.STATIC_ROOT},), ] 注意\r项目上线以后，关闭debug模式时，django默认是不提供静态文件的访问支持，项目部署的时候，我们会通过收集静态文件使用nginx这种web服务器来提供静态文件的访问支持。\r","date":"2022-05-20","objectID":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/:1:4","tags":["Django"],"title":"Django 模板语法","uri":"/django-%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95/"},{"categories":["Kubernetes"],"content":"背景 项目现场通过 kubeadm 部署一套 k8s 临时环境 版本是v1.22, 因为是临时环境，部署方式是一主两从的模式， 部署后十天客户直接将主节点的内存进行了扩容，导致现场的应用服务无法访问。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"现象 打开访问应用门户，提示 nginx 网关访问报错 503 Service Temporarily Unavailable ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"定位 通过 kubectl 查看 pod 状态发现很多应用是 CrashLoopBackOff,猜测是系统基础组件出现异常,查看应用日志提示 jdbc 连接 MySQL 异常，查看MySQL 日志发现端口52306被占用。 排查为 apiserver和etcd连接的随机端口占用了52306 # sudo netstat -nap|grep 52306 tcp 0 0 127.0.0.1:52306 127.0.0.1:2379 ESTABLISHED 30166/kube-apiserve tcp 0 0 127.0.0.1:2379 127.0.0.1:52306 ESTABLISHED 23788/etcd ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"问题处理 确认端口占用情况：执行 sudo netstat -lnp | grep 命令查看指定端口是否被占用 释放端口：如果该端口已被占用，可以通过 sudo lsof -i: 命令查找占用端口的进程 临时处理，pod 重建 kill 掉 etcd 的静态 pod，端口可能还是会重新被占用 永久处理，主机 k8s.conf 预留端口 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:4:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"保留预留端口 $ cat /etc/sysctl.d/k8s.conf net.ipv4.ip_forward = 1 kernel.core_pattern=/tmp/zcore/core.%h~%e fs.inotify.max_user_watches = 1048576 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_local_reserved_ports = 52000-52999 net.ipv4.ip_local_reserved_ports新增预留端口配置，保留端口范围不被占用，告诉内核保留端口范围从 52000 到 52999，以便这些端口不会被普通应用程序占用 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:4:1","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"/etc/sysctl.d/k8s.conf 配置项说明 在 Kubernetes 1.22 版本的 /etc/sysctl.d/k8s.conf 配置文件中，可能包含以下一些配置项： 1、 net.bridge.bridge-nf-call-ip6tables： 含义：控制是否将 IPv6 数据包传递给 iptables 的 netfilter 框架进行处理。如果设置为 1，则表示启用；如果设置为 0，则表示禁用。 默认值：1 2、 net.bridge.bridge-nf-call-iptables： 含义：控制是否将数据包传递给 iptables 的 netfilter 框架进行处理。如果设置为 1，则表示启用；如果设置为 0，则表示禁用。 默认值：1 3、 net.ipv4.ip_forward： 含义：控制 Linux 内核是否允许 IP 数据包转发。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 4、 net.ipv4.conf.all.forwarding： 含义：控制所有网络接口的 IP 转发功能。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 5、 net.ipv4.conf.default.forwarding： 含义：控制默认网络接口的 IP 转发功能。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 以上是常见的示例配置项和默认值，但实际的配置项和默认值可能会根据操作系统和 Kubernetes 版本而有所不同。在实际使用中，请根据文档和操作系统的要求进行正确配置。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:5:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"问题现象 生产环境无法访问，这里主要是梳理遇到问题应该有的一个排查思路 portal-exception\r","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"问题排查 登录节点查看namespace 下各pod状态 kubectl get pod -o wide -n prod 发现portal cmdb application等均处于异常状态 由于portal启动会依赖cmdb 优先查看cmdb的日志，发现报错连接redis异常 查看redis状态 处于正常状态 kubectl get pod -o wide -n prod|grep redis 进入cmdb 容器进行redis 连接测试 telnet redis 6379 发现解析域名 redis 有问题 因此怀疑coredns存在问题 查看 coredns 状态 kubectl get pod -o wide -n kube-system|grep coredns 发现pod处于terminating以及pending 由于coredns配置有节点选择器，只会调度到k8s master节点 此外对master做了taint ,—-防止其它的各种系统组件向Master调度，导致master资源受压缩。（此污点对已经调度在该节点的pod不会产生驱逐，但是新建pod的将无法调度） $ kubectl describe node 10.10.xxx Name: 10.10.xxx Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=10.10.xxx kubernetes.io/os=linux kubernetes.io/role=master zcm.role=k8s Annotations: node.alpha.kubernetes.io/ttl: 0 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sat, 25 Mar 2023 10:08:15 +0800 Taints: scheduler=custom:NoSchedule Unschedulable: false 导致coredns pending 临时处理,将节点选择器移除 coredns调度成功，启动完成 portal cmdb等依赖redis的服务自行恢复 生产环境恢复访问 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"问题分析 问题发生前，集成对10.10.xxx等k8s master机器进行了迁移操作，主机发生了重启。 因此coredns发生重新调度，此时由于节点选择器以及taint的缘故，coredns无法成功调度启动， 进而影响了容器内对redis的解析 ，导致依赖redis的容器不断重启，生产环境无法访问。 后续对各个k8s集群的coredns配置了对污点的容忍，避免类似问题的再次发生。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"背景 statefulset 通过nfs 动态创建pv，发现无法创建成功 ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["Kubernetes"],"content":"报错日志 Warning FailedMount 2m50s (x6 over 6m4s) kubelet Unable to attach or mount volumes: unmounted volumes=[data], unattached volumes=[kube-api-access-8p8wf data]: error processing PVC kube-logging/data-es-cluster-0: PVC is not bound 通过报错日志可以看的出来pvc 无法绑定pv,通过命令查看pvc创建成功，pv 则没有进行创建 StatefulSet 挂载 NFS 存储卷时出现了问题,导致 PVC 没有被成功绑定到 PV的原因 常见原因有: PVC 和 PV 不匹配 PVC 的 storage class、访问模式、大小资源请求等需要和 PV 定义一致,否则不会被匹配到合适的 PV。 NFS 服务器配置问题 NFS 服务器需要正常启动、导出共享目录,并且 Kubernetes 节点能够访问到 NFS 服务器。 RBAC 鉴权问题 Kubernetes 节点上的 kubelet 需要有获取、挂载 PV 的权限。 NFS Client 配置问题 Kubernetes 节点上需要安装 NFS Client,并且配置可以访问 NFS 服务器。 StatefulSet 配置错误 StatefulSet 的 volumeClaimTemplates 需要与 PVC 的定义相匹配。 存储卷读写权限问题 存储卷需要有读写权限,避免因权限问题无法挂载。 ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["Kubernetes"],"content":"nfs 在kubernetes中动态创建pv和版本的关系 在早期的 Kubernetes 版本中(如 v1.11 之前),NFS provisioner 并不包含在默认部署中,这会导致通过 NFS 存储类无法动态创建 PV。 从 Kubernetes v1.11 开始,NFS 动态供应功能成为了默认部署的一部分,但也需要进行额外的配置,主要步骤包括: 安装 NFS 客户端组件 部署 NFS 动态供应器 external-provisioner 创建 StorageClass,指定 nfs 作为 provisioner 创建 PersistentVolumeClaim, 引用该 StorageClass 此时,NFS 供应器就可以根据 PVC 的请求动态创建 PV 来绑定 PVC。 所以简单来说,Kubernetes 低版本中需要手动安装和配置 NFS 动态供应器; 高版本中已内置但也需要显式配置才能启用该功能。正确配置后就可以通过 NFS StorageClass 来动态创建 PV。 这里的高版本指的是v1.20 之后，在 kube-apiserver 的启动参数中不移除 API 对象中的 selfLink 字段。 selfLink 是 Kubernetes 中每个 API 对象的一个字段,用于表示对象自身的 URL 地址 从 Kubernetes 1.20 版本开始,该字段默认被移除了。但可以通过设置 RemoveSelfLink=false 来保留该字段 原因是 selfLink 字段已很少被用到,但删去后可能会影响部分老版本的客户端。所以提供了这个特性开关来向后兼容 一般来说,除非确实需要兼容老版本客户端,否则不建议保留 selfLink 字段 显式开启方式： $ vi /etc/kubernetes/manifests/kube-apiserver.yaml .... spec: containers: - command: - kube-apiserver - --feature-gates=RemoveSelfLink=false ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["linux"],"content":"netstat netstat是一个常用的命令行网络工具，用于显示与网络连接、路由表和网络接口相关的信息。以下是一些常用的netstat命令： netstat -tunlp：显示所有TCP和UDP端口的监听情况，以及对应的进程信息。 netstat -tuln：显示所有TCP端口的监听情况，包括本地地址、外部地址和状态。 netstat -a：显示所有活动的网络连接，包括监听和非监听状态。 netstat -r：显示路由表，包括目标地址、网关、子网掩码和接口。 netstat -s：显示网络统计信息，包括传输的数据包数量、错误数量和丢失数量等。 netstat -i：显示网络接口信息，包括接口名称、MAC地址、IP地址和状态等。 netstat -c：持续输出网络连接的信息，每隔一段时间刷新一次。 ","date":"2022-03-29","objectID":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/:1:0","tags":["linux"],"title":"Linux 网络排障","uri":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"},{"categories":["linux"],"content":"sar sar（System Activity Reporter）是一个性能监控工具，它可以提供系统资源使用情况的历史数据。以下是一些常用的sar命令和相应的使用场景： sar -u：显示CPU使用情况。 使用场景：了解系统CPU的平均负载、用户空间CPU使用率、系统空间CPU使用率，以及等待I/O的CPU使用率。 sar -r：显示内存使用情况。 使用场景：查看主要的内存指标，如总内存、可用内存、内存利用率、缓存和缓冲区。 sar -n DEV：显示网络接口的数据传输情况。 使用场景：监测网络流量、带宽使用情况，识别网络瓶颈。 sar -q：显示系统负载情况。 使用场景：通过观察平均负载、运行队列长度和就绪进程数，了解系统性能和负载情况。 sar -b：显示系统的I/O使用情况。 使用场景：监测磁盘IO的情况，包括块读写次数、块传输速率，查找磁盘性能问题。 sar -W：显示系统交换空间的使用情况。 使用场景：了解交换空间的使用情况，识别系统内存不足导致的交换瓶颈。 sar -d：显示块设备的I/O统计信息。 使用场景：查看块设备（硬盘）的读写操作、传输速率和请求队列长度。 ","date":"2022-03-29","objectID":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/:2:0","tags":["linux"],"title":"Linux 网络排障","uri":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"},{"categories":["linux"],"content":"Example 统计sockets连接新 sar -n SOCK $ sar -n SOCK 1 1 Linux 4.4.115-1.el7.elrepo.x86_64 (chm) 2022年05月20日 _x86_64_ (12 CPU) 14时05分40秒 totsck tcpsck udpsck rawsck ip-frag tcp-tw 14时05分41秒 7725 76 5 0 0 642 平均时间: 7725 76 5 0 0 642 totsck 当前被使用的socket总数 tcpsck 当前正在被使用的TCP的socket总数 udpsck 当前正在被使用的UDP的socket总数 rawsck 当前正在被使用于RAW的skcket总数 if-frag 当前的IP分片的数目 tcp-tw TCP套接字中处于TIME-WAIT状态的连接数量 这些sar命令可用于监控系统资源的使用情况，帮助诊断性能问题和优化系统配置。您可以通过调整命令的参数来获取特定的监控数据，并结合其他工具和命令进行综合分析 ","date":"2022-03-29","objectID":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/:2:1","tags":["linux"],"title":"Linux 网络排障","uri":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"},{"categories":["linux"],"content":"telnet telnet是一个用于远程登录和管理远程主机的网络协议和工具。以下是一些常用的telnet命令和相应的使用场景： 1.telnet host：连接到指定的远程主机。 使用场景：远程登录到其他计算机，进行命令行管理和操作。 2.telnet host port：连接到指定主机的特定端口。 使用场景：检查特定服务的可用性，如通过telnet测试SMTP服务器是否能够连接。 3.Ctrl + ]：进入telnet控制台。 使用场景：在telnet会话中，按下Ctrl + ]键后，可以进入控制台，执行一些附加功能，如终止会话、更改设置等。 4.send string：发送字符串到远程主机。 使用场景：在telnet会话中，可以使用send命令发送特定的字符串至远程主机，用于模拟用户输入等情景。 5.display或toggle options：显示或切换选项状态。 使用场景：在telnet会话中，可以使用这两个命令查看或切换当前会话的选项状态，例如回显、行编辑等。 6.quit：退出当前telnet会话。 使用场景：在完成telnet会话后，使用该命令退出并关闭连接。 telnet命令可以用于远程登录和管理远程主机，但由于安全性较差，已逐渐被SSH等更安全的协议取代。在实际应用中，建议使用更加安全的远程连接方法，如SSH（Secure Shell）。 ","date":"2022-03-29","objectID":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/:3:0","tags":["linux"],"title":"Linux 网络排障","uri":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"},{"categories":["linux"],"content":"ss ss（Socket Statistics）是一个Linux系统中用于显示当前活动套接字（socket）信息的命令。它可以提供更详细和全面的套接字统计数据。以下是一些常用的ss命令和相应的使用场景： 1.ss -t：显示TCP套接字信息。 使用场景：查看当前系统上的TCP连接信息，包括本地地址和端口、远程地址和端口、连接状态等。 2.ss -u：显示UDP套接字信息。 使用场景：查看当前系统上的UDP连接信息，包括本地地址和端口、远程地址和端口等。 3.ss -l：显示监听套接字信息。 使用场景：查看当前系统上正在监听的套接字信息，包括监听的协议、本地地址和端口等。 4.ss -p：显示套接字及其关联进程信息。 使用场景：查看每个套接字对应的关联进程的详细信息，包括进程ID、用户、命令等。 5.ss -n：以数字形式展示套接字信息。 使用场景：显示IP地址和端口号时不进行反向解析，加快输出速度。 6.ss -s：显示套接字统计摘要(包含IPv6)。 使用场景：显示系统级别的套接字统计信息，包括打开的套接字数、活动连接数、侦听套接字数等。 7.ss -o：显示定时器相关信息。 使用场景：查看系统中的定时器事件相关信息，如计时器名称、超时时间、重复间隔等。 这些ss命令可用于监控和诊断网络连接和套接字的状态，帮助定位网络问题并进行性能调优。在实际应用中，可以结合其他命令和工具（如grep、netstat等）进行更深入的分析和排查。 ","date":"2022-03-29","objectID":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/:4:0","tags":["linux"],"title":"Linux 网络排障","uri":"/linux%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"},{"categories":["Python"],"content":"介绍 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:1:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"Python 简介 摘要\rPython 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。 Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。 Python 是一种解释型语言： 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。 Python 是交互式语言： 这意味着，您可以在一个Python提示符，直接互动执行写你的程序。 Python 是面向对象语言: 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。 Python 是初学者的语言：Python 对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到 WWW 浏览器再到游戏。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:1:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"Python 特点 信息\r易于学习：Python有相对较少的关键字，结构简单，和一个明确定义的语法，学习起来更加简单。 易于阅读：Python代码定义的更清晰。 易于维护：Python的成功在于它的源代码是相当容易维护的。 一个广泛的标准库：Python的最大的优势之一是丰富的库，跨平台的，在UNIX，Windows和Macintosh兼容很好。 互动模式：互动模式的支持，您可以从终端输入执行代码并获得结果的语言，互动的测试和调试代码片断。 可移植：基于其开放源代码的特性，Python已经被移植（也就是使其工作）到许多平台。 可扩展：如果你需要一段运行很快的关键代码，或者是想要编写一些不愿开放的算法，你可以使用C或C++完成那部分程序，然后从你的Python程序中调用。 数据库：Python提供所有主要的商业数据库的接口。 GUI编程：Python支持GUI可以创建和移植到许多系统调用。 可嵌入: 你可以将Python嵌入到C/C++程序，让你的程序的用户获得\"脚本化\"的能力。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:1:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"安装 Python 3 Python最新源码，二进制文档，新闻资讯等可以在Python的官网查看到： Python官网：https://www.python.org/ 你可以在以下链接中下载 Python 的文档，你可以下载 HTML、PDF 和 PostScript 等格式的文档。 Python文档下载地址：https://www.python.org/doc/ ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:2:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"Window 平台安装 Python 以下为在 Window 平台上安装 Python 的简单步骤： 打开 WEB 浏览器访问https://www.python.org/downloads/windows/ ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:2:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"设置开发环境 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:3:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"使用虚拟环境（virtualenv 或 venv）命令行 venv，Python官方用于创建虚拟环境的工具。 cd xxx/xxx/crm python3.9 -m venv ddd python3.7 -m venv xxxx python3.7 -m venv /xxx/xxx/xxx/xx/ppp virtualenv 【推荐】 pip install virtualenv cd /xxx/xx/ virtualenv ddd --python=python3.9 # or virtualenv /xxx/xx/ddd --python=python3.9 激活虚拟环境 win cd F:\\envs\\crm\\Scripts activate mac source /虚拟环境目录/bin/activate ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:3:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"通过配置编辑器（如 VS Code、PyCharm 等） 通过配置编辑器如Pycharm 创建虚拟环境是一种更方便的方式，原理还是通过命令行，通过界面化操作会直观一些 virtualenv\r","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:3:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"基础语法 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:4:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"变量 变量规则 变量只能包含字母、数字和下划线 变量不可以包含空格，可以使用下划线来分隔单词 不要将python 关键字作为变量 变量名应该简短具有描述性 慎用小写字母i和大写字母O，会被误看出数字1和0 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:4:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"控制流（if、for、while） 条件语句 if 条件语句 if 判断条件： 执行语句…… else： 执行语句…… 多条件匹配时 if 判断条件1: 执行语句1…… elif 判断条件2: 执行语句2…… elif 判断条件3: 执行语句3…… else: 执行语句4…… 循环语句 while 循环语句 while 判断条件： 执行语句…… Gif 演示 Python while 语句执行过程 loop-over-python-list-animation\rfor循环语句 for iterating_var in sequence: statements(s) 流程图 python_for_loop\r实例 #!/usr/bin/python # -*- coding: UTF-8 -*- for letter in 'Python': # 第一个实例 print('当前字母 :', letter) fruits = ['banana', 'apple', 'mango'] for fruit in fruits: # 第二个实例 print('当前水果 :', fruit) print(\"Good bye!\") 通过序列索引迭代 #!/usr/bin/python # -*- coding: UTF-8 -*- fruits = ['banana', 'apple', 'mango'] for index in range(len(fruits)): print('当前水果 :', fruits[index]) print(\"Good bye!\") ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:4:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"函数 函数定义和调用 def greet_user(): # 1. 关键字def \"\"\"显示简单的问候语，文档字符串注释，方便生成程序文档\"\"\" # 2. 注释 print(\"hello\") # 3. 函数体 greet_user() # 4. 调用 参数 实参和形参 def greet_user(username): pass username=\"xiao hua\" greet_user(username) # 形参 greet_user(\"xiao hua\") # 实参 默认参数 # 可写函数说明 def printinfo(name, age=35): \"\"\"打印任何传入的字符串\"\"\" print(\"Name: \", name) print(\"Age \", age) return # 调用printinfo函数 printinfo(age=50, name=\"miki\") printinfo(name=\"miki\") ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:4:3","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"异常处理 捕捉异常可以使用try/except语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 try….except…else 以下为简单的try….except…else的语法： try: \u003c语句\u003e #运行别的代码 except \u003c名字\u003e： \u003c语句\u003e #如果在try部份引发了'name'异常 except \u003c名字\u003e，\u003c数据\u003e: \u003c语句\u003e #如果引发了'name'异常，获得附加的数据 else: \u003c语句\u003e #如果没有异常发生 try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 实例 下面是简单的例子，它打开一个文件，在该文件中的内容写入内容，且并未发生异常： #!/usr/bin/python # -*- coding: UTF-8 -*- try: fh = open(\"testfile\", \"w\") fh.write(\"这是一个测试文件，用于测试异常!!\") except IOError: print(\"Error: 没有找到文件或读取文件失败\") else: print(\"内容写入文件成功\") fh.close() 输出结果 $ python test.py 内容写入文件成功 $ cat testfile # 查看写入的内容 这是一个测试文件，用于测试异常!! try-finally 语句 try-finally 语句无论是否发生异常都将执行最后的代码。 try: \u003c语句\u003e finally: \u003c语句\u003e #退出try时总会执行 raise 示例 #!/usr/bin/python # -*- coding: UTF-8 -*- try: fh = open(\"testfile\", \"w\") fh.write(\"这是一个测试文件，用于测试异常!!\") finally: print(\"Error: 没有找到文件或读取文件失败\") 输出 $ python test.py Error: 没有找到文件或读取文件失败 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:4:4","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"数据结构 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:5:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"列表（List） 列表式什么? 列表由一系列按特定顺序排列的元素组成 Python有6个序列的内置类型，但最常见的是列表和元组。 序列都可以进行的操作包括索引，切片，加，乘，检查成员。 此外，Python已经内置确定序列的长度以及确定最大和最小的元素的方法。 列表是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现。 列表的数据项不需要具有相同的类型 创建一个列表，只要把逗号分隔的不同的数据项使用方括号括起来即可。如下所示： list1 = ['physics', 'chemistry', 1997, 2000] list2 = [1, 2, 3, 4, 5 ] list3 = [\"a\", \"b\", \"c\", \"d\"] 列表操作 list1 = ['physics', 'chemistry', 1997, 2000] list2 = [1, 2, 3, 4, 5, 6, 7] # 1. 访问列表中的值 print(\"list1[0]: \", list1[0]) print(\"list2[1:5]: \", list2[1:5]) # 2. 更新列表 list2.append(8) print(list2) # [1, 2, 3, 4, 5, 6, 7, 8] # 3. 删除列表中的值，通过下标索引删除 del list2[1] print(list2) # [1, 3, 4, 5, 6, 7, 8] 列表脚本操作符 Python 表达式 结果 描述 len([1, 2, 3]) 3 长度 [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] 组合 [‘Hi!’] * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 重复 3 in [1, 2, 3] True 元素是否存在于列表中 for x in [1, 2, 3]: print x, 1 2 3 迭代 Python列表函数\u0026方法 序号 函数 1 cmp(list1, list2) 比较两个列表的元素 2 len(list) 列表元素个数 3 max(list) 返回列表元素最大值 4 min(list) 返回列表元素最小值 5 list(seq) 将元组转换为列表 Python包含以下方法: 序号 方法 1 list.append(obj) 在列表末尾添加新的对象 2 list.count(obj) 统计某个元素在列表中出现的次数 3 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4 list.index(obj) 从列表中找出某个值第一个匹配项的索引位置 5 list.insert(index, obj) 将对象插入列表 6 list.pop([index=-1]) 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7 list.remove(obj) 移除列表中某个值的第一个匹配项 8 list.reverse() 反向列表中元素 9 list.sort(cmp=None, key=None, reverse=False) 对原列表进行排序 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:5:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"元组（Tuple） Python的元组与列表类似，不同之处在于元组的元素不能修改。 元组使用小括号，列表使用方括号。 元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。 示例 tup1 = ('physics', 'chemistry', 1997, 2000) tup2 = (1, 2, 3, 4, 5 ) tup3 = \"a\", \"b\", \"c\", \"d\" # 空元组 tup1 = () # 元组中只包含一个元素时，需要在元素后面添加逗号 tup1 = (50,) 元组操作 #!/usr/bin/python tup1 = ('physics', 'chemistry', 1997, 2000) tup2 = (1, 2, 3, 4, 5, 6, 7) # 1. 访问元组 print(\"tup1[0]: \", tup1[0]) print(\"tup2[1:5]: \", tup2[1:5]) # 2. 修改元组(元组中的元素值是不允许修改的，但我们可以对元组进行连接组合) # 以下修改元组元素操作是非法的。 #tup2[0] = 100 # 创建一个新的元组 tup3 = tup1 + tup2 print(tup3) # 3. 删除元组(元组中的元素值是不允许删除的，但我们可以使用del语句来删除整个元组) print(tup2) del tup2 print(\"After deleting tup2 : \") print(tup2) 元组运算符 与字符串一样，元组之间可以使用 + 号和 * 号进行运算。这就意味着他们可以组合和复制，运算后会生成一个新的元组。 Python 表达式 结果 描述 len((1, 2, 3)) 3 计算元素个数 (1, 2, 3) + (4, 5, 6) (1, 2, 3, 4, 5, 6) 连接 (‘Hi!’,) * 4 (‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’) 复制 3 in (1, 2, 3) True 元素是否存在 for x in (1, 2, 3): print x, 1 2 3 迭代 元组索引，截取 因为元组也是一个序列，所以我们可以访问元组中的指定位置的元素，也可以截取索引中的一段元素，如下所示： 元组： L = ('spam', 'Spam', 'SPAM!') Python 表达式 结果 描述 L[2] ‘SPAM!’ 读取第三个元素 L[-2] ‘Spam’ 反向读取，读取倒数第二个元素 L[1:] (‘Spam’, ‘SPAM!’) 截取元素 元组内置函数 序号 方法及描述 1 cmp(tuple1, tuple2) 比较两个元组元素。 2 len(tuple) 计算元组元素个数。 3 max(tuple) 返回元组中元素最大值。 4 min(tuple) 返回元组中元素最小值。 5 tuple(seq) 将列表转换为元组。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:5:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"字典（Dictionary） 字典是另一种可变容器模型，且可存储任意类型对象。 字典的每个键值 key=\u003evalue 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示 d = {key1 : value1, key2 : value2 } 键一般是唯一的，如果重复最后的一个键值对会替换前面的，值不需要唯一。 字典操作 #!/usr/bin/python dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'} # 1. 访问字典 print(\"dict['Name']: \", dict['Name']) print(\"dict['Age']: \", dict['Age']) # 2. 修改字典 dict['Age'] = 8 # 更新 dict['School'] = \"CODEXY\" # 添加 print(\"dict['Age']: \", dict['Age']) print(\"dict['School']: \", dict['MIT']) # 3. 删除字典元素 del dict['Name'] # 删除键是'Name'的条目 dict.clear() # 清空词典所有条目 del dict # 删除词典 字典的两个特性 不允许同一个键出现两次。创建时如果同一个键被赋值两次，后一个值会被覆盖 键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行 字典内置函数\u0026方法 Python字典包含了以下内置函数： 序号 函数及描述 1 cmp(dict1, dict2) 比较两个字典元素。 2 len(dict) 计算字典元素个数，即键的总数。 3 str(dict) 输出字典可打印的字符串表示。 4 type(variable) 返回输入的变量类型，如果变量是字典就返回字典类型。 Python字典包含了以下内置方法： 序号 函数及描述 1 dict.clear() 删除字典内所有元素 2 dict.copy() 返回一个字典的浅复制 3 dict.fromkeys(seq[, val]) 创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值 4 dict.get(key, default=None) 返回指定键的值，如果值不在字典中返回default值 5 dict.has_key(key) 如果键在字典dict里返回true，否则返回false 6 dict.items() 以列表返回可遍历的(键, 值) 元组数组 7 dict.keys() 以列表返回一个字典所有的键 8 dict.setdefault(key, default=None) 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default 9 dict.update(dict2) 把字典dict2的键/值对更新到dict里 10 dict.values() 以列表返回字典中的所有值 11 pop(key[,default]) 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。 12 popitem() 随机返回并删除字典中的一对键和值。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:5:3","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"集合（Set） 在 Python 中，集合（Set）是一种无序且元素唯一的数据类型。它基于哈希表实现，因此支持高效的成员检测和删除操作。 创建集合 可以使用大括号 {} 或者 set() 构造函数来创建集合。 # 使用大括号创建集合 my_set = {1, 2, 3, 4, 5} # 使用 set() 构造函数创建集合 another_set = set([5, 6, 7, 8, 9]) 集合的特点 无序性：集合中的元素没有固定的顺序。 唯一性：集合中不允许包含重复的元素。 可变性：集合是可变的，可以添加或删除元素。 哈希性：集合中的元素必须是可哈希的，即不可变类型，如整数、浮点数、元组、字符串等。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:5:4","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"面向对象编程 Python从设计之初就已经是一门面向对象的语言，正因为如此，在Python中创建一个类和对象是很容易的。 面向对象技术简介 类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。 类变量：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 数据成员：类变量或者实例变量, 用于处理类及其实例对象的相关的数据。 方法重写：如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 局部变量：定义在方法中的变量，只作用于当前实例的类。 实例变量：在类的声明中，属性是用变量来表示的。这种变量就称为实例变量，是在类声明的内部但是在类的其他成员方法之外声明的。 继承：即一个派生类（derived class）继承基类（base 1. class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟\"是一个（is-a）“关系（例图，Dog是一个Animal）。 实例化：创建一个类的实例，类的具体对象。 方法：类中定义的函数。 对象：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:6:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"类和对象 创建类 class ClassName: '''类的帮助信息''' #类文档字符串 class_suite #类体 类的帮助信息可以通过ClassName.__doc__查看。 class_suite 由类成员，方法，数据属性组成。 示例 #!/usr/bin/python # -*- coding: UTF-8 -*- class Employee: '所有员工的基类' empCount = 0 def __init__(self, name, salary): self.name = name self.salary = salary Employee.empCount += 1 def displayCount(self): print(\"Total Employee %d\" % Employee.empCount) def displayEmployee(self): print(\"Name : \", self.name, \", Salary: \", self.salary) 创建类的实例对象 实例化类其他编程语言中一般用关键字 new，但是在 Python 中并没有这个关键字，类的实例化类似函数调用方式。 以下使用类的名称 Employee 来实例化，并通过 __init__ 方法接收参数。 \"创建 Employee 类的第一个对象\" emp1 = Employee(\"Zara\", 2000) \"创建 Employee 类的第二个对象\" emp2 = Employee(\"Manni\", 5000) Python 内置类属性 __dict__ : 类的属性（包含一个字典，由类的数据属性组成） __doc__ :类的文档字符串 __name__: 类名 __module__: 类定义所在的模块（类的全名是'__main__.className'，如果类位于一个导入模块mymod中，那么className.__module__ 等于 mymod） __bases__ : 类的所有父类构成元素（包含了一个由所有父类组成的元组） ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:6:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"类的继承 面向对象的编程带来的主要好处之一是代码的重用，实现这种重用的方法之一是通过继承机制。 通过继承创建的新类称为子类或派生类，被继承的类称为基类、父类或超类。 继承语法 class 派生类名(基类名) ... 在python中继承中的一些特点： 1、如果在子类中需要父类的构造方法就需要显示的调用父类的构造方法，或者不重写父类的构造方法。详细说明可查看：python 子类继承父类构造函数说明。 2、在调用基类的方法时，需要加上基类的类名前缀，且需要带上 self 参数变量。区别在于类中调用普通函数时并不需要带上 self 参数 3、Python 总是首先查找对应类型的方法，如果它不能在派生类中找到对应的方法，它才开始到基类中逐个查找。（先在本类中查找调用的方法，找不到才去基类中找）。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:6:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"模块和包 Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:7:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"模块的导入 模块定义好后，我们可以使用 import 语句来引入模块，语法如下： import module1[, module2[,... moduleN]] 比如要引用模块 math，就可以在文件最开始的地方用 import math 来引入。在调用 math 模块中的函数时，必须这样引用： 模块名.函数名 from…import 语句 Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下： from modname import name1[, name2[, ... nameN]] from…import* 语句 把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明： from modname import * ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:7:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"文件操作 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:8:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"打开和关闭文件 Python 提供了必要的函数和方法进行默认情况下的文件基本操作。你可以用 file 对象做大部分的文件操作。 open 函数 你必须先用Python内置的open()函数打开一个文件，创建一个file对象，相关的方法才可以调用它进行读写。 语法： file object = open(file_name [, access_mode][, buffering]) 各个参数的细节如下： file_name：file_name变量是一个包含了你要访问的文件名称的字符串值。 access_mode：access_mode决定了打开文件的模式：只读，写入，追加等。所有可取值见如下的完全列表。这个参数是非强制的，默认文件访问模式为只读(r)。 buffering:如果buffering的值被设为0，就不会有寄存。如果buffering的值取1，访问文件时会寄存行。如果将buffering的值设为大于1的整数，表明了这就是的寄存区的缓冲大小。如果取负值，寄存区的缓冲大小则为系统默认。 读写文件内容 不同模式打开文件的完全列表： 模式 描述 t 文本模式 (默认)。 x 写模式，新建一个文件，如果该文件已存在则会报错。 b 二进制模式。 + 打开一个文件进行更新(可读可写)。 U 通用换行模式（不推荐）。 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。 w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 下图很好的总结了这几种模式： file accessmode\r模式 r r+ w w+ a a+ 读 + + + + 写 + + + + + 创建 + + + + 覆盖 + + 指针在开始 + + + + 指针在结尾 + + ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:8:1","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"使用 with 语句处理文件 在 Python 中，with 语句用于管理代码块执行过程中的上下文环境，确保在进入和退出代码块时，资源的正确获取和释放。它通常与支持上下文管理协议（Context Management Protocol）的对象一起使用，如文件操作、数据库连接、网络连接等需要在使用后及时关闭或释放资源的情况。 with open('example.txt', 'r') as file: content = file.read() print(content) # 在退出 with 块后，文件会自动关闭，即使出现异常也能保证资源的释放 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:8:2","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"常用标准库 操作系统接口（os 模块） 文件路径操作（pathlib 模块） 时间和日期处理（datetime 模块） 正则表达式（re 模块） Python 常用模块和常用第三方模块示例 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:9:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"进阶话题 并发编程（多线程和多进程） 异步编程（asyncio 模块） 数据库访问（sqlite3、SQLAlchemy 等） ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:10:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"实际应用示例 简单的 Web 开发（使用 Flask 或 Django） 数据分析与可视化（使用 Pandas 和 Matplotlib） ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:11:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"资源推荐 官方文档链接 谷歌Python代码风格指南 中文翻译 30个Python常用极简代码，拿走就用 收藏 | 学习Python的11个顶级Github存储库 改善Python程序的91个建议 Django Django-中文 ","date":"2022-03-20","objectID":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/:12:0","tags":["Python"],"title":"Python3 快速上手指南","uri":"/python3-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"categories":["Python"],"content":"项目目录布局 project_name ├── docs │ ├── make.bat │ ├── Makefile │ └── source │ ├── conf.py │ └── index.rst ├── examples │ └── example.py ├── project_name │ └── package_name │ └── __init__.py │ ├── module1.py │ ├── module2.py │ ├── package1/ │ │ ├── __init__.py │ │ ├── module3.py │ │ ├── module4.py │ │ └── ... ├── tests │ └── __init__.py ├── .gitignore ├── LICENSE.txt ├── MANIFEST.in ├── README.md ├── requirements.txt ├── setup.py 在这个结构中： project_name/ 是项目的根目录。 project_name/project_name/ 目录包含项目的源代码，init.py 文件是一个特殊的文件，它标志着该目录是一个 Python 包。 module1.py 和 module2.py 是 Python 模块，它们包含 Python 代码。 package1/ 是一个 Python 包，它可以包含其他模块和子包。包内的 init.py 文件用于组织包的内容。 tests/ 目录包含项目的测试代码。 docs/ 目录包含项目的文档。 setup.py 是一个常见的 Python 项目配置文件，它用于安装，卸载，打包等任务。 requirements.txt 列出了项目的依赖。 Python 项目结构并没有严格的规范，不过这种结构基本就是 Python 社区中通用的最佳实践，你可以在很多开源 Python 项目中看到这种结构。 ","date":"2022-03-18","objectID":"/python-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97_%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95/:0:0","tags":["Python"],"title":"Python 快速上手指南 项目目录","uri":"/python-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97_%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95/"},{"categories":["hugo"],"content":"test test LoveIt提供了admonition shortcode，支持 12 种样式，可以在页面中插入提示的横幅。代码如下 ","date":"2021-09-15","objectID":"/first_post/:1:0","tags":["hugo"],"title":"First_post","uri":"/first_post/"},{"categories":["hugo"],"content":"主题自带的admonition样式 注意\r一个 注意 横幅\r这是一个默认不展开的横幅\r一个 注意 横幅\r摘要\r一个 摘要 横幅\r信息\r一个 信息 横幅\r技巧\r一个 技巧 横幅\r成功\r一个 成功 横幅\r问题\r一个 问题 横幅\r警告\r一个 警告 横幅\r失败\r一个 失败 横幅\r危险\r一个 危险 横幅\rBug\r一个 Bug 横幅\r示例\r一个 示例 横幅\r引用\r一个 引用 横幅\r","date":"2021-09-15","objectID":"/first_post/:2:0","tags":["hugo"],"title":"First_post","uri":"/first_post/"},{"categories":[""],"content":"前言 生活可能不像你想象的那么好\r我们在人的一生中最为辉煌的一天，并不是功成名就的那一天，而是从悲叹和绝望中产生对人生挑战的欲望，并且勇敢的迈向这种挑战的那一天。 人生当中成功只是一时的，失败却是主旋律。但是如何面对失败却把人分成了不同的样子。有的人会被失败击垮，有的人能够不断的爬起来，继续向前。 我想真正的成熟，应该并不是追求完美，而是直面自己的缺憾，这才是生活的本质。 也许他们会明白莫泊桑的一句话：生活可能不像你想象的那么好，但是也不会像你想象的那么糟。人的脆弱和坚强都超乎了自己的想象。有时候，可能脆弱的一句话就泪流满面，有时候，你发现自己咬着牙已经走过了很长的路，\r人的一生中最大的问题不是找不到正确的方法而是在实践中长久的悖逆人性 最淡的墨水也胜过最强的记忆\rAbout Persistence(最淡的墨水也胜过最强的记忆) Nothing in the world can take the place of Persistence. Talent will not; nothing is more common than unsuccessful men with talent. Genius will not; unrewarded genius is almost a proverb. Education will not; the world is full of educated derelicts. Persistence and Determination alone are omnipotent. The slogan “Press On” has solved and will always solve the problems of the human race. 个人介绍 简要介绍：目前居住南京，目前离职状态，喜欢云原生并通过了CKA,CKS认证,对监控落地有相关经验， 熟练使用Docker、K8s，有生产k8s集群的构建、运维、优化、排错经验，熟悉各种开源中间件的部署和优化，有运维自动化、监控系统 相关开发经验。 个人信息：lushuan 拿手菜：清蒸鲈鱼、红烧肉、西红柿炒蛋、炒花蛤、香辣小炒肉 兴趣爱好：篮球、音乐、阅读、掼蛋、台球、旅游等 邮箱：lushuan2071@126.com 我的微信 技能说明：我会的东西基本上都写在博客中了，不敢说有多么精通，一直在努力学习中 Kubernetes Prometheus InfluxDB Grafana Ansible Docker Helm Linux Shell MySQL ","date":"2021-09-15","objectID":"/about/:0:0","tags":[""],"title":"About","uri":"/about/"},{"categories":[""],"content":"云计算相关认证 CKA CKS ","date":"2021-09-15","objectID":"/about/:1:0","tags":[""],"title":"About","uri":"/about/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 ContainerCreating 或 Waiting 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 配置错误 检查是否打包了正确的镜像 检查配置了正确的容器参数 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"磁盘爆满 启动 Pod 会调 CRI 接口创建容器，容器运行时创建容器时通常会在数据目录下为新建的容器创建一些目录和文件，如果数据目录所在的磁盘空间满了就会创建失败并报错: Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \"apigateway-6dc48bf8b6-l8xrw\": Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"limit 设置太小或者单位不对 如果 limit 设置过小以至于不足以成功运行 Sandbox 也会造成这种状态，常见的是因为 memory limit 单位设置不对造成的 limit 过小，比如误将 memory 的 limit 单位像 request 一样设置为小 m，这个单位在 memory 不适用，会被 k8s 识别成 byte， 应该用 Mi 或 M。， 举个例子: 如果 memory limit 设为 1024m 表示限制 1.024 Byte，这么小的内存， pause 容器一起来就会被 cgroup-oom kill 掉，导致 pod 状态一直处于 ContainerCreating。 这种情况通常会报下面的 event: Pod sandbox changed, it will be killed and re-created。 kubelet报错 to start sandbox container for pod ... Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused \"process_linux.go:301: running exec setns process for init caused \\\"signal: killed\\\"\": unknown ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"拉取镜像失败 镜像拉取失败也分很多情况，这里列举下: 配置了错误的镜像 Kubelet 无法访问镜像仓库（比如默认 pause 镜像在 gcr.io 上，国内环境访问需要特殊处理） 拉取私有镜像的 imagePullSecret 没有配置或配置有误 镜像太大，拉取超时（可以适当调整 kubelet 的 —image-pull-progress-deadline 和 —runtime-request-timeout 选项） ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"controller-manager 异常 查看 master 上 kube-controller-manager 状态，异常的话尝试重启。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:5","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Error 状态 通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括： 依赖的 ConfigMap、Secret 或者 PV 等不存在 请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等 违反集群的安全策略 容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 ImagePullBackOff 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"http 类型 registry，地址未加入到 insecure-registry dockerd 默认从 https 类型的 registry 拉取镜像，如果使用 https 类型的 registry，则必须将它添加到 insecure-registry 参数中，然后重启或 reload dockerd 生效。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"https 自签发类型 resitry，没有给节点添加 ca 证书 如果 registry 是 https 类型，但证书是自签发的，dockerd 会校验 registry 的证书，校验成功才能正常使用镜像仓库， 要想校验成功就需要将 registry 的 ca 证书放置到 /etc/docker/certs.d/\u003cregistry:port\u003e/ca.crt 位置。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"私有镜像仓库认证失败 如果 registry 需要认证，但是 Pod 没有配置 imagePullSecret，配置的 Secret 不存在或者有误都会认证失败。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像文件损坏 如果 push 的镜像文件损坏了，下载下来也用不了，需要重新 push 镜像文件 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像拉取超时 如果节点上新起的 Pod 太多就会有许多可能会造成容器镜像下载排队，如果前面有许多大镜像需要下载很长时间，后面排队的 Pod 就会报拉取超时。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:5","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像不存在 kubelet 日志： PullImage \"imroc/test:v0.2\" from image service failed: rpc error: code = Unknown desc = Error response from daemon: manifest for imroc/test:v0.2 not found ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:6","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Pending 状态 Pending 状态说明 Pod 还没有被调度到某个节点上，需要看下 Pod 事件进一步判断原因，比如: $ kubectl describe pod tikv-0 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 3m (x106 over 33m) default-scheduler 0/4 nodes are available: 1 node(s) had no available volume zone, 2 Insufficient cpu, 3 Insufficient memory. 下面列举下可能原因和解决方法。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"节点资源不够 节点资源不够有以下几种情况: CPU 负载过高 剩余可以被分配的内存不够 如果判断某个 Node 资源是否足够？ 通过 kubectl describe node 查看 node 资源情况，关注以下信息： Allocatable: 表示此节点能够申请的资源总和 Allocated resources: 表示此节点已分配的资源 (Allocatable 减去节点上所有 Pod 总的 Request) $ sudo kubectl describe node 10.10.192.220|grep Allo -A 6 Allocatable: cpu: 8 ephemeral-storage: 33806352329 hugepages-2Mi: 0 memory: 24543516Ki pods: 110 System Info: -- Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 3650m (45%) 50150m (626%) memory 5092Mi (21%) 81290Mi (339%) ephemeral-storage 0 (0%) 0 (0%) 可以看到能够申请的资源总和，当前节点可以创建110个pods，cpu 8核，cpu requests占比45% 前者与后者相减，可得出剩余可申请的资源。如果这个值小于 Pod 的 request，就不满足 Pod 的资源要求，Scheduler 在 Predicates (预选) 阶段就会剔除掉这个 Node，也就不会调度上去 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"不满足 nodeSelector 与 affinity 如果 Pod 包含 nodeSelector 指定了节点需要包含的 label，调度器将只会考虑将 Pod 调度到包含这些 label 的 Node 上，如果没有 Node 有这些 label 或者有这些 label 的 Node 其它条件不满足也将会无法调度。参考官方文档： https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/ 如果 Pod 包含 affinity（亲和性）的配置，调度器根据调度算法也可能算出没有满足条件的 Node，从而无法调度。affinity 有以下几类: nodeAffinity: 节点亲和性，可以看成是增强版的 nodeSelector，用于限制 Pod 只允许被调度到某一部分 Node。 podAffinity: Pod 亲和性，用于将一些有关联的 Pod 调度到同一个地方，同一个地方可以是指同一个节点或同一个可用区的节点等。 podAntiAffinity: Pod 反亲和性，用于避免将某一类 Pod 调度到同一个地方避免单点故障，比如将集群 DNS 服务的 Pod 副本都调度到不同节点，避免一个节点挂了造成整个集群 DNS 解析失败，使得业务中断。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Node 存在 Pod 没有容忍的污点 如果节点上存在污点 (Taints)，而 Pod 没有响应的容忍 (Tolerations)，Pod 也将不会调度上去。通过 describe node 可以看下 Node 有哪些 Taints: $ kubectl describe nodes host1 ... Taints: special=true:NoSchedule ... 污点既可以是手动添加也可以是被自动添加 手动添加污点 $ kubectl taint node host1 special=true:NoSchedule node \"host1\" tainted 另外，有些场景下希望新加的节点默认不调度 Pod，直到调整完节点上某些配置才允许调度，就给新加的节点都加上 node.kubernetes.io/unschedulable 这个污点 自动添加污点 如果节点运行状态不正常，污点也可以被自动添加，从 v1.12 开始，TaintNodesByCondition 特性进入 Beta 默认开启，controller manager 会检查 Node 的 Condition，如果命中条件就自动为 Node 加上相应的污点，这些 Condition 与 Taints 的对应关系如下: Conditon Value Taints -------- ----- ------ OutOfDisk True node.kubernetes.io/out-of-disk Ready False node.kubernetes.io/not-ready Ready Unknown node.kubernetes.io/unreachable MemoryPressure True node.kubernetes.io/memory-pressure PIDPressure True node.kubernetes.io/pid-pressure DiskPressure True node.kubernetes.io/disk-pressure NetworkUnavailable True node.kubernetes.io/network-unavailable 解释下上面各种条件的意思: OutOfDisk 为 True 表示节点磁盘空间不够了 Ready 为 False 表示节点不健康 Ready 为 Unknown 表示节点失联，在 node-monitor-grace-period 这么长的时间内没有上报状态 controller-manager 就会将 Node 状态置为 Unknown (默认 40s) MemoryPressure 为 True 表示节点内存压力大，实际可用内存很少 PIDPressure 为 True 表示节点上运行了太多进程，PID 数量不够用了 DiskPressure 为 True 表示节点上的磁盘可用空间太少了 NetworkUnavailable 为 True 表示节点上的网络没有正确配置，无法跟其它 Pod 正常通信 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"kube-scheduler 没有正常运行 检查 maser 上的 kube-scheduler 是否运行正常，异常的话可以尝试重启临时恢复。 $ sudo kubectl -n kube-system get pod|grep kube-scheduler kube-scheduler-10.10.192.220 1/1 Running 183 (40d ago) 424d ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Terminating 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"磁盘爆满 如果 docker 的数据目录所在磁盘被写满，docker 无法正常运行，无法进行删除和创建操作，所以 kubelet 调用 docker 删除容器没反应，看 event 类似这样： Normal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"存在 “i” 文件属性 如果容器的镜像本身或者容器启动后写入的文件存在 “i” 文件属性，此文件就无法被修改删除，而删除 Pod 时会清理容器目录，但里面包含有不可删除的文件，就一直删不了，Pod 状态也将一直保持 Terminating，kubelet 报错: Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.922965 14109 remote_runtime.go:250] RemoveContainer \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\" from runtime service failed: rpc error: code = Unknown desc = failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \"overlay2\" failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.923027 14109 kuberuntime_gc.go:126] Failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": rpc error: code = Unknown desc = failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \"overlay2\" failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted 通过 man chattr 查看 “i” 文件属性描述: A file with the 'i' attribute cannot be modified: it cannot be deleted or renamed, no link can be created to this file and no data can be written to the file. Only the superuser or a process possessing the CAP_LINUX_IMMUTABLE capability can set or clear this attribute. 彻底解决当然是不要在容器镜像中或启动后的容器设置 “i” 文件属性，临时恢复方法： 复制 kubelet 日志报错提示的文件路径，然后执行 chattr -i : chattr -i /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash 执行完后等待 kubelet 自动重试，Pod 就可以被自动删除了。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"docker 17 的 bug docker hang 住，没有任何响应，看 event: Warning FailedSync 3m (x408 over 1h) kubelet, 10.179.80.31 error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded 怀疑是17版本dockerd的BUG。可通过 kubectl -n cn-staging delete pod apigateway-6dc48bf8b6-clcwk –force –grace-period=0 强制删除pod，但 docker ps 仍看得到这个容器 处置建议： 升级到docker 18. 该版本使用了新的 containerd，针对很多bug进行了修复。 如果出现terminating状态的话，可以提供让容器专家进行排查，不建议直接强行删除，会可能导致一些业务上问题。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"存在 Finalizers k8s 资源的 metadata 里如果存在 finalizers，那么该资源一般是由某程序创建的，并且在其创建的资源的 metadata 里的 finalizers 加了一个它的标识，这意味着这个资源被删除时需要由创建资源的程序来做删除前的清理，清理完了它需要将标识从该资源的 finalizers 中移除，然后才会最终彻底删除资源。比如 Rancher 创建的一些资源就会写入 finalizers 标识。 处理建议：kubectl edit 手动编辑资源定义，删掉 finalizers，这时再看下资源，就会发现已经删掉了。通过prometheus-operator 创建prometheus时，最后无法删除namespace 也是此原因。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Unknown 状态 通常是节点失联，没有上报状态给 apiserver，到达阀值后 controller-manager 认为节点失联并将其状态置为 Unknown。 可能原因: 节点高负载导致无法上报 节点宕机 节点被关机 网络不通 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:6:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 健康检查失败 Kubernetes 健康检查包含就绪检查(readinessProbe)和存活检查(livenessProbe) pod 如果就绪检查失败会将此 pod ip 从 service 中摘除，通过 service 访问，流量将不会被转发给就绪检查失败的 pod pod 如果存活检查失败，kubelet 将会杀死容器并尝试重启 健康检查失败的可能原因有多种，除了业务程序BUG导致不能响应健康检查导致 unhealthy，还能有有其它原因，下面我们来逐个排查。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"健康检查配置不合理 initialDelaySeconds 太短，容器启动慢，导致容器还没完全启动就开始探测，如果 successThreshold 是默认值 1，检查失败一次就会被 kill，然后 pod 一直这样被 kill 重启。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"节点负载高 cpu 占用高（比如跑满）会导致进程无法正常发包收包，通常会 timeout，导致 kubelet 认为 pod 不健康。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"容器内进程端口监听挂掉 使用 netstat -tunlp 检查端口监听是否还在，如果不在了，抓包可以看到会直接 reset 掉健康检查探测的连接: 20:15:17.890996 IP 172.16.2.1.38074 \u003e 172.16.2.23.8888: Flags [S], seq 96880261, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.891021 IP 172.16.2.23.8888 \u003e 172.16.2.1.38074: Flags [R.], seq 0, ack 96880262, win 0, length 0 20:15:17.906744 IP 10.0.0.16.54132 \u003e 172.16.2.23.8888: Flags [S], seq 1207014342, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.906766 IP 172.16.2.23.8888 \u003e 10.0.0.16.54132: Flags [R.], seq 0, ack 1207014343, win 0, length 0 连接异常，从而健康检查失败。发生这种情况的原因可能在一个节点上启动了多个使用 hostNetwork 监听相同宿主机端口的 Pod，只会有一个 Pod 监听成功，但监听失败的 Pod 的业务逻辑允许了监听失败，并没有退出，Pod 又配了健康检查，kubelet 就会给 Pod 发送健康检查探测报文，但 Pod 由于没有监听所以就会健康检查失败。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 处于 CrashLoopBackOff 状态 Pod 如果处于 CrashLoopBackOff 状态说明之前是启动了，只是又异常退出了，应用实例状态为CrashLoopBackOff， 表现为实例不断重启，由ready状态变为Complete再变成CrashLoopBackOff。 一般由于应用实例容器异常退出导致的实例异常，需要排查应用日志确定异常退出原因。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"容器进程主动退出 如果是容器进程主动退出，退出状态码一般在 0-128 之间，除了可能是业务程序 BUG，还有其它许多可能原因 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"系统OOM 如果发生系统 OOM，可以看到 Pod 中容器退出状态码是 137，表示被 SIGKILL 信号杀死，同时内核会报错: Out of memory: Kill process …。大概率是节点上部署了其它非 K8S 管理的进程消耗了比较多的内存，或者 kubelet 的 –kube-reserved 和 –system-reserved 配的比较小，没有预留足够的空间给其它非容器进程，节点上所有 Pod 的实际内存占用总量不会超过 /sys/fs/cgroup/memory/kubepods 这里 cgroup 的限制，这个限制等于 capacity - “kube-reserved” - “system-reserved”，如果预留空间设置合理，节点上其它非容器进程（kubelet, dockerd, kube-proxy, sshd 等) 内存占用没有超过 kubelet 配置的预留空间是不会发生系统 OOM 的，可以根据实际需求做合理的调整。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"cgroup OOM 如果是 cgroup OOM 杀掉的进程，从 Pod 事件的下 Reason 可以看到是 OOMKilled，说明容器实际占用的内存超过 limit 了，同时内核日志会报: ``。 可以根据需求调整下 limit ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod调度 一般情况下我们部署的 Pod 是通过集群的自动调度策略来选择节点的，默认情况下调度器考虑的是资源足够，并且负载尽量平均，但是有的时候我们需要能够更加细粒度的去控制 Pod 的调度，比如我们希望一些机器学习的应用只跑在有 GPU 的节点上；但是有的时候我们的服务之间交流比较频繁，又希望能够将这服务的 Pod 都调度到同一个的节点上。这就需要使用一些调度方式来控制 Pod 的调度了，主要有两个概念：亲和性和反亲和性，亲和性又分成节点亲和性(nodeAffinity)和 Pod 亲和性(podAffinity)。 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:0:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"nodeSelector 在了解亲和性之前，我们先来了解一个非常常用的调度方式：nodeSelector。我们知道 label 标签是 kubernetes 中一个非常重要的概念，用户可以非常灵活的利用 label 来管理集群中的资源，比如最常见的 Service 对象通过 label 去匹配 Pod 资源，而 Pod 的调度也可以根据节点的 label 来进行调度。 我们可以通过下面的命令查看我们的 node 的 label： $ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS master1 Ready control-plane,master 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/exclude-from-external-load-balancers= node1 Ready \u003cnone\u003e 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node1,kubernetes.io/os=linux node2 Ready \u003cnone\u003e 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node2,kubernetes.io/os=linux 现在我们先给节点 node2 增加一个com=schedulernode的标签，命令如下： $ kubectl label nodes node2 com=schedulernode node/node2 labeled 我们可以通过上面的 –show-labels 参数可以查看上述标签是否生效。当节点被打上了相关标签后，在调度的时候就可以使用这些标签了，只需要在 Pod 的 spec 字段中添加 nodeSelector 字段，里面是我们需要被调度的节点的 label 标签，比如，下面的 Pod 我们要强制调度到 node2 这个节点上去，我们就可以使用 nodeSelector 来表示了： # node-selector-demo.yaml apiVersion: v1 kind: Pod metadata: labels: app: busybox-pod name: test-busybox spec: containers: - command: - sleep - \"3600\" image: busybox imagePullPolicy: Always name: test-busybox nodeSelector: com: schedulernode 然后我们可以通过 describe 命令查看调度结果： $ kubectl apply -f pod-selector-demo.yaml pod/test-busybox created $ kubectl describe pod test-busybox Name: test-busybox Namespace: default Priority: 0 Node: node2/192.168.31.46 ...... Node-Selectors: com=schedulernode Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u003cunknown\u003e default-scheduler Successfully assigned default/test-busybox to node2 Normal Pulling 13s kubelet, node2 Pulling image \"busybox\" Normal Pulled 10s kubelet, node2 Successfully pulled image \"busybox\" Normal Created 10s kubelet, node2 Created container test-busybox Normal Started 9s kubelet, node2 Started container test-busybox 我们可以看到 Events 下面的信息，我们的 Pod 通过默认的 default-scheduler 调度器被绑定到了 node2 节点。不过需要注意的是nodeSelector 属于强制性的，如果我们的目标节点没有可用的资源，我们的 Pod 就会一直处于 Pending 状态。 通过上面的例子我们可以感受到 nodeSelector 的方式比较直观，但是还够灵活，控制粒度偏大，接下来我们再和大家了解下更加灵活的方式：节点亲和性(nodeAffinity)。 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:1:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"亲和性和反亲和性调度 前面我们了解了 kubernetes 调度器的调度流程，我们知道默认的调度器在使用的时候，经过了 predicates 和 priorities 两个阶段，但是在实际的生产环境中，往往我们需要根据自己的一些实际需求来控制 Pod 的调度，这就需要用到 nodeAffinity(节点亲和性)、podAffinity(pod 亲和性) 以及 podAntiAffinity(pod 反亲和性)。 亲和性调度可以分成软策略和硬策略两种方式: 软策略就是如果现在没有满足调度要求的节点的话，Pod 就会忽略这条规则，继续完成调度过程，说白了就是满足条件最好了，没有的话也无所谓 硬策略就比较强硬了，如果没有满足条件的节点的话，就不断重试直到满足条件为止，简单说就是你必须满足我的要求，不然就不干了 对于亲和性和反亲和性都有这两种规则可以设置： preferredDuringSchedulingIgnoredDuringExecution 和requiredDuringSchedulingIgnoredDuringExecution，前面的就是软策略，后面的就是硬策略 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:2:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"节点亲和性 节点亲和性（nodeAffinity）主要是用来控制 Pod 要部署在哪些节点上，以及不能部署在哪些节点上的，它可以进行一些简单的逻辑组合了，不只是简单的相等匹配。 比如现在我们用一个 Deployment 来管理8个 Pod 副本，现在我们来控制下这些 Pod 的调度，如下例子： # node-affinity-demo.yaml apiVersion: apps/v1 kind: Deployment metadata: name: node-affinity labels: app: node-affinity spec: replicas: 8 selector: matchLabels: app: node-affinity template: metadata: labels: app: node-affinity spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 name: nginxweb affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 硬策略 nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - master1 preferredDuringSchedulingIgnoredDuringExecution: # 软策略 - weight: 1 preference: matchExpressions: - key: com operator: In values: - schedulernode 上面这个 Pod 首先是要求不能运行在 master1 这个节点上，如果有个节点满足 com=schedulernode 的话就优先调度到这个节点上。 由于上面 node02 节点我们打上了 com=schedulernode 这样的 label 标签，所以按要求会优先调度到这个节点来的，现在我们来创建这个 Pod，然后查看具体的调度情况是否满足我们的要求。 $ kubectl apply -f node-affinty-demo.yaml deployment.apps/node-affinity created $ kubectl get pods -l app=node-affinity -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES node-affinity-cdd9d54d9-bgbbh 1/1 Running 0 2m28s 10.244.2.247 node2 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-dlbck 1/1 Running 0 2m28s 10.244.4.16 node1 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-g2jr6 1/1 Running 0 2m28s 10.244.4.17 node1 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-gzr58 1/1 Running 0 2m28s 10.244.1.118 node1 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-hcv7r 1/1 Running 0 2m28s 10.244.2.246 node2 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-kvxw4 1/1 Running 0 2m28s 10.244.2.245 node2 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-p4mmk 1/1 Running 0 2m28s 10.244.2.244 node2 \u003cnone\u003e \u003cnone\u003e node-affinity-cdd9d54d9-t5mff 1/1 Running 0 2m28s 10.244.1.117 node2 \u003cnone\u003e \u003cnone\u003e 从结果可以看出有5个 Pod 被部署到了 node2 节点上，但是可以看到并没有一个 Pod 被部署到 master1 这个节点上，因为我们的硬策略就是不允许部署到该节点上，而 node2 是软策略，所以会尽量满足。这里的匹配逻辑是 label 标签的值在某个列表中，现在 Kubernetes 提供的操作符有下面的几种： In：label 的值在某个列表中 NotIn：label 的值不在某个列表中 Gt：label 的值大于某个值 Lt：label 的值小于某个值 Exists：某个 label 存在 DoesNotExist：某个 label 不存在 但是需要注意的是如果 nodeSelectorTerms 下面有多个选项的话，满足任何一个条件就可以了；如果 matchExpressions有多个选项的话，则必须同时满足这些条件才能正常调度 Pod。 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:3:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"Pod亲和性 Pod 亲和性（podAffinity）主要解决 Pod 可以和哪些 Pod 部署在同一个拓扑域中的问题（其中拓扑域用主机标签实现，可以是单个主机，也可以是多个主机组成的 cluster、zone 等等），而 Pod 反亲和性主要是解决 Pod 不能和哪些 Pod 部署在同一个拓扑域中的问题，它们都是处理的 Pod 与 Pod 之间的关系，比如一个 Pod 在一个节点上了，那么我这个也得在这个节点，或者你这个 Pod 在节点上了，那么我就不想和你待在同一个节点上。 由于我们这里只有一个集群，并没有区域或者机房的概念，所以我们这里直接使用主机名来作为拓扑域，把 Pod 创建在同一个主机上面。 $ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS master1 Ready control-plane,master 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/exclude-from-external-load-balancers= node1 Ready \u003cnone\u003e 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node1,kubernetes.io/os=linux node2 Ready \u003cnone\u003e 82d v1.22.2 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node2,kubernetes.io/os=linux,com=schedulernode 同样，还是针对上面的资源对象，我们来测试下 Pod 的亲和性： # pod-affinity-demo.yaml apiVersion: apps/v1 kind: Deployment metadata: name: pod-affinity labels: app: pod-affinity spec: replicas: 3 selector: matchLabels: app: pod-affinity template: metadata: labels: app: pod-affinity spec: containers: - name: nginx image: nginx ports: - containerPort: 80 name: nginxweb affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 硬策略 - labelSelector: matchExpressions: - key: app operator: In values: - busybox-pod topologyKey: kubernetes.io/hostname 上面这个例子中的 Pod 需要调度到某个指定的节点上，并且该节点上运行了一个带有 app=busybox-pod 标签的 Pod。我们可以查看有标签 app=busybox-pod 的 pod 列表： $ kubectl get pods -l app=busybox-pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES test-busybox 1/1 Running 0 27m 10.244.2.242 node2 \u003cnone\u003e \u003cnone\u003e 我们看到这个 Pod 运行在了 node2 的节点上面，所以按照上面的亲和性来说，上面我们部署的3个 Pod 副本也应该运行在 node2 节点上： $ kubectl apply -f pod-affinity-demo.yaml deployment.apps/pod-affinity created $ kubectl get pods -o wide -l app=pod-affinity NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-affinity-587f9b5b58-5nxmf 1/1 Running 0 26s 10.244.2.249 node2 \u003cnone\u003e \u003cnone\u003e pod-affinity-587f9b5b58-m2j7s 1/1 Running 0 26s 10.244.2.248 node2 \u003cnone\u003e \u003cnone\u003e pod-affinity-587f9b5b58-vrd7b 1/1 Running 0 26s 10.244.2.250 node2 \u003cnone\u003e \u003cnone\u003e 如果我们把上面的 test-busybox 和 pod-affinity 这个 Deployment 都删除，然后重新创建 pod-affinity 这个资源，看看能不能正常调度呢： $ kubectl delete -f node-selector-demo.yaml pod \"test-busybox\" deleted $ kubectl delete -f pod-affinity-demo.yaml deployment.apps \"pod-affinity\" deleted $ kubectl apply -f pod-affinity-demo.yaml deployment.apps/pod-affinity created $ kubectl get pods -o wide -l app=pod-affinity NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-affinity-587f9b5b58-bbfgr 0/1 Pending 0 18s \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e pod-affinity-587f9b5b58-lwc8n 0/1 Pending 0 18s \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e pod-affinity-587f9b5b58-pc7ql 0/1 Pending 0 18s \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e \u003cnone\u003e 我们可以看到都处于 Pending 状态了，这是因为现在没有一个节点上面拥有 app=busybox-pod 这个标签的 Pod，而上面我们的调度使用的是硬策略，所以就没办法进行调度了，大家可以去尝试下重新将 test-busybox 这个 Pod 调度到其他节点上，观察下上面的3个副本会不会也被调度到对应的节点上去。 我们这个地方使用的是 kubernetes.io/hostname 这个拓扑域，意思就是我们当前调度的 Pod 要和目标的 Pod 处于同一个主机上面，因为要处于同一个拓扑域下面，为了说明这个问题，我们把拓扑域改成 beta.kubernetes.io/os，同样的我们当前调度的 Pod 要和目标的 Pod 处于同一个拓扑域中，目标的 Pod 是拥有 beta.kubernetes.io/os=linux 的标签，而我们这里所有节点都有这样的标签，这也就意味着我们所有节点都在同一个拓扑域中，所以我们这里的 Pod 可以被调度到任何一个节点，重新运行上面的 app=busybox-pod 的 Pod，然后再更新下我们这里的资源对象： $ kubectl get pods -o wide -l app=pod-affinity NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-affinity-76c56567c-792n4 1/1 Running 0 2m59s 10.244.2.254 node2 \u003cnone\u003e \u003cnone\u003e pod-affinity-76c56567c-8s2pd 1/1 Running 0 3m53s 10.244.4.18 node1 \u003cnone\u003e \u003cnone\u003e pod-affinity-76c56567c-hx7ck 1/1 Running 0 2m52s 10.244.3.23 node2 \u003cnone\u003e \u003cnone\u003e 可以看到现在是分别运行在2个节点下面的，因为他们都属于 beta.kubernetes.io/os 这个拓扑域。 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:4:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"Pod反亲和性 Pod 反亲和性（podAntiAffinity）则是反着来的，比如一个节点上运行了某个 Pod，那么我们的模板 Pod 则不希望被调度到这个节点上面去了。我们把上面的 podAffinity 直接改成 podAntiAffinity： # pod-antiaffinity-demo.yaml apiVersion: apps/v1 kind: Deployment metadata: name: pod-antiaffinity labels: app: pod-antiaffinity spec: replicas: 3 selector: matchLabels: app: pod-antiaffinity template: metadata: labels: app: pod-antiaffinity spec: containers: - name: nginx image: nginx ports: - containerPort: 80 name: nginxweb affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 硬策略 - labelSelector: matchExpressions: - key: app operator: In values: - busybox-pod topologyKey: kubernetes.io/hostname 这里的意思就是如果一个节点上面有一个 app=busybox-pod 这样的 Pod 的话，那么我们的 Pod 就别调度到这个节点上面来，上面我们把app=busybox-pod 这个 Pod 固定到了 node2 这个节点上面的，所以正常来说我们这里的 Pod 不会出现在该节点上： $ kubectl apply -f pod-antiaffinity-demo.yaml deployment.apps/pod-antiaffinity created $ kubectl get pods -l app=pod-antiaffinity -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-antiaffinity-84d5bf9df4-9c9qk 1/1 Running 0 73s 10.244.4.19 node1 \u003cnone\u003e \u003cnone\u003e pod-antiaffinity-84d5bf9df4-q6lkm 1/1 Running 0 67s 10.244.3.24 node1 \u003cnone\u003e \u003cnone\u003e pod-antiaffinity-84d5bf9df4-vk9tc 1/1 Running 0 57s 10.244.3.25 node1 \u003cnone\u003e \u003cnone\u003e 我们可以看到没有被调度到 node2 节点上，因为我们这里使用的是 Pod 反亲和性。大家可以思考下，如果这里我们将拓扑域更改成 beta.kubernetes.io/os 会怎么样呢？可以自己去测试下看看。 ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:5:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["Kubernetes"],"content":"污点和容忍 对于 nodeAffinity 无论是硬策略还是软策略方式，都是调度 Pod 到预期节点上，而污点（Taints）恰好与之相反，如果一个节点标记为 Taints ，除非 Pod 也被标识为可以容忍污点节点，否则该 Taints 节点不会被调度 Pod。 比如用户希望把 Master 节点保留给 Kubernetes 系统组件使用，或者把一组具有特殊资源预留给某些 Pod，则污点就很有用了，Pod 不会再被调度到 taint 标记过的节点。我们使用 kubeadm 搭建的集群默认就给 master 节点添加了一个污点标记，所以我们看到我们平时的 Pod 都没有被调度到 master 上去： $ kubectl describe node master1 Name: master1 Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=master1 kubernetes.io/os=linux node-role.kubernetes.io/master= ...... Taints: node-role.kubernetes.io/master:NoSchedule Unschedulable: false ...... 我们可以使用上面的命令查看 master 节点的信息，其中有一条关于 Taints 的信息：node-role.kubernetes.io/master:NoSchedule，就表示master 节点打了一个污点的标记，其中影响的参数是 NoSchedule，表示 Pod 不会被调度到标记为 taints 的节点，除了 NoSchedule 外，还有另外两个选项： PreferNoSchedule：NoSchedule 的软策略版本，表示尽量不调度到污点节点上去 NoExecute：该选项意味着一旦 Taint 生效，如该节点内正在运行的 Pod 没有对应容忍（Tolerate）设置，则会直接被逐出污点 相比较NoExecute策略，NoSchedule，只会影响新的 Pod 调度，不会将正在运行的Pod进行驱逐 taint 标记节点的命令如下： $ kubectl taint nodes node2 test=node2:NoSchedule node \"node2\" tainted 上面的命名将 node2 节点标记为了污点，影响策略是 NoSchedule，只会影响新的 Pod 调度，如果仍然希望某个 Pod 调度到 taint 节点上，则必须在 Spec 中做出 Toleration 定义，才能调度到该节点，比如现在我们想要将一个 Pod 调度到 master 节点： # taint-demo.yaml apiVersion: apps/v1 kind: Deployment metadata: name: taint labels: app: taint spec: replicas: 3 selector: matchLabels: app: taint template: metadata: labels: app: taint spec: containers: - name: nginx image: nginx ports: - name: http containerPort: 80 tolerations: - key: \"node-role.kubernetes.io/master\" operator: \"Exists\" effect: \"NoSchedule\" 由于 master 节点被标记为了污点，所以我们这里要想 Pod 能够调度到改节点去，就需要增加容忍的声明： tolerations: - key: \"node-role.kubernetes.io/master\" operator: \"Exists\" effect: \"NoSchedule\" 然后创建上面的资源，查看结果： $ kubectl apply -f taint-demo.yaml deployment.apps \"taint\" created $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... taint-845d8bb4fb-57mhm 1/1 Running 0 1m 10.244.4.247 node2 taint-845d8bb4fb-bbvmp 1/1 Running 0 1m 10.244.0.33 master1 taint-845d8bb4fb-zb78x 1/1 Running 0 1m 10.244.4.246 node2 ...... 我们可以看到有一个 Pod 副本被调度到了 master 节点，这就是容忍的使用方法。 对于 tolerations 属性的写法，其中的 key、value、effect 与 Node 的 Taint 设置需保持一致， 还有以下几点说明： 如果 operator 的值是 Exists，则 value 属性可省略 如果 operator 的值是 Equal，则表示其 key 与 value 之间的关系是 equal(等于) 如果不指定 operator 属性，则默认值为 Equal 另外，还有两个特殊值： 空的 key 如果再配合 Exists 就能匹配所有的 key 与 value，也就是是能容忍所有节点的所有 Taints 空的 effect 匹配所有的 effect 最后如果我们要取消节点的污点标记，可以使用下面的命令 $ kubectl taint nodes node2 test- node \"node2\" untainted ","date":"2021-07-16","objectID":"/pod%E8%B0%83%E5%BA%A6/:6:0","tags":["Kubernetes"],"title":"Pod调度","uri":"/pod%E8%B0%83%E5%BA%A6/"},{"categories":["linux"],"content":"awk 是 Linux/Unix 系统中的一个强大的文本处理工具,主要用于处理文本文件和字符串。 ","date":"2021-06-29","objectID":"/awk/:0:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"特性 awk 的一些关键特性: 可以根据字段进行操作,如打印指定列、求列的总和等 支持条件判断和循环语句,可以实现复杂的文本处理 使用正则表达式进行模式匹配和内容提取 内置字符串操作函数,如匹配、替换、截取等 ","date":"2021-06-29","objectID":"/awk/:1:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"适用场景 awk 适用于报表生成、格式转换、数学运算等场景。掌握了 awk,可以大大提高 Bash 脚本的文本处理能力 ","date":"2021-06-29","objectID":"/awk/:2:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"内置函数 内置函数 command 释义 gsub(r,s) 在整个$0中用s替代r 相当于 sed ’s///g' gsub(r,s,t) 在整个t中用s替代r index(s,t) 返回s中字符串t的第一位置 length(s) 返回s长度 match(s,r) 测试s是否包含匹配r的字符串 split(s,a,fs) 在fs上将s分成序列a sprint(fmt,exp) 返回经fmt格式化后的exp sub(r,s) 用$0中最左边最长的子串代替s 相当于 sed ’s///' substr(s,p) 返回字符串s中从p开始的后缀部分 substr(s,p,n) 返回字符串s中从p开始长度为n的后缀部分 ","date":"2021-06-29","objectID":"/awk/:3:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"awk 判断 awk ‘{print ($1\u003e$2)?“第一排”$1:“第二排”$2}’ # 条件判断 括号代表if语句判断 “?“代表then “:“代表else awk ‘{max=($1\u003e$2)? $1 : $2; print max}’ # 条件判断 如果$1大于$2,max值为为$1,否则为$2 awk ‘{if ( $6 \u003e 50) print $1 \" Too high” ;else print “Range is OK”}’ file awk ‘{if ( $6 \u003e 50) { count++;print $3 } else { x+5; print $2 } }’ file ","date":"2021-06-29","objectID":"/awk/:4:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"awk 循环 awk ‘{i = 1; while ( i \u003c= NF ) { print NF, $i ; i++ } }’ file awk ‘{ for ( i = 1; i \u003c= NF; i++ ) print NF,$i }’ file ","date":"2021-06-29","objectID":"/awk/:5:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"示例 awk ‘{print $1, $3}’ file.txt 每行按空格分割成多个字段,输出第1个和第3个字段 awk ‘{sum+=$1*$1} END {print sum}’ file.txt 求第一列的平方和 awk ’length \u003e 80’ file.txt 查找长度大于80的行 awk ‘/regex/ {print $0}’ log.txt 使用正则表达式匹配内容 awk ‘{print $NF}’ file.txt 打印最后一列 awk ‘{print $(NF-1) }’ file.txt 打印倒数第二列 awk ‘{OFS=”#”;$1=$1;print $0}’ file.txt OFS 输出记录分隔符 awk ‘{if(NR==3){print $0} else {print “不是第三行”}}’ file.txt 打印指定行 awk ‘NR==1||NR==3{print $0}’ test.txt 打印第一行或者第三行 awk ‘/Tom/’ file # 打印匹配到得行 awk ‘/^Tom/{print $1}’ # 匹配Tom开头的行 打印第一个字段 awk ‘$1 !~ /ly$/’ # 显示所有第一个字段不是以ly结尾的行 awk ‘$3 \u003c40’ # 如果第三个字段值小于40才打印 awk ‘$4==90{print $5}’ # 取出第四列等于90的第五列 awk ‘/^(no|so)/’ test # 打印所有以模式no或so开头的行 awk ‘$3 * $4 \u003e 500’ # 算术运算(第三个字段和第四个字段乘积大于500则显示) awk ‘{print NR” “$0}’ # 加行号 awk ‘/tom/,/suz/’ # 打印tom到suz之间的行 awk ‘{a+=$1}END{print a}’ # 列求和 awk ‘sum+=$1{print sum}’ # 将$1的值叠加后赋给sum awk ‘{a+=$1}END{print a/NR}’ # 列求平均值 awk ‘!s[$1 $3]++’ file # 根据第一列和第三列过滤重复行 awk -F’[ :\\t]’ ‘{print $1,$2}’ # 以空格、:、制表符Tab为分隔符 awk ‘{print “’\"$a”’”,\"’\"$b\"’\"}’ # 引用外部变量 awk ‘{if(NR==52){print;exit}}’ # 显示第52行 awk ‘/关键字/{a=NR+2}a==NR {print}’ # 取关键字下第几行 awk ‘gsub(/liu/,“aaaa”,$1){print $0}’ # 只打印匹配替换后的行 ll | awk -F’[ ]+|[ ][ ]+’ ‘/^$/{print $8}’ # 提取时间,空格不固定 awk ‘{$1=\"\";$2=\"\";$3=\"\";print}’ # 去掉前三列 echo aada:aba|awk ‘/d/||/b/{print}’ # 匹配两内容之一 echo aada:abaa|awk -F: ‘$1~/d/||$2~/b/{print}’ # 关键列匹配两内容之一 echo Ma asdas|awk ‘$1~/^[a-Z][a-Z]$/{print }’ # 第一个域匹配正则 echo aada:aaba|awk ‘/d/\u0026\u0026/b/{print}’ # 同时匹配两条件 awk ’length($1)==“4”{print $1}’ # 字符串位数 awk ‘{if($2\u003e3){system (“touch “$1)}}’ # 执行系统命令 awk ‘{sub(/Mac/,“Macintosh”,$0);print}’ # 用Macintosh替换Mac awk ‘{gsub(/Mac/,“MacIntosh”,$1); print}’ # 第一个域内用Macintosh替换Mac awk -F ’’ ‘{ for(i=1;i\u003cNF+1;i++)a+=$i ;print a}’ # 多位数算出其每位数的总和.比如 1234， 得到 10 awk ‘{ i=$1%10;if ( i == 0 ) {print i}}’ # 判断$1是否整除(awk中定义变量引用时不能带 $ ) awk ‘BEGIN{a=0}{if ($1\u003ea) a=$1 fi}END{print a}’ # 列求最大值 设定一个变量开始为0，遇到比该数大的值，就赋值给该变量，直到结束 awk ‘BEGIN{a=11111}{if ($1\u003ca) a=$1 fi}END{print a}’ # 求最小值 awk ‘{if(A)print;A=0}/regexp/{A=1}’ # 查找字符串并将匹配行的下一行显示出来，但并不显示匹配行 awk ‘/regexp/{print A}{A=$0}’ # 查找字符串并将匹配行的上一行显示出来，但并不显示匹配行 awk ‘{if(!/mysql/)gsub(/1/,“a”);print $0}’ # 将1替换成a，并且只在行中未出现字串mysql的情况下替换 awk ‘BEGIN{srand();fr=int(100*rand());print fr;}’ # 获取随机数 awk ‘{if(NR==3)F=1}{if(F){i++;if(i%7==1)print}}’ # 从第3行开始，每7行显示一次 awk ‘{if(NF\u003c1){print i;i=0} else {i++;print $0}}’ # 显示空行分割各段的行数 echo +null:null |awk -F: ‘$1!~\"^+”\u0026\u0026$2!=“null”{print $0}’ # 关键列同时匹配 awk -v RS=@ ‘NF{for(i=1;i\u003c=NF;i++)if($i) printf $i;print “”}’ # 指定记录分隔符 awk ‘{b[$1]=b[$1]$2}END{for(i in b){print i,b[i]}}’ # 列叠加 awk ‘{ i=($1%100);if ( $i \u003e= 0 ) {print $0,$i}}’ # 求余数 awk ‘{b=a;a=$1; if(NR\u003e1){print a-b}}’ # 当前行减上一行 awk ‘{a[NR]=$1}END{for (i=1;i\u003c=NR;i++){print a[i]-a[i-1]}}’ # 当前行减上一行 awk -F: ‘{name[x++]=$1};END{for(i=0;i\u003cNR;i++)print i,name[i]}’ # END只打印最后的结果,END块里面处理数组内容 awk ‘{sum2+=$2;count=count+1}END{print sum2,sum2/count}’ # $2的总和 $2总和除个数(平均值) awk -v a=0 -F ‘B’ ‘{for (i=1;i\u003cNF;i++){ a=a+length($i)+1;print a }}’ # 打印所以B的所在位置 awk ‘BEGIN{ “date” | getline d; split(d,mon) ; print mon[2]}’ file # 将date值赋给d，并将d设置为数组mon，打印mon数组中第2个元素 awk ‘BEGIN{info=“this is a test2010test!\";print substr(info,4,10);}’ # 截取字符串(substr使用) awk ‘BEGIN{info=“this is a test2010test!\";print index(info,“test”)?“ok”:“no found”;}’ # 匹配字符串(index使用) awk ‘BEGIN{info=“this is a test2010test!\";print match(info,/[0-9]+/)?“ok”:“no found”;}’ # 正则表达式匹配查找(match使用) awk ‘{for(i=1;i\u003c=4;i++)printf $i\"“FS; for(y=10;y\u003c=13;y++) printf $y\"“FS;print “”}’ # 打印前4列和后4列 awk ‘BEGIN{for(n=0;n++\u003c9;){for(i=0;i++\u003cn;)printf i\"x\"n”=“i*n” “;print “”}}’ # 乘法口诀 awk ‘BEGIN{info=“this is a test”;split(info,tA,” “);print length(tA);for(k in tA){print k,tA[k];}}’ # 字符串分割(split使用) awk ‘{if (system (“grep “$2” tmp/* \u003e /dev/null 2\u003e\u00261”) == 0 ) {print $1,“Y”} else {print $1,“N”} }’ a # 执行系统命令判断返回状态 awk ‘{for(i=1;i\u003c=NF;i++) a[i,NR]=$i}END{for(i=1;i\u003c=NF;i++) {for(j=1;j\u003c=NR;j++) printf a[i,j] \" “;print “”}}’ # 将多行转多列 常用示例 #删除temp文件的重复行 awk '!($0 in array) { array[$0]; print }' temp #查看最长使用的10个unix命令 awk '{print $1}' ~","date":"2021-06-29","objectID":"/awk/:6:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"思维导图 awk\r","date":"2021-06-29","objectID":"/awk/:7:0","tags":["linux文本三剑客"],"title":"文本三剑客之 awk","uri":"/awk/"},{"categories":["linux"],"content":"文本处理三剑客之SED Stream EDitor, 流编辑器 sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为\"模式空间\"（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。 功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等 参考： http://www.gnu.org/software/sed/manual/sed.html 简单的说sed主要是用来编辑文件，那么可以从四个角度来学这个命令，增删查改 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:0:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"初体验 在行首添加一行 sed '1i\\AAA' aa.txt 在行尾添加一行 sed '$a\\AAA' aa.txt ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:1:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"基础 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"用法 用法： sed [option]... 'script' inputfile... 常用选项： -n 不输出模式空间内容到屏幕，即不自动打印 -e 多点编辑 -f /PATH/SCRIPT_FILE 从指定文件中读取编辑脚本 -r 支持使用扩展正则表达式 -i.bak 备份文件并原处编辑 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:1","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"地址定界 (1) 不给地址：对全文进行处理 (2) 单地址： #：指定的行，$：最后一行 /pattern/：被此处模式所能够匹配到的每一行 (3) 地址范围： #,# #,+# /pat1/,/pat2/ #,/pat1/ (4) ~：步进 1~2 奇数行 2~2 偶数行 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:2","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"编辑命令 命令 说明 d 删除模式空间匹配的行，并立即启用下一轮循环 p 打印当前模式空间内容，追加到默认输出之后 a [\\]text 在指定行后面追加文本，支持使用\\n实现多行追加 i [\\]text 在行前面插入文本 c [\\]text 替换行为单行或多行文本 w /path/file 保存模式匹配的行至指定文件 r /path/file 读取指定文件的文本至模式空间中匹配到的行后 = 为模式空间中的行打印行号 ! 模式空间中匹配行取反处理 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:3","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"查找替换 s/// 查找替换,支持使用其它分隔符，s@@@，s### 替换标记： g 行内全局替换 p 显示替换成功的行 w /PATH/FILE 将替换成功的行保存至文件中 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:4","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"示例 命令 介绍 cp /etc/passwd /tmp/passwd 样本文件 sed ‘2p’ /tmp/passwd 打印第二行 sed -n ‘2p’ /tmp/passwd 打印第二行静默输出第二行 sed -n ‘1,4p’ /tmp/passwd 静默输出一至四行 sed -n ‘/root/p’ /tmp/passwd 静默输出匹配包含root字符串的行 sed -n ‘2,/root/p’ /tmp/passwd 从2行开始，静默输出匹配包含root字符串的行 sed -n ‘/^$/=’ file 显示空行行号 sed -n -e ‘/^$/p’ -e ‘/^$/=’ file sed ‘/root/a\\superman’ /tmp/passwd 在匹配root字符串行后追加superman sed ‘/root/i\\superman’ /tmp/passwd 在匹配root字符串行前追加superman sed ‘/root/c\\superman’ /tmp/passwd 重写匹配root字符串的行 sed ‘/^$/d’ file 清空文件 sed ‘1,10d’ file 删除文件的1-10行 nl /tmp/passwd sed ‘2,5d’ nl /tmp/passwd sed ‘2a tea’ sed ’s/test/mytest/g’ example 文件替换 sed -n ’s/root/\u0026superman/p’ /tmp/passwd 在匹配的单词后添加内容 sed -n ’s/root/superman\u0026/p’ /tmp/passwd 在匹配的单词前添加内容 sed -e ’s/dog/cat/’ -e ’s/hi/lo/’ pets 多个正则匹配 sed –i ’s/dog/cat/g’ pets 替换生效 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:2:5","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"总结 添加使用append,insert命令，删除使用delete,修改使用copy,subsitute命令,查看print 结合-n 静默输出，可以覆盖百分之八十以上的场景 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:3:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"高级编辑命令 P： 打印模式空间开端至\\n内容，并追加到默认输出之前 h: 把模式空间中的内容覆盖至保持空间中 H：把模式空间中的内容追加至保持空间中 g: 从保持空间取出数据覆盖至模式空间 G：从保持空间取出内容追加至模式空间 x: 把模式空间中的内容与保持空间中的内容进行互换 n: 读取匹配到的行的下一行覆盖至模式空间 N：读取匹配到的行的下一行追加至模式空间 d: 删除模式空间中的行 D：如果模式空间包含换行符，则删除直到第一个换行符的模式空间中的文本，并不会读取新的输入行，而使用合成的模式空间重新启动循环。如果模式空间 不包含换行符，则会像发出d命令那样启动正常的新循环 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:4:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"练习 1、删除centos7系统/etc/grub2.cfg文件中所有以空白开头的行行首的空白字符 2、删除/etc/fstab文件中所有以#开头，后面至少跟一个空白字符的行的行首的#和空白字符 3、在centos6系统/root/install.log每一行行首增加#号 4、在/etc/fstab文件中不以#开头的行的行首增加#号 5、处理/etc/fstab路径,使用sed命令取出其目录名和基名 6、利用sed 取出ifconfig命令中本机的IPv4地址 7、统计centos安装光盘中Package目录下的所有rpm文件的以.分隔倒数第二个字段的重复次数 8、统计/etc/init.d/functions文件中每个单词的出现次数，并排序（用grep和sed两种方法分别实现） 9、将文本文件的n和n+1行合并为一行，n为奇数行 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:5:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"思维导图 sed\r","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:6:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"参考 linux-sed-command sed常用命令 ","date":"2021-06-26","objectID":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/:7:0","tags":["linux文本三剑客"],"title":"文本三剑客之 sed","uri":"/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/"},{"categories":["linux"],"content":"为什么使用Linux grep命令? Grep是一个非常有用的命令行工具，可以用来在文件中查找指定的文本模式。通过使用grep命令，你可以快速定位和提取包含特定模式的行，从而加快查找和处理文本数据的效率。这是一个在日常工作中经常需要使用的任务，因此grep命令在Linux中非常流行。 ","date":"2021-06-20","objectID":"/grep/:1:0","tags":["linux文本三剑客"],"title":"文本三剑客之 grep","uri":"/grep/"},{"categories":["linux"],"content":"Linux grep命令是什么？ Grep是一个在Linux和其他类Unix系统上可用的命令行实用程序，用于搜索和匹配文本。它的名字来自于全局正则表达式（global regular expression print），它的主要功能是根据给定的模式搜索文件中的文本，并打印匹配的行。grep命令支持使用简单的文本模式或正则表达式进行搜索，并且可以通过命令选项进行进一步的定制。 ","date":"2021-06-20","objectID":"/grep/:2:0","tags":["linux文本三剑客"],"title":"文本三剑客之 grep","uri":"/grep/"},{"categories":["linux"],"content":"如何使用Linux grep命令？ 要使用grep命令，在命令行中输入grep，后跟要搜索的模式和要搜索的文件的路径。下面是一些常用的grep命令选项和示例： 示例列表 命令 解释 grep -i “pattern” file.txt 忽略大小写进行搜索 grep -r “pattern” directory/ 递归搜索子目录 grep -E “pattern” file.txt 使用正则表达式进行搜索 grep -A 2 “pattern” file.txt 显示匹配模式之前或之后的文本行 grep -C 2 “pattern” file.txt 输出匹配模式的上下文行 grep -i “pattern” file.txt 忽略大小写 grep -w “pattern” file.txt 精确匹配 grep -e hello -e world file.txt 多个关键词匹配 grep -v “pattern” file.txt 反向查找，不包含某个关键词的行 grep -lr “pattern” file.txt 递归匹配哪些文件名包含匹配的关键词 grep -o “pattern” file.txt 只输出匹配的内容 grep\r","date":"2021-06-20","objectID":"/grep/:3:0","tags":["linux文本三剑客"],"title":"文本三剑客之 grep","uri":"/grep/"},{"categories":["linux"],"content":"参考 是真的很详细了！Linux中的Grep命令使用实例 ","date":"2021-06-20","objectID":"/grep/:4:0","tags":["linux文本三剑客"],"title":"文本三剑客之 grep","uri":"/grep/"},{"categories":["Kubernetes"],"content":"K8s Service有四种类型 Service Headless Service NodePort Service LoadBalancer Service Service 如果不指定则为默认类型 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:0:0","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"Service ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"Service是什么？ Service服务可以为一组具有相同功能的容器应用提供一个统一的入口地址。 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:1:1","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"Service可以用来做什么？ 我们都知道Pod在摧毁重建时ip地址是会动态变化的，这样通过客户端直接访问不合适了，这时候就可以选择使用服务来和Pod建立连接，通过标签选择器进行适配。这样就能有效的解决了Pod ip地址动态变换的问题了。 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:1:2","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"Headless Service headless service作为service的一种类型，它又解决了什么问题？headless service 顾名思义无头服务。 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:2:0","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"为什么需要无头服务？ 客户端想要和指定的的Pod直接通信 并不是随机选择 开发人员希望自己控制负载均衡的策略，不使用Service提供的默认的负载均衡的功能，或者应用程序希望知道属于同组服务的其它实例。 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:2:1","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"Headless Service使用场景 有状态应用，例如数据库 例如主节点可以对数据库进行读写操作，而其它的两个工作节点只能读，在这里客户端就没必要指定pod服务的集群地址，直接指定数据库Pod ip地址即可，这里需要绑定dns，客户端访问dns，dns会自动返回pod IP地址列表 Service\r","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:2:2","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"总结 无头服务不需要指定集群地址 无头服务适用有状态应用例如数据库 无头服务dns查询会返回pod列表，开发人员可以自定义负载均衡策略 普通Service可以通过负载均衡路由到不同的容器应用 ","date":"2021-06-13","objectID":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/:3:0","tags":["Kubernetes"],"title":"K8s默认Service和Headless Service的区别","uri":"/k8s%E9%BB%98%E8%AE%A4service%E5%92%8Cheadless-service%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["Kubernetes"],"content":"资源对象概述 Kubernetes中的基本概念和术语大多是围绕资源对象（Resource Object）来说的，而资源对象在总体上可分为以下两类。 某种资源的对象，例如节点（Node）、Pod、服务（Service）、存储卷（Volume） 与资源对象相关的事物与动作，例如标签（Label）、注解（Annotation）、命名空间（Namespace）、部署（Deployment）、HPA、PVC。 集群类 集群（Cluster）表示一个由Master和Node组成的Kubernetes集群。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:0:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Master Master指的是集群的控制节点。在每个Kubernetes集群中都需要有一个或一组被称为Master的节点，来负责整个集群的管理和控制。Master通常占据一个独立的服务器（在高可用部署中建议至少使用3台服务器），是整个集群的\"大脑\"，如果它发生宕机或者不可用，那么对集群内容器应用的管理都将无法实施。 在Master上运行着以下关键进程。 Kubernetes API Server（kube-apiserver）：提供HTTP RESTfulAPI接口的主要服务，是Kubernetes里对所有资源进行增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager）：Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的\"大总管\"。 Kubernetes Scheduler（kube-scheduler）：负责资源调度（Pod调度）的进程，相当于公交公司的调度室。 另外，在Master上通常还需要部署etcd服务 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:1:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Node Kubernetes集群中除Master外的其他服务器被称为Node，Node在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他Node上。 在每个Node上都运行着以下关键进程。 kubelet：负责Pod对应容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy：实现Kubernetes Service的通信与负载均衡机制的服务。 容器运行时（如Docker）：负责本机的容器创建和管理。Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个Node上已正确安装、配置和启动了上述关键进程。在默认情况下，kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范畴，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、主机CPU和内存使用情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。而某个Node在超过指定时间不上报信息时，会被Master判定为\"失联\"，该Node的状态就被标记为不可用（NotReady），Master随后会触发\"工作负载大转移\"的自动流程。 应用类 Kubernetes中属于应用类的概念和相应的资源对象类型最多，所以应用类也是需要重点学习的一类。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:2:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service与Pod 应用类相关的资源对象主要是围绕Service（服务）和Pod这两个核心对象展开的。 一般说来，Service指的是无状态服务，通常由多个程序副本提供服务，在特殊情况下也可以是有状态的单实例服务，比如MySQL这种数据存储类的服务。与我们常规理解的服务不同，Kubernetes里的Service具有一个全局唯一的虚拟ClusterIP地址，Service一旦被创建，Kubernetes就会自动为它分配一个可用的ClusterIP地址，而且在Service的整个生命周期中，它的ClusterIP地址都不会改变，客户端可以通过这个虚拟IP地址+服务的端口直接访问该服务，再通过部署Kubernetes集群的DNS服务，就可以实现Service Name（域名）到ClusterIP地址的DNS映射功能，我们只要使用服务的名称（DNS名称）即可完成到目标服务的访问请求。“服务发现\"这个传统架构中的棘手问题在这里首次得以完美解决，同时，凭借ClusterIP地址的独特设计，Kubernetes进一步实现了Service的透明负载均衡和故障自动恢复的高级特性。 通过分析、识别并建模系统中的所有服务为微服务——Kubernetes Service，我们的系统最终由多个提供不同业务能力而又彼此独立的微服务单元组成，服务之间通过TCP/IP进行通信，从而形成强大又灵活的弹性网格，拥有强大的分布式能力、弹性扩展能力、容错能力，程序架构也变得简单和直观许多 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:3:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Pod 为什么Kubernetes会设计出一个全新的Pod概念并且Pod有这样特殊的组成结构？原因如下。 为多进程之间的协作提供一个抽象模型，使用Pod作为基本的调度、复制等管理工作的最小单位，让多个应用进程能一起有效地调度和伸缩。 Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术实现，例如Flannel、OpenvSwitch等，因此我们需要牢记一点：在Kubernetes里，一个Pod里的容器与另外主机上的Pod容器能够直接通信。 Pod其实有两种类型：普通的Pod及静态Pod（Static Pod）。后者比较特殊，它并没被存放在Kubernetes的etcd中，而是被存放在某个具体的Node上的一个具体文件中，并且只能在此Node上启动、运行。而普通的Pod一旦被创建，就会被放入etcd中存储，随后被Kubernetes Master调度到某个具体的Node上并绑定（Binding），该Pod被对应的Node上的kubelet进程实例化成一组相关的Docker容器并启动。在默认情况下，当Pod里的某个容器停止时，Kubernetes会自动检测到这个问题并且重新启动这个Pod（重启Pod里的所有容器），如果Pod所在的Node宕机，就会将这个Node上的所有Pod都重新调度到其他节点上。 Pod、容器与Node的关系 Pod、容器与Node的关系\r","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:4:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Label与标签选择器 Label（标签）是Kubernetes系统中的另一个核心概念，相当于我们熟悉的\"标签”。一个Label是一个key=value的键值对，其中的key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、Deployment等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作，例如，部署不同版本的应用到不同的环境中，以及监控、分析应用（日志记录、监控、告警）等。一些常用的Label示例如下。 版本标签：release：stable和release：canary。 环境标签：environment：dev、environment：qa和environment：production。 架构标签：tier：frontend、tier：backend和tier：middleware。 分区标签：partition：customerA和partition：customerB。 质量管控标签：track：daily和track：weekly Label也是Pod的重要属性之一，其重要性仅次于Pod的端口，我们几乎见不到没有Label的Pod Service很重要的一个属性就是标签选择器，如果我们不小心把标签选择器写错了，就会出现指鹿为马的闹剧。如果恰好匹 配到了另一种Pod实例，而且对应的容器端口恰好正确，服务可以正常连接，则很难排查问题，特别是在有众多Service的复杂系统中。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:5:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Pod与Deployment 前面提到，大部分Service都是无状态的服务，可以由多个Pod副本实例提供服务。通常情况下，每个Service对应的Pod服务实例数量都是固定的，如果一个一个地手工创建Pod实例，就太麻烦了，最好是用模板的思路，即提供一个Pod模板（Template），然后由程序根据我们指定的模板自动创建指定数量的Pod实例。这就是Deployment这个资源对象所要完成的事情了。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:6:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service的ClusterIP地址 既然每个Pod都会被分配一个单独的IP地址，而且每个Pod都提供了一个独立的Endpoint（Pod IP+containerPort）以被客户端访问，那么现在多个Pod副本组成了一个集群来提供服务，客户端如何访问它们呢？传统的做法是部署一个负载均衡器（软件或硬件），为这组Pod开启一个对外的服务端口如8000端口，并且将这些Pod的Endpoint列表加入8000端口的转发列表中，客户端就可以通过负载均衡器的对外IP地址+8000端口来访问此服务了。Kubernetes也是类似的做法，Kubernetes内部在每个Node上都运行了一套全局的虚拟负载均衡器，自动注入并自动实时更新集群中所有Service的路由表，通过iptables或者IPVS机制，把对Service的请求转发到其后端对应的某个Pod实例上，并在内部实现服务的负载均衡与会话保持机制。不仅如此，Kubernetes还采用了一种很巧妙又影响深远的设计——ClusterIP地址。我们知道，Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变，因为新Pod的IP地址与之前旧Pod的不同。Service一旦被创建，Kubernetes就会自动为它分配一个全局唯一的虚拟IP地址——ClusterIP地址，而且在Service的整个生命周期内，其ClusterIP地址不会发生改变，这样一来，每个服务就变成了具备唯一IP地址的通信节点，远程服务之间的通信问题就变成了基础的TCP网络通信问题。 之所以说ClusterIP地址是一种虚拟IP地址，原因有以下几点。 ClusterIP地址仅仅作用于Kubernetes Service这个对象，并由Kubernetes管理和分配IP地址（来源于ClusterIP地址池），与Node和Master所在的物理网络完全无关。 因为没有一个\"实体网络对象\"来响应，所以ClusterIP地址无法被Ping通。ClusterIP地址只能与Service Port组成一个具体的服务访问端点，单独的ClusterIP不具备TCP/IP通信的基础。 ClusterIP属于Kubernetes集群这个封闭的空间，集群外的节点要访问这个通信端口，则需要做一些额外的工作 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:7:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service的外网访问问题 前面提到，服务的ClusterIP地址在Kubernetes集群内才能被访问，那么如何让集群外的应用访问我们的服务呢？这也是一个相对复杂的问题。要弄明白这个问题的解决思路和解决方法，我们需要先弄明白 Kubernetes的三种IP，这三种IP分别如下。 Node IP：Node的IP地址。 Pod IP：Pod的IP地址。 Service IP：Service的IP地址。 首先，Node IP是Kubernetes集群中每个节点的物理网卡的IP地址，是一个真实存在的物理网络，所有属于这个网络的服务器都能通过这个网络直接通信，不管其中是否有部分节点不属于这个Kubernetes集群。这也表明Kubernetes集群之外的节点访问Kubernetes集群内的某个节点或者TCP/IP服务时，都必须通过Node IP通信。 其次，Pod IP是每个Pod的IP地址，在使用Docker作为容器支持引擎的情况下，它是Docker Engine根据docker0网桥的IP地址段进行分配的，通常是一个虚拟二层网络。前面说过，Kubernetes要求位于不同Node上的Pod都能够彼此直接通信，所以Kubernetes中一个Pod里的容器访问另外一个Pod里的容器时，就是通过Pod IP所在的虚拟二层网络进行通信的，而真实的TCP/IP流量是通过Node IP所在的物理网卡流出的。 在Kubernetes集群内，Service的ClusterIP地址属于集群内的地址，无法在集群外直接使用这个地址。为了解决这个问题，Kubernetes首先引入了NodePort这个概念，NodePort也是解决集群外的应用访问集群内服务的直接、有效的常见做法 NodePort的实现方式是，在Kubernetes集群的每个Node上都为需要外部访问的Service开启一个对应的TCP监听端口，外部系统只要用任意一个Node的IP地址+NodePort端口号即可访问此服务，在任意Node上运行netstat命令，就可以看到有NodePort端口被监听。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:8:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"NodePort 存在的一问题引出了Ingress对象 NodePort的确功能强大且通用性强，但也存在一个问题，即每个Service都需要在Node上独占一个端口，而端口又是有限的物理资源，那能不能让多个Service共用一个对外端口呢？这就是后来增加的Ingress资源对象所要解决的问题。在一定程度上，我们可以把Ingress的实现机制理解为基于Nginx的支持虚拟主机的HTTP代理。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:9:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"有状态的应用集群 我们知道，Deployment对象是用来实现无状态服务的多副本自动控制功能的，那么有状态的服务，比如ZooKeeper集群、MySQL高可用集群（3节点集群）、Kafka集群等是怎么实现自动部署和管理的呢？这个问题就复杂多了，这些一开始是依赖StatefulSet解决的，但后来发现对于一些复杂的有状态的集群应用来说，StatefulSet还是不够通用和强大，所以后面又出现了Kubernetes Operator。 我们先说说StatefulSet。StatefulSet之前曾用过PetSet这个名称，很多人都知道，在IT世界里，有状态的应用被类比为宠物（Pet），无状态的应用则被类比为牛羊，每个宠物在主人那里都是\"唯一的存在\"，宠物生病了，我们是要花很多钱去治疗的，需要我们用心照料，而无差别的牛羊则没有这个待遇。总结下来，在有状态集群中一般有如下特殊共性。 每个节点都有固定的身份ID，通过这个ID，集群中的成员可以相互发现并通信。 集群的规模是比较固定的，集群规模不能随意变动。 集群中的每个节点都是有状态的，通常会持久化数据到永久存储中，每个节点在重启后都需要使用原有的持久化数据。 集群中成员节点的启动顺序（以及关闭顺序）通常也是确定的。 如果磁盘损坏，则集群里的某个节点无法正常运行，集群功能受损 StatefulSet从本质上来说，可被看作Deployment/RC的一个特殊变种，它有如下特性。 StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群内的其他成员。假设StatefulSet的名称为kafka，那么第1个Pod叫kafka-0，第2个叫kafka-1，以此类推。 StatefulSet控制的Pod副本的启停顺序是受控的，操作第n个Pod时，前n-1个Pod已经是运行且准备好的状态。 StatefulSet里的Pod采用稳定的持久化存储卷，通过PV或PVC来实现，删除Pod时默认不会删除与StatefulSet相关的存储卷（为了保证数据安全）。 StatefulSet除了要与PV卷捆绑使用，以存储Pod的状态数据，还要与Headless Service配合使用，即在每个StatefulSet定义中都要声明它属于哪个Headless Service。StatefulSet在Headless Service的基础上又为StatefulSet控制的每个Pod实例都创建了一个DNS域名，这个域名的格式 如下： ${podname}.${headless service name} StatefulSet的建模能力有限，面对复杂的有状态集群时显得力不从心，所以就有了后来的Kubernetes Operator框架和众多的Operator实现了。需要注意的是，Kubernetes Operator框架并不是面向普通用户的，而是面向Kubernetes平台开发者的。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:10:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"批处理应用 除了无状态服务、有状态集群、常见的第三种应用，还有批处理应用。批处理应用的特点是一个或多个进程处理一组数据（图像、文件、视频等），在这组数据都处理完成后，批处理任务自动结束。为了支持这类应用，Kubernetes引入了新的资源对象——Job。 Jobs控制器提供了两个控制并发数的参数：completions和parallelism，completions表示需要运行任务数的总数，parallelism表示并发运行的个数，例如设置parallelism为1，则会依次运行任务，在前面的任务运行后再运行后面的任务。Job所控制的Pod副本是短暂运行的，可以将其视为一组容器，其中的每个容器都仅运行一次。当Job控制的所有Pod副本都运行结束时，对应的Job也就结束了。Job在实现方式上与Deployment等副本控制器不同，Job生成的Pod副本是不能自动重启的，对应Pod副本的restartPolicy都被设置为Never，因此，当对应的Pod副本都执行完成时，相应的Job也就完成了控制使命。后来，Kubernetes增加了CronJob，可以周期性地执行某个任务。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:11:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"应用的配置问题 通过前面的学习，我们初步理解了三种应用建模的资源对象，总结如下。 无状态服务的建模：Deployment。 有状态集群的建模：StatefulSet。 批处理应用的建模：Job。 在进行应用建模时，应该如何解决应用需要在不同的环境中修改配置的问题呢？这就涉及ConfigMap和Secret两个对象。 ConfigMap顾名思义，就是保存配置项（key=value）的一个Map，如果你只是把它理解为编程语言中的一个Map，那就大错特错了。ConfigMap是分布式系统中\"配置中心\"的独特实现之一。我们知道，几乎所有应用都需要一个静态的配置文件来提供启动参数，当这个应用是一个分布式应用，有多个副本部署在不同的机器上时，配置文件的分发就成为一个让人头疼的问题，所以很多分布式系统都有一个配置中心组件，来解决这个问题。但配置中心通常会引入新的API，从而导致应用的耦合和侵入。 用户将配置文件的内容保存到ConfigMap中，文件名可作为key，value就是整个文件的内容，多个配置文件都可被放入同一个ConfigMap。 在建模用户应用时，在Pod里将ConfigMap定义为特殊的Volume进行挂载。在Pod被调度到某个具体Node上时，ConfigMap里的配置文件会被自动还原到本地目录下，然后映射到Pod里指定的配置目录下，这样用户的程序就可以无感知地读取配置了。 在ConfigMap的内容发生修改后，Kubernetes会自动重新获取ConfigMap的内容，并在目标节点上更新对应的文件。 接下来说说Secret。Secret也用于解决应用配置的问题，不过它解决的是对敏感信息的配置问题，比如数据库的用户名和密码、应用的数字证书、Token、SSH密钥及其他需要保密的敏感配置。对于这类敏感信息，我们可以创建一个Secret对象，然后被Pod引用。Secret中的数据要求以BASE64编码格式存放。注意，BASE64编码并不是加密的，在Kubernetes 1.7版本以后，Secret中的数据才可以以加密的形式进行保存，更加安全。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:12:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"应用的运维问题 最后说说与应用的自动运维相关的几个重要对象。 首先就是HPA（Horizontal Pod Autoscaler），如果我们用Deployment来控制Pod的副本数量，则可以通过手工运行kubectl scale命令来实现Pod扩容或缩容。如果仅仅到此为止，则显然不符合谷歌对Kubernetes的定位目标——自动化、智能化。在谷歌看来，分布式系统要能够根据当前负载的变化自动触发水平扩容或缩容，因为这一过程可能是频繁发生、不可预料的，所以采用手动控制的方式是不现实的，因此就有了后来的HPA这个高级功能。我们可以将HPA理解为Pod横向自动扩容，即自动控制Pod数量的增加或减少。通过追踪分析指定Deployment控制的所有目标Pod的负载变化情况，来确定是否需要有针对性地调整目标Pod的副本数量，这是HPA的实现原理。Kubernetes内置了基于Pod的CPU利用率进行自动扩缩容的机制，应用开发者也可以自定义度量指标如每秒请求数，来实现自定义的HPA功能。 存储类 存储类的资源对象主要包括Volume、Persistent Volume、PVC和StorageClass。 首先看看基础的存储类资源对象——Volume（存储卷） Volume是Pod中能够被多个容器访问的共享目录。Kubernetes中的Volume概念、用途和目的与Docker中的Volume比较类似，但二者不能等价。首先，Kubernetes中的Volume被定义在Pod上，被一个Pod里的多个容器挂载到具体的文件目录下；其次，Kubernetes中的Volume与Pod的生命周期相同，但与容器的生命周期不相关，当容器终止或者重启时，Volume中的数据也不会丢失；最后，Kubernetes支持多种类型的Volume，例如GlusterFS、Ceph等分布式文件系统。Volume的使用也比较简单，在大多数情况下，我们先在Pod上声明一个Volume，然后在容器里引用该Volume并将其挂载（Mount）到容器里的某个目录下。举例来说，若我们要给之前的Tomcat Pod增加一个名为datavol的Volume，并将其挂载到容器的某个路径/mydata-data目录下，则只对Pod的定义文件做下修正即可。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:13:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"emptyDir 一个emptyDir是在Pod分配到Node时创建的。从它的名称就可以看出，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为这是Kubernetes自动分配的一个目录，当Pod从Node上移除时，emptyDir中的数据也被永久移除。emptyDir的一些用途如下。 临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留。 长时间任务执行过程中使用的临时目录。 一个容器需要从另一个容器中获取数据的目录（多容器共享目录）。 在默认情况下，emptyDir使用的是节点的存储介质，例如磁盘或者网络存储。还可以使用emptyDir.medium属性，把这个属性设置为\"Memory\"，就可以使用更快的基于内存的后端存储了。需要注意的是，这种情况下的emptyDir使用的内存会被计入容器的内存消耗，将受到资源限制和配额机制的管理。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:14:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"hostPath hostPath为在Pod上挂载宿主机上的文件或目录，通常可以用于以下几方面。 在容器应用程序生成的日志文件需要永久保存时，可以使用宿主机的高速文件系统对其进行存储。 需要访问宿主机上Docker引擎内部数据结构的容器应用时，可以通过定义hostPath为宿主机/var/lib/docker目录，使容器内部的应用可以直接访问Docker的文件系统。 在使用这种类型的Volume时，需要注意以下几点。 在不同的Node上具有相同配置的Pod，可能会因为宿主机上的目录和文件不同，而导致对Volume上目录和文件的访问结果不一致。 如果使用了资源配额管理，则Kubernetes无法将hostPath在宿主机上使用的资源纳入管理。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:15:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"公有云Volume 公有云提供的Volume类型包括谷歌公有云提供的GCEPersistentDisk、亚马逊公有云提供的AWS Elastic Block Store（EBSVolume）等。当我们的Kubernetes集群运行在公有云上或者使用公有云厂家提供的Kubernetes集群时，就可以使用这类Volume。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:16:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"其他类型的Volume iscsi：将iSCSI存储设备上的目录挂载到Pod中。 nfs：将NFS Server上的目录挂载到Pod中。 glusterfs：将开源GlusterFS网络文件系统的目录挂载到Pod中。 rbd：将Ceph块设备共享存储（Rados Block Device）挂载到Pod中。 gitRepo：通过挂载一个空目录，并从Git库克隆（clone）一个git repository以供Pod使用。 configmap：将配置数据挂载为容器内的文件。 secret：将Secret数据挂载为容器内的文件。 安全类 安全始终是Kubernetes发展过程中的一个关键领域。 从本质上来说，Kubernetes可被看作一个多用户共享资源的资源管理系统，这里的资源主要是各种Kubernetes里的各类资源对象，比如Pod、Service、Deployment等。只有通过认证的用户才能通过Kubernetes的API Server查询、创建及维护相应的资源对象，理解这一点很关键。 Kubernetes里的用户有两类：我们开发的运行在Pod里的应用；普通用户，如典型的kubectl命令行工具，基本上由指定的运维人员（集群管理员）使用。在更多的情况下，我们开发的Pod应用需要通过API Server查询、创建及管理其他相关资源对象，所以这类用户才是Kubernetes的关键用户。为此，Kubernetes设计了Service Account这个特殊的资源对象，代表Pod应用的账号，为Pod提供必要的身份认证。在此基础上，Kubernetes进一步实现和完善了基于角色的访问控制权限系统——RBAC（Role-Based Access Control）。 在默认情况下，Kubernetes在每个命名空间中都会创建一个默认的名称为default的Service Account，因此Service Account是不能全局使用的，只能被它所在命名空间中的Pod使用。通过以下命令可以查看集群中的所有Service Account： sudo kubectl get sa -A Service Account是通过Secret来保存对应的用户（应用）身份凭证的，这些凭证信息有CA根证书数据（ca.crt）和签名后的Token信息（Token）。在Token信息中就包括了对应的Service Account的名称，因此API Server通过接收到的Token信息就能确定Service Account的身份。在默认情况下，用户创建一个Pod时，Pod会绑定对应命名空间中的default这个Service Account作为其\"公民身份证\"。当Pod里的容器被创建时，Kubernetes会把对应的Secret对象中的身份信息（ca.crt、Token等）持久化保存到容器里固定位置的本地文件中，因此当容器里的用户进程通过Kubernetes提供的客户端API去访问API Server时，这些API会自动读取这些身份信息文件，并将其附加到HTTPS请求中传递给API Server以完成身份认证逻辑。在身份认证通过以后，就涉及\"访问授权\"的问题，这就是RBAC要解决的问题了。 首先我们要学习的是Role这个资源对象，包括Role与ClusterRole两种类型的角色。角色定义了一组特定权限的规则，比如可以操作某类资源对象。局限于某个命名空间的角色由Role对象定义，作用于整个Kubernetes集群范围内的角色则通过ClusterRole对象定义。 在RoleBinding中使用subjects（目标主体）来表示要授权的对象，这是因为我们可以授权三类目标账号：Group（用户组）、User（某个具体用户）和Service Account（Pod应用所使用的账号）。 在安全领域，除了以上针对API Server访问安全相关的资源对象，还有一种特殊的资源对象——NetworkPolicy（网络策略），它是网络安全相关的资源对象，用于解决用户应用之间的网络隔离和授权问题。NetworkPolicy是一种关于Pod间相互通信，以及Pod与其他网络端点间相互通信的安全规则设定。 NetworkPolicy资源使用标签选择Pod，并定义选定Pod所允许的通信规则。在默认情况下，Pod间及Pod与其他网络端点间的访问是没有限制的，这假设了Kubernetes集群被一个厂商（公司/租户）独占，其中部署的应用都是相互可信的，无须相互防范。但是，如果存在多个厂商共同使用一个Kubernetes集群的情况，则特别是在公有云环境中，不同厂商的应用要相互隔离以增加安全性，这就可以通过NetworkPolicy来实现了。 ","date":"2021-06-13","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:17:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Influxdb"],"content":"InfluxDB 基础了解 ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:1:0","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Influxdb"],"content":"介绍 一个开源的时间序列数据库 ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:1:1","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Influxdb"],"content":"特性 1、内置HTTP-API,无需编写服务端代码来启动和运行。 2、数据可以被标记，允许非常灵活的查询 3、类似SQL一样的查询语言 4、简单的安装和管理， 快速的获取和输出数据 5、它的目标是符合实时查询， 这意味着每一个数据点都会被索引，并且可以立即在小于100ms的查询中获得 docker 创建容器实例 docker run --name=cm2-influxdb -d -p 8530:8083 -p 8586:8086 \\ -v /opt/influxdata:/var/lib/influxdb \\ -m 10g \\ --restart=always \\ influxdb:1.8 ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:1:2","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Influxdb"],"content":"配置鉴权 ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:2:0","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Influxdb"],"content":"添加鉴权配置 [http] enabled = true bind-address = \":8086\" auth-enabled = true log-enabled = true ping-auth-enabled = true 重启influxdb服务 未添加鉴权 $ curl -G http://172.16.24.220:8586/query --data-urlencode \"q=SHOW DATABASES\" {\"results\":[{\"statement_id\":0,\"series\":[{\"name\":\"databases\",\"columns\":[\"name\"],\"values\":[[\"host_metrics\"],[\"vnf_metrics\"],[\"events\"],[\"alarm\"],[\"custom_metrics\"],[\"_internal\"],[\"k8s_metrics\"],[\"mw_metrics\"],[\"bss_metrics\"],[\"application_metrics\"],[\"oss_metrics\"],[\"itracing_metrics\"],[\"prometheus_metrics\"],[\"dcm_metrics\"]]}]}]} 添加鉴权未创建用户,提示需要创建鉴权用户或者关闭鉴权 curl -G http://172.16.17.82:8586/query --data-urlencode \"q=SHOW DATABASES\" [lushuan@220 nms-influxdb]$ curl -G http://172.16.24.220:8586/query --data-urlencode \"q=SHOW DATABASES\" {\"error\":\"error authorizing query: create admin user first or disable authentication\"} 登录influxdb 容器创建用户 docker exec -it cm2-influxdb sh \u003e influx \u003e CREATE USER admin WITH PASSWORD 'password' WITH ALL PRIVILEGES 再次测试 $ curl -G http://172.16.24.220:8586/query -u admin:abc@123A --data-urlencode \"q=SHOW DATABASES\" {\"results\":[{\"statement_id\":0,\"series\":[{\"name\":\"databases\",\"columns\":[\"name\"],\"values\":[[\"host_metrics\"],[\"vnf_metrics\"],[\"events\"],[\"alarm\"],[\"custom_metrics\"],[\"_internal\"],[\"k8s_metrics\"],[\"mw_metrics\"],[\"bss_metrics\"],[\"application_metrics\"],[\"oss_metrics\"],[\"itracing_metrics\"],[\"prometheus_metrics\"],[\"dcm_metrics\"]]}]}]} ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:2:1","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Influxdb"],"content":"参考 influxdb 官网 ","date":"2021-05-28","objectID":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/:3:0","tags":["Influxdb"],"title":"Influxdb 添加鉴权","uri":"/influxdb-%E9%85%8D%E7%BD%AE%E9%89%B4%E6%9D%83/"},{"categories":["Kubernetes"],"content":"背景 通过 kubeadm 安装k8s v1.20 集群报错 操作系统环境信息 $ cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"18.04.5 LTS (Bionic Beaver)\" ID=ubuntu ID_LIKE=debian PRETTY_NAME=\"Ubuntu 18.04.5 LTS\" VERSION_ID=\"18.04\" HOME_URL=\"https://www.ubuntu.com/\" SUPPORT_URL=\"https://help.ubuntu.com/\" BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\" PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" VERSION_CODENAME=bionic UBUNTU_CODENAME=bionic kubeadm init 安装报错信息 [kubelet-check] It seems like the kubelet isn't running or healthy. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - 'systemctl status kubelet' - 'journalctl -xeu kubelet' Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - 'docker ps -a | grep kube | grep -v pause' Once you have found the failing container, you can inspect its logs with: - 'docker logs CONTAINERID' ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:1:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"排查思路 查看官网介绍为 docker 和 kubelet 服务中的 cgroup 驱动不一致，有两种方法 方式一：驱动向 docker 看齐 方式二：驱动为向 kubelet 看齐 如果docker 不方便重启则统一向 kubelet看齐，并重启对应的服务即可 ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:2:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"解决方式 ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"docker 配置文件 这里采取的是方式二，docker 默认驱动为 cgroupfs ,只需要添加 \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], 修改后配置文件 $ cat /etc/docker/daemon.json { \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], \"bip\":\"172.12.0.1/24\", \"registry-mirrors\": [ \"http://docker-registry-mirror.kodekloud.com\" ] } 重启docker systemctl restart docker ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:1","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"kublete 配置文件 grep 截取一下,可以看得出来kubelet默认 cgoup 驱动为systemd $ cat /var/lib/kubelet/config.yaml |grep group cgroupDriver: systemd 重启kubelet （optional） systemctl restart kubelet ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:2","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"参考 配置cgroup驱动 Docker中的Cgroup Driver:Cgroupfs 与 Systemd 为什么要修改docker的cgroup driver ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:4:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["linux"],"content":"打算给一台服务器做逻辑卷分区，发现磁盘未做分区，且磁盘空间余量较大，本篇记录一下 fdisk 磁盘分区划分的过程 fdisk\r","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"事情的起因 通过pvcreate 创建逻辑卷组提示报错 报错信息 警告\rCan’t open /dev/sda1 exclusively. Mounted filesystem?\r通过 fdisk -l 查看该分区为boot 分区无法创建逻辑卷。fdisk -l 可以用来查看磁盘的所有分区 $ fdisk -l Disk /dev/sda: 1000.2 GB, 1000171331584 bytes, 1953459632 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 262144 bytes / 262144 bytes Disk label type: dos Disk identifier: 0x0003eb01 Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 276834303 137367552 8e Linux LVM 从上面的信息可以了解到磁盘/dev/sda划分了两个分区，且扇区大小为512字节，boot 分区大小为(2099199-2048)*512/1024/1024=1G, 且通过pvdisplay查看该/dev/sda2 分区为131G，已经全部用完。总的磁盘有1000.2 GB 可用，抛出boot /dev/sda1分区和/dev/sda2 的 131GB空间，还剩800多GB的磁盘空间未使用。闲言少叙，开始通过fdisk划分新的磁盘分区/dev/sda3 主分区和扩展分区 fdisk\r","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:1:0","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"划分磁盘分区 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:2:0","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"首先了解什么是 fdisk 命令 fdisk 的意思是 固定磁盘(Fixed Disk) 或 格式化磁盘(Format Disk)，它是命令行下允许用户对分区进行查看、创建、调整大小、删除、移动和复制的工具。它支持 MBR、Sun、SGI、BSD 分区表，但是它不支持 GUID 分区表（GPT）。它不是为操作大分区设计的。 fdisk 允许我们在每块硬盘上创建最多四个主分区。它们中的其中一个可以作为扩展分区，并下设多个逻辑分区。1-4 扇区作为主分区被保留，逻辑分区从扇区 5 开始。 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:2:1","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"查看分区 fdisk 查看特定分区 fdisk -l /dev/sda fdisk交互指令说明 命令 说明 是否常用 a 设置可引导标记 否 b 编辑bsd磁盘标签 否 c 设置DOS操作系统兼容标记 否 d 删除一个分区 注：这是删除一个分区的动作 是 l 显示已知的分区类型。82 为Linux swap分区，83为Linux分区 注：l是列出分区类型，以供我们设置相应分区的类型； 是 m m 是列出帮助信息 是 n 添加一个分区 是 o 建立空白DOS分区表 否 p p列出分区表 是 q 不保存退出 是 s 新建空白SUN磁盘标签 否 t 改变一个分区的系统ID 是 u 改变显示记录单位 否 v 验证分区表 否 w 把分区表写入硬盘并退出 是 x 扩展应用，专家功能 否 关注一下常用命令即可 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:2:2","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"创建扩展分区 列出当前操作硬盘的分区情况，用 p $ fdisk /dev/sda Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default e): p 新建磁盘分区，用 n,在创建的时候会提示选择是使用主分区还是逻辑分区，见扩展一。 直接下一步会提示创建分区的大小，指定分区大小时直接默认起始扇区后，在last Sector size 处直接+400GB，最后 选择 w进行保存，这个不要忘记。这个时候分区已经分配好了，但是还不能使用，因为没有对该分区进行格式化操作，指定分区文件系统。 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:3:0","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"指定分区文件系统并生效分区 选择不同文件系统的性能也不通，选择合适的文件系统对分区进行格式，在格式化文件系统前先更新分区表。重新扫描分区表需要借助partprobe命令。 partprobe命令是用于重新扫描系统上的分区表，以便内核能够识别新创建或修改的分区。当您在不重启系统的情况下对磁盘进行了分区或调整分区大小时，可以使用partprobe命令通知内核更新分区信息。 partprobe命令会读取分区表并向内核发送信号，让内核重新加载分区信息。这样，系统就能够识别到最新的分区信息，并使其可用于挂载和访问。 $ partprobe $ cat /proc/partitions major minor #blocks name 8 0 976729816 sda 8 1 1048576 sda1 8 2 137367552 sda2 8 3 412102655 sda3 [root@CENTOS7 temp]# mkfs.ext3 /dev/sda3 注意：partprobe命令需要root权限才能执行。在执行partprobe之后，您可以使用相应的命令（例如fdisk或lsblk）来检查分区是否已成功更新。 格式化完分区表后那么到此就完成了，我的目标是完成硬盘分区来创建物理卷。后续可以参考逻辑卷组管理文章 如： pvcreate /dev/sda3 vgcreate vgdata /dev/sda3 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:3:1","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"设置开机挂载 设置开机挂载需同步至 /etc/fstab 文件中 示例 mkdir -p /var/lib/kubelet lvcreate -n lvkubelet -L +35G vgdata mkfs.xfs /dev/vgdata/lvkubelet echo \"/dev/mapper/vgdata-lvkubelet /var/lib/kubelet xfs defaults 0 0\" \u003e\u003e /etc/fstab mount -a ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:3:2","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["linux"],"content":"扩展一：fdisk 新增主分区和扩展分区的主要区别 主分区(Primary Partition)是硬盘上的基本分区,每个硬盘最多可以创建4个主分区。 扩展分区(Extended Partition)是一种特殊的主分区,它不能直接存储数据,仅可用于扩展更多的逻辑分区。每个硬盘只能创建1个扩展分区。 主分区可以直接存储数据,而扩展分区内需要再创建逻辑分区(Logical Partition)才能存储数据。 主分区对文件系统格式化的支持更广泛,可支持各种文件系统。扩展分区和逻辑分区仅支持部分文件系统。 主分区的访问效率稍高一些。扩展分区和逻辑分区的访问会稍微低一些。 如果没有空间限制,建议使用主分区。如果磁盘空间不足,可以使用扩展分区额外增加更多分区。 所以总的来说,主分区更基础和通用,扩展分区可以提供更多额外的分区数。选择时需要根据实际磁盘空间及使用需求来决定。 小结：有主选主，主分区更基础和通用 ","date":"2021-04-29","objectID":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/:3:3","tags":["linux"],"title":"fdisk 磁盘管理详解","uri":"/fdisk%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E8%AF%A6%E8%A7%A3/"},{"categories":["Git"],"content":"创建版本库 $ git clone \u003curl\u003e # 克隆远程仓库 $ git init # 初始化本地仓库 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:1:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"Git 全局设置 git config --global user.name \"lu.shua\" git config --global user.email \"lu.shuan@iwhalecloud.com\" ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"修改和提交 $ git status # 查看状态 $ git diff # 查看变更内容 $ git add . # 跟踪所有改动过的文件 $ git add \u003cfile\u003e # 跟踪指定的文件 $ git mv \u003cold\u003e \u003cnew\u003e# 文件改名 $ git rm \u003cfile\u003e # 删除文件 $ git rm --cached \u003cfile\u003e # 停止跟踪文件但不删除 $ git commit -m \"commit message\" # 修改所有更新过的文件 $ git commit --amend # 修改最后一次提交 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"查看提交历史 $ git log # 查看提交历史 $ git log -p \u003cfile\u003e # 查看指定文件的提交历史 $ git blame \u003cfile\u003e # 以列表的方式查看指定文件的提交历史 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:4:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"撤销操作 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复暂存区当前目录的所有文件到工作区 $ git checkout . # 恢复工作区到指定 commit $ git checkout [commit] # 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变 $ git reset [file] # 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定 commit，同时重置暂存区和工作区，与指定 commit 一致 $ git reset --hard [commit] ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:5:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"分支与标签 $ git branch # 显示所有本地分支 $ git checkout \u003cbranch/tag\u003e # 切换到指定分支活标签 $ git branch \u003cnew-branch\u003e # 创建新分支 $ git branch -d \u003cbranch\u003e # 删除本地分支 $ git tag # 列出本地标签 $ git tag \u003ctagname\u003e # 基于最新提交创建标签 $ git tag -d \u003ctagname\u003e # 删除标签 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:6:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"合并与衍合 $ git merge \u003cbranch\u003e # 合并指定分支到当前分支 $ git rebase \u003cbranch\u003e # 衍合指定分支到当前分支 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:7:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"远程操作 $ git remote -v # 查看远程版本库信息 $ git remove show \u003cremote\u003e # 查看指定远程版本库信息 $ git remote add \u003cremote\u003e \u003curl\u003e # 添加远程版本库 $ git fetch \u003cremote\u003e # 从远程库获取代码 $ git pull \u003cremote\u003e \u003cbranch\u003e# 下载代码及快速合并 $ git push \u003cremote\u003e \u003cbranch\u003e# 上传代码及快速合并 $ git push \u003cremote\u003e :\u003cbranch/tag-name\u003e # 删除远程分支活标签 $ git push --tags # 上传所有标签 ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:8:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"创建一个新仓库 git clone git@gitlab.iwhalecloud.com:monitor/nms-arm.git cd nms-arm touch README.md git add README.md git commit -m \"add README\" git push -u origin master ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:9:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"推送现有文件夹至remote repository cd existing_folder git init git remote add origin git@gitlab.iwhalecloud.com:monitor/nms-arm.git git add . git commit -m \"Initial commit\" git push -u origin master ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:10:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["Git"],"content":"github 创建仓库引导命令 create a new repository on the command line echo \"# blog\" \u003e\u003e README.md git init git add README.md git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/username/blog.git git push -u origin main push an existing repository from the command line git remote add origin https://github.com/username/blog.git git branch -M main git push -u origin main ","date":"2021-04-17","objectID":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:11:0","tags":["Git"],"title":"Git 常用操作","uri":"/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"categories":["linux"],"content":"背景 部署 k8s 时需要对磁盘进行分区划分，正常是集成是直接给创建好的，现场在沟通过程中只提供了一块磁盘。 本篇文章记录一下磁盘分区划分的原理和步骤，尽量选择大白话。 lvm\r","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:1:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"lvm 介绍 LVM——全称Logical Volume Manager，可以将多个硬盘和硬盘分区做成一个逻辑卷，并把这个逻辑卷作为一个整体来统一管理，动态对分区进行扩缩空间大小，提高磁盘管理灵活性。 在安装CentOS 7的过程中选择自动分区时，默认就是以LVM的方案安装的系统。 但是/boot分区必须独立出来，不能基于LVM创建。 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:2:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"三个概念 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:3:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"PV(Physical Volume) 物理卷 物理卷，Physical Volume，是LVM机制的基本存储设备，通常对应一个普通分区或是整个硬盘。 创建物理卷时，会在分区或磁盘头部创建一个用于记录LVM属性的保留区块，并把存储空间分割成默认大小为4MB的基本单元（Physical Extend，PE），从而构成物理卷。 普通分区先转换分区类型为8e；整块硬盘，可以将所有的空间划分为一个主分区再做调整 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:3:1","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"VG(Volume Group) 卷组 卷组，Volume Group，是由一个或多个物理卷组成的一个整体。可以动态添加、移除物理卷，创建时可以指定PE大小 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:3:2","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"LV(Logical Volume) 逻辑卷 逻辑卷，Logical Volume，建立在卷组之上，与物理卷没有直接关系。格式化后，即可挂载使用。 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:3:3","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"三者关系 lvm\r","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:4:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"lvm特点 LVM最大的特点就是可以对磁盘进行动态管理。因为逻辑卷的大小是可以动态调整的，而且不会丢失现有的数据。我们如果新增加了硬盘，其也不会改变现有上层的逻辑卷。作为一个动态磁盘管理机制，逻辑卷技术大大提高了磁盘管理的灵活性！ ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:5:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"工作原理 物理磁盘被格式化为PV，空间被划分为一个个的PE 不同的PV加入到同一个VG中，不同PV的PE全部进入到了VG的PE池内 LV基于PE创建，大小为PE的整数倍，组成LV的PE可能来自不同的物理磁盘 LV现在就直接可以格式化后挂载使用了 LV的扩充缩减实际上就是增加或减少组成该LV的PE数量，其过程不会丢失原始数据 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:6:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"讲个故事 上面工作原理可以做一个类比，集成提供的挂载磁盘可以理解为一堆小麦，pv的作用是将这一堆小麦打磨成面粉， 不管挂载多少个磁盘pv都可以做成面粉，一堆一堆的面粉(pv格式化的各个磁盘)可以加入到一个VG中， 这个VG可以理解为一个供销社将所有的面粉进行了纳管，当然也可以不同的面粉划分给不同的供销社, 意思就是四块磁盘A、B、C、D 通过打面机pv做成了四份面粉，A、C份面粉卖给了大脚供销社VG-DJ,C、D两份面粉卖给了小脚供销社 VG-XJ,现在亚洲舞王尼古拉斯赵四想要吃馒头，就选择了去大脚供销社去购买面粉，打算购买50斤面粉。这50斤面粉供销提供的lv, lv 一小份的面粉是来自于vg供销社而不是pv 面粉制造机器。下面会给出示例从小麦生产到赵四购买面粉。 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:7:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"操作 lvm\r","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:8:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"分区操作 1、 查看磁盘 通过fdisk -l可以看出集成提供了一块600多G的磁盘 /dev/xvdc $ fdisk -l .... Disk /dev/xvdc: 644.2 GB, 644245094400 bytes, 1258291200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 2、 创建物理卷 pv 将小麦加工成面粉，原理是物理磁盘被格式化为PV，空间被划分为一个个的PE $ pvcreate /dev/xvdc Physical volume \"/dev/xvdc\" successfully created 3、 创建逻辑卷组 将面粉运输至大脚供销社vgdata,vgdata 是自定义的逻辑卷组名 $ vgcreate vgdata /dev/xvdc Volume group \"vgdata\" successfully created $ vgs VG #PV #LV #SN Attr VSize VFree centos 1 3 0 wz--n- \u003c99.00g 0 datavg 1 1 0 wz--n- \u003c400.00g 4.00m vgdata 1 0 0 wz--n- \u003c600.00g \u003c600.00g 4、创建逻辑卷 可以看的出来逻辑卷的创建是来自于逻辑卷组vg,后面的扩容也是从逻辑卷组进行扩容，这个步骤可以比喻为赵四去大脚超市 购买了35斤的面粉 mkdir -p /var/lib/kubelet lvcreate -n lvkubelet -L +35G vgdata mkfs.xfs /dev/vgdata/lvkubelet echo \"/dev/mapper/vgdata-lvkubelet /var/lib/kubelet xfs defaults 0 0\" \u003e\u003e /etc/fstab mount -a 查看逻辑卷是否挂载成功 $ df -h|grep kubelet /dev/mapper/vgdata-lvkubelet 35G 35M 35G 1% /var/lib/kubelet ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:8:1","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"相关操作命令 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:9:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"创建逻辑卷 Linux 系统使用逻辑卷来模拟物理分区，并在其中保存文件系统。 选 项 长选项名 描 述 -c –chunksize 指定快照逻辑卷的单位大小 -C –contiguous 设置或重置连续分配策略 -i –stripes 指定条带数 -I –stripesize 指定每个条带的大小 -l –extents 指定分配给新逻辑卷的逻辑区段数，或者要用的逻辑区段的百分比 -L –size 指定分配给新逻辑卷的硬盘大小 -M –persistent 让次设备号一直有效 -n –name 指定新逻辑卷的名称 -p –permission 为逻辑卷设置读/写权限 -r –readahead 设置预读扇区数 -R –regionsize 指定将镜像分成多大的区 -s snapshot 创建快照逻辑卷 -Z –zero 将新逻辑卷的前1 KB数据设置为零 -m –mirrors 创建逻辑卷镜像 空 –minor 指定设备的次设备号 参数很多，其实常用的就几个 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:9:1","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"指定逻辑卷大小 如逻辑卷组 Vol1 lvcreate -n lvtest -L +32G Vol1 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:9:2","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"创建文件系统 此时只有逻辑卷没有文件系统，需要给逻辑卷指定文件系统 这里的文件系统指定的是ext4，公司生产环境中使用的是 xfs 文件系统如mkfs.xfs /dev/vgdata/lvkubelet，以下示例使用的是ext4文件系统，不同文件系统的差别请自行了解，这里不做说明 sudo mkfs.ext4 /dev/Vol1/lvtest mke2fs 1.41.12 (17-May-2010) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 131376 inodes, 525312 blocks 26265 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=541065216 17 block groups 32768 blocks per group, 32768 fragments per group 7728 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912 Writing inode tables: done Creating journal (16384 blocks): done Writing superblocks and filesystem accounting information: done This filesystem will be automatically checked every 28 mounts or 180 days, whichever comes first.Use tune2fs -c or -i to override. ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:10:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"目录挂载 在创建了文件系统后需要将该逻辑卷挂载到指定的虚拟目录下，就跟他是物理分区一样 sudo mount /dev/Vol1/lvtest /mnt/my_partition 命令解释是将逻辑卷挂载到指定虚拟目录上 设置挂载永久生效，否则机器重启后会丢失掉 注意修改名称 echo \"/dev/mapper/$vgname-lvdocker /var/lib/docker xfs defaults 0 0\" \u003e\u003e /etc/fstab ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:10:1","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"修改LVM 命 令 功 能 vgchange 激活和禁用卷组 vgremove 删除卷组 vgextend 将物理卷加到卷组中 vgreduce 从卷组中删除物理卷 lvextend 增加逻辑卷的大小 lvreduce 减小逻辑卷的大小 通过以上命令可以完全控制你的LVM环境 如扩容 扩容前先取消挂载 umount /mnt/my_partition # 对/dev/Vol1/lvtest 增加1G lvextend -L +1G /dev/Vol1/lvtest -r # 重新挂载设备，并查看挂载状态 mount -a df -h ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:10:2","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"LVM 命令汇总 功能 pv命令 vg命令 lv命令 扫描 pvscan vgscan lvscan Create创建 pvcreate vgcreate lvcreate Display显示 pvdisplay vgdisplay lvdisplay Remove移除 pvremove vgremove lvremove Extend扩展 - vgextend lvextend Reduce减少 - vgreduce lvreduce 关于收缩 LVM 逻辑卷，可以参考上面的命令lvreduce。这会涉及到数据安全性问题，谨慎使用 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:11:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"小结 就是三步走，创建物理卷，创建卷组，创建逻辑卷，然后格式化并挂载使用。扩容的话，没有挂载使用，就正常扩，然后格式化挂载，已经挂载使用了，扩容后在线调整生效。 ","date":"2021-03-18","objectID":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/:12:0","tags":["linux"],"title":"lvm 逻辑卷组管理","uri":"/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E7%BB%84%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":"简介 之所以能用到这个命令，是由于很多 linux 命令不支持用管道传递参数，xargs 可以理解为参数转换器，例如 #错误指令 find /sbin -perm +700 | ls -l #正确指令 find /sbin -perm +700 |xargs ls -l 通常Linux命令可以用|首尾相连，上一个命令的 stdout 连接到下一个命令的 stdin。但是有些命令，比如ls、rm等，是从命令行参数接受输入的。这时候如果想把上一个命令的输出传给它们，就不好办了。所以就有了xargs。 简单而言，xargs可以把从 stdin 接受到的输入，按空白符或加车符分隔开，然后依次作为参数去调用xargs后面的命令 xargs 默认的分隔符：空格 或 回车 ","date":"2021-02-28","objectID":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/:1:0","tags":["linux"],"title":"xargs原理及使用","uri":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["linux"],"content":"参数使用 想把所有.jpg文件删除，当然你可以 rm *.jpg，但是如果要递归操作所有子目录下的文件呢？ 可以这样： find . -name \"*.jpg\" | xargs rm 这样，所有被find找到的文件名，都会作为参数来调用rm命令了 对于大多数情况，这一行命令没有问题，但是如有些文件名中包含空格，就会有问题了。 xargs默认以空白符分隔接受到的输入，所以一个含有空格的文件名会被当做多个参数，分别传给rm。所以在处理文件名这类命令时，通常要这样 find . -name \"*.jpg\" -print0 | xargs -0 rm 这里的 -print0 是告诉find命令，在每个输出后面以’\\0’作为结束。-0是告诉xargs，使用’\\0’来分隔输入，而不是空白符。这样就避免出现问题了。 下面再考虑另一种情况，假设不是删除，而是想把符合要求的文件名都添加上后缀.bak怎么办？这时候需要这样 find . -name \"*.jpg\" -print0 | xargs -0 -I {} mv {} {}.bak 常用命令 其中的-I {} (initial arguments)是告诉xargs，后面的命令中，用{}表示占位符，将会被实际的参数替代。这样就行了。 其他有用的参数还有： -n 用于指定每次传递几个参数 -d 用于指定切分输入内容时，具体的分隔符 -a file 从文件中读入作为sdtin $ cat 1.txt aaa bbb ccc ddd a b $ xargs -a 1.txt echo aaa bbb ccc ddd a b -e flag 注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止 $ xargs -E 'ddd' -a 1.txt echo aaa bbb ccc $ cat 1.txt |xargs -E 'ddd' echo aaa bbb ccc -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。 $ cat 1.txt |xargs -n 2 echo aaa bbb ccc ddd a b -p 操作具有可交互性，每次执行comand都交互式提示用户选择，当每次执行一个argument的时候询问一次用户 $ cat 1.txt |xargs -p echo echo aaa bbb ccc ddd a b ?...y aaa bbb ccc ddd a b $ cat 1.txt |xargs -p echo echo aaa bbb ccc ddd a b ?...n -t 表示先打印命令，然后再执行 $ cat 1.txt |xargs -t echo echo aaa bbb ccc ddd a b aaa bbb ccc ddd a b 占位 -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给{}，可以用{}代替。小写的-i带参数时和大写的-I是一模一样的，小写的-i可以不带参数，这时候相当于大写的-I {}。 不过手册里面不建议使用小写的-i，可能会有什么问题 xargs加上-I (这里手册建议使用大写的-I)后就可以用 {}表示管道传过来的参数放到该位置 $ ls 1.txt 2.txt 3.txt log.xml $ ls *.txt | xargs -t -i mv {} {}.bak mv 1.txt 1.txt.bak mv 2.txt 2.txt.bak mv 3.txt 3.txt.bak $ ls 1.txt.bak 2.txt.bak 3.txt.bak log.xml 空参数传递 -r no-run-if-empty 如果没有要处理的参数传递给xargs xargs 默认是带空参数运行一次，如果你希望无参数时，停止 xargs，直接退出，使用 -r 选项即可，其可以防止xargs 后面命令带空参数运行报错 $ echo \"\"|xargs -t mv mv mv: missing file operand Try `mv --help' for more information. $ echo \"\"|xargs -t -r mv #直接退出 -s num xargs后面那个命令的最大命令行字符数(含空格) -L 从标准输入一次读取num行送给Command命令 ，-l和-L功能一样 $ cat 1.txt.bak aaa bbb ccc ddd a b ccc dsds $ cat 1.txt.bak |xargs -L 4 echo aaa bbb ccc ddd a b ccc dsds $ cat 1.txt.bak |xargs -L 1 echo aaa bbb ccc ddd a b ccc dsds -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符 $ cat 1.txt.bak aaa@ bbb ccc@ ddd a b $ cat 1.txt.bak |xargs -d '@' echo aaa bbb ccc ddd a b ","date":"2021-02-28","objectID":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/:2:0","tags":["linux"],"title":"xargs原理及使用","uri":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["linux"],"content":"xargs 结合find 使用 举例 $find . -name \"install.log\" -print | cat ./install.log #显示从管道传来的内容，仅仅作为字符串来处理 $find . -name \"install.log\" -print | xargs cat aaaaaa #将管道传来的内容作为文件，交给cat执行。也就是说，该命令执行的是如果存在install.log，那么就打印出这个文件的内容。 来看看xargs命令是如何同find命令一起使用的，并给出一些例子。 1、在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限： # find . -perm -7 -print | xargs chmod o-w 2、查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件 # find . -type f -print | xargs file ./liyao: empty 3、尝试用rm 删除太多的文件，你可能得到一个错误信息：/bin/rm Argument list too long. 用xargs 去避免这个问题 $find ~ -name ‘*.log’ -print0 | xargs -i -0 rm -f {} 4、查找所有的jpg 文件，并且压缩它 # find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz 5、拷贝所有的图片文件到一个外部的硬盘驱动 # ls *.jpg | xargs -n1 -i cp {} /external-hard-drive/directory ","date":"2021-02-28","objectID":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/:3:0","tags":["linux"],"title":"xargs原理及使用","uri":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["linux"],"content":"总结 命令 解释 echo -n “hello#word” |xargs -d “#” 适用#号进行拆分 echo “hello word”|xargs -n 1 一次传递一个参数 echo -n “hello#word”|xargs -d “#” -t 直接输出打印命令无用户交互 echo -n “hello#word”|xargs -d “#” -p 用户交互选择是否打印命令并且输出打印命令 echo -n “hello#word”|xargs -I {} echo {} 占位符initial arguments echo -n “”|xargs -r echo 小写r(no run if empty),如果传递的参数为空则不执行 ","date":"2021-02-28","objectID":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/:4:0","tags":["linux"],"title":"xargs原理及使用","uri":"/xargs%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["MySQL"],"content":"背景 数据是企业生产的重中之重，保护数据安全，防止数据丢失很关键 ","date":"2020-08-17","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/:1:0","tags":["MySQL"],"title":"MySQL 数据库备份和还原","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"categories":["MySQL"],"content":"使用 mysqldump 进行备份 备份的方案场景，列举部分场景 只备份某一个库，不要里面的表 备份所有的库，和所有的表，但是不要表中的数据，只备份它的结构(创建的SQL) 只要某一个库，以及这个库中的所有表，以及所有数据 只要某一个库，里面的某一张表 mysqldump 相关命令\rmysqldump客户端可用来转储数据库或搜集数据库进行备份或将数据转移到另一个SQL服务器(不一定是一个MySQL服务器)。转储包含创建表和/或装载表的SQL语句。 如果你在服务器上进行备份，并且表均为MyISAM表，应考虑使用mysqlhotcopy，因为可以更快地进行备份和恢复。参见8.9节，“mysqlhotcopy：数据库备份程序”。 有3种方式来调用mysqldump： shell\u003e mysqldump [options] db_name [tables] shell\u003e mysqldump [options] —database DB1 [DB2 DB3…] shell\u003e mysqldump [options] –all–database 如果没有指定任何表或使用了—database或–all–database选项，则转储整个数据库。 要想获得你的版本的mysqldump支持的选项，执行mysqldump —help。 如果运行mysqldump没有–quick或–opt选项，mysqldump在转储结果前将整个结果集装入内存。如果转储大数据库可能会出现问题。该选项默认启用，但可以用–skip-opt禁用。 如果使用最新版本的mysqldump程序生成一个转储重装到很旧版本的MySQL服务器中，不应使用–opt或-e选项。 mysqldump支持下面的选项： —help，-？ 显示帮助消息并退出。 –add-drop–database 在每个CREATE DATABASE语句前添加DROP DATABASE语句。\r–add-drop-tables 在每个CREATE TABLE语句前添加DROP TABLE语句。\r–add-locking 用LOCK TABLES和UNLOCK TABLES语句引用每个表转储。重载转储文件时插入得更快。参见7.2.16节，“INSERT语句的速度”。\r–all–database，-A 转储所有数据库中的所有表。与使用---database选项相同，在命令行中命名所有数据库。\r–allow-keywords 允许创建关键字列名。应在每个列名前面加上表名前缀。\r—comments[={0|1}] 如果设置为 0，禁止转储文件中的其它信息，例如程序版本、服务器版本和主机。--skip—comments与---comments=0的结果相同。 默认值为1，即包括额外信息。\r–compact 产生少量输出。该选项禁用注释并启用--skip-add-drop-tables、--no-set-names、--skip-disable-keys和--skip-add-locking选项。\r–compatible=name 产生与其它数据库系统或旧的MySQL服务器更兼容的输出。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options或者no_field_options。要使用几个值，用逗号将它们隔开。这些值与设置服务器SQL模式的相应选项有相同的含义。参见5.3.2节，“SQL服务器模式”。\r该选项不能保证同其它服务器之间的兼容性。它只启用那些目前能够使转储输出更兼容的SQL模式值。例如，--compatible=oracle 不映射Oracle类型或使用Oracle注释语法的数据类型。\r–complete-insert，-c 使用包括列名的完整的INSERT语句。\r–compress，-C 压缩在客户端和服务器之间发送的所有信息（如果二者均支持压缩）。\r–create-option 在CREATE TABLE语句中包括所有MySQL表选项。\r—database，-B 转储几个数据库。通常情况，mysqldump将命令行中的第1个名字参量看作数据库名，后面的名看作表名。使用该选项，它将所有名字参量看作数据库名。CREATE DATABASE IF NOT EXISTS db_name和USE db_name语句包含在每个新数据库前的输出中。\r—debug[=debug_options]，-# [debug_options] 写调试日志。debug_options字符串通常为'd:t:o,file_name'。\r–default-character-set=charset 使用charsetas默认字符集。参见5.10.1节，“数据和排序用字符集”。如果没有指定，mysqldump使用utf8。\r–delayed-insert 使用INSERT DELAYED语句插入行。\r–delete-master-logs 在主复制服务器上，完成转储操作后删除二进制日志。该选项自动启用--master-data。\r–disable-keys，-K 对于每个表，用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地装载转储文件，因为在插入所有行后创建索引。该选项只适合MyISAM表。\r–extended-insert，-e 使用包括几个VALUES列表的多行INSERT语法。这样使转储文件更小，重载文件时可以加速插入。\r–fields-terminated-by=…，–fields-enclosed-by=…，–fields-optionally-enclosed-by=…，–fields-escaped-by=…，–行-terminated-by=… 这些选项结合-T选项使用，与LOAD DATA INFILE的相应子句有相同的含义。参见13.2.5节，“LOAD DATA INFILE语法”。\r–first-slave，-x 不赞成使用，现在重新命名为--lock-all-tables。\r–flush-logs，-F 开始转储前刷新MySQL服务器日志文件。该选项要求RELOAD权限。请注意如果结合--all--database(或-A)选项使用该选项，根据每个转储的数据库刷新日志。例外情况是当使用--lock-all-tables或--master-data的时候：在这种情况下，日志只刷新一次，在所有 表被锁定后刷新。如果你想要同时转储和刷新日志，应使用--flush-logs连同--lock-all-tables或--master-data。\r–force，-f 在表转储过程中，即使出现SQL错误也继续。 –host=host_name，-h host_name 从给定主机的MySQL服务器转储数据。默认主机是localhost。 –hex-blob 使用十六进制符号转储二进制字符串列(例如，‘abc’ 变为0x616263)。影响到的列有BINARY、VARBINARY、BLOB。 –lock-all-tables，-x 所有数据库中的所有表加锁。在整体转储过程中通过全局读锁定来实现。该选项自动关闭–single-transaction和–lock-tables。 –lock-tables，-l 开始转储前锁定所有表。用READ LOCAL锁定表以允许并行插入MyISAM表。对于事务表例如InnoDB和BDB，–single-transaction是一个更好的选项，因为它不根本需要锁定表。 请注意当转储多个数据库时，–lock-tables分别为每个数据库锁定表。因此，该选项不能保证转储文件中的表在数据库之间的逻辑一致性。不同数据库表的转储状态可以完全不同。 –master-data[=value] 该选项将二进制日志的位置和文件名写入到输出中。该选项要求有RELOAD权限，并且必须启用二进制日志。如果该选项值等于1，位置和文件名被写入CHANGE MASTER语句形式的转储输出，如果你使用该SQL转储主服务器以设置从服务器，从服务器从主服务器二进制日志的正确位置开始。如果选项值等于2，CHANGE MASTER语句被写成SQL注释。如果value被省略，这是默认动作。 –master-data 选项启用–lock-all-tables，除非还指定–single-transaction(在这种情况下，只在刚开始转储时短时间获得全局读锁定。又见–single-transaction。在任何一种情况下，日志相关动作发生在转储时。该选项自动关闭–lock-tables。 –no-create-db，-n 该选项禁用CREATE DATABASE /*!32312 IF NOT EXISTS*/ db_name语句，如果给出---database或--all--database选项，则包含到输出中。\r–no-create-info，-t 不写重新创建每个转储表的CREATE TABLE语句。\r–no-data，-d 不写表的任何行信息。如果你只想转储表的结构这很有用。\r–opt 该选项是速记；等同于指定 --add-drop-tables--add-locking --create-option --disable-keys--extended-insert ","date":"2020-08-17","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/:2:0","tags":["MySQL"],"title":"MySQL 数据库备份和还原","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"categories":["MySQL"],"content":"数据备份的各个场景 场景一：备份所有数据库实例 mysqldump -u root -p --all-databases\u003e all_databases.sql 场景二：导出某个或某几个数据库 数据库为myblog mysqldump -u root -p --databases test mysql \u003e db_test_and_mysql.sql 场景三：导出一张表 数据库为myblog，表为wp_users mysqldump -u dbadmin -p myblog wp_users\u003e blog_users.sql 场景四：导出整个数据库结构 导出一个数据库结构 -d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table mysqldump -u dbadmin -p -d --add-drop-table myblog \u003e blog_struc.sql 场景五：导出数据库中的一张表结构 数据库为myblog，表为wp_users mysqldump -u dbadmin -p -d --add-drop-table myblog wp_users\u003e blog_users_struc.sql 场景六：导出数据库一个表数据,不包括表结构 数据库为test，表为person mysqldump -u root -p -t test person \u003e order.sql ","date":"2020-08-17","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/:2:1","tags":["MySQL"],"title":"MySQL 数据库备份和还原","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"categories":["MySQL"],"content":"数据还原 数据导出就有导入还原,库实例为test,将备份的数据进行还原 mysql -h127.0.0.1 -uroot -P3306 -p test \u003c order.sql ","date":"2020-08-17","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/:2:2","tags":["MySQL"],"title":"MySQL 数据库备份和还原","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"categories":["MySQL"],"content":"通过 crontab 定时备份指定数据库脚本参考 脚本验证适用环境Centos7.x #!/bin/bash #set -e # 备份并清理，将mysql 表数据保留21天 dateDir=$(date +%Y%m%d)\"_all\" backUpFolder=/zpaasssd/zcm/mysql_171_grafana_dashboard_bkp host=10.10.168.67 port=20821 username=\"root\" password=\"password\" main(){ mkdir ${backUpFolder}/${dateDir} #rm -rf ${backUpFolder}/$(date -d \"-21 day\" +%Y%m%d)\"_all\".tar.gz if [[ -f ${backUpFolder}/$(date -d \"-21 day\" +%Y%m%d)\"_all\".tar.gz ]];then rm -rf ${backUpFolder}/$(date -d \"-21 day\" +%Y%m%d)\"_all\".tar.gz fi mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_grafana --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_grafana.sql mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_grafpub --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_grafpub.sql #mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_nms --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_nms.sql mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_task --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_task.sql mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_dialing --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_dialing.sql #mysqldump -h $host -P $port -u ${username} -p${password} --databases zcm_idocs --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/zcm_idocs.sql mysqldump -h $host -P $port -u ${username} -p${password} --databases nms_sla --default-character-set utf8 \u003e ${backUpFolder}/${dateDir}/nms_sla.sql #压缩备份文件,清理原始文件 cd ${backUpFolder} tar zcvf ${dateDir}.tar.gz ${dateDir} rm -rf ${backUpFolder}/${dateDir} # 解压 #tar zxvf /zpaasssd/zcm/mysql_171_grafana_dashboard_bkp.tar.gz echo success } main ","date":"2020-08-17","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/:3:0","tags":["MySQL"],"title":"MySQL 数据库备份和还原","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"categories":["learning method"],"content":"\r摘要\r欲罢不能的学习需要一个良好的学习情绪和专注力。 下面主要是学习节奏的控制 改变学习心态，而不是在电脑旁坐了12小时，其实只是学了2个小时\r","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:0:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"1. 如何选择学习时间 选择在早上和下午学习，尽量不要选择在晚上学习(保护发际线)。 在睡前大量用脑，会让脑袋即紧张有疲劳，还会影响睡眠质量。 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:1:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"2.把时间分成几段 假设你今天早上打算学6个小时，可以安排早晨2.5小时， 下午安排2小时，晚上安排1.5小时。把尽量多的任务放到早上和中午去完成。 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:2:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"3. 吃饭的时候保持悠闲和放松 吃不好心情会变差 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:3:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"4. 继续打碎时间 把两个小时左右的时间砍成不足一个小时的区间。学一个小时，就放松 十分钟，这十分钟一定要把自己的注意力转移到别的事情上。看点不相干的书啊，回个微信啥的 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:4:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"5. 转换地方 在一个地方学的久了会让自己感觉时间过得很慢,不要在一个地方呆太久，多踩几个作案地点 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:5:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"6. 换材料 假设学习了一个小时英语，下一个小时就学别的东西，换材料有助于减轻对学习的厌恶感和疲劳度，主要是为了维持新鲜感 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:6:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["learning method"],"content":"7. 中午或者下午休息时间千万不要去学习。 不学习也是伟大计划中的一部分,要和学习一样认真执行，不好好吃饭想学习的事，会让你情绪很紧绷。 整个学习的方法就是保持时间的超级集中点，切换打断带来轻松感，空隙娱乐带来 奖励感，减少体感时间的长度来减少心理压力。 另外还有一点我认为最重要的是保持专注。 ","date":"2020-06-19","objectID":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/:7:0","tags":["learning method"],"title":"欲罢不能的学习方法策略","uri":"/%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AD%96%E7%95%A5/"},{"categories":["Ansible"],"content":"Ansible 中文权威指南 Ansible 知识图谱\r","date":"2020-05-17","objectID":"/ansible%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:0:0","tags":["Ansible"],"title":"Ansible 知识图谱","uri":"/ansible%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["Shell"],"content":"在大部份的 UNIX 系统，三种著名且广被支持的 shell 是 Bourne shell（AT\u0026T shell，在 Linux 下是 BASH）、C shell（Berkeley shell，在 Linux 下是 TCSH）和 Korn shell（Bourne shell 的超集）。 这三种 shell 在交谈（interactive）模式下的表现相当类似，但作为命令文件语言时，在语法和执行效率上就有些不同了。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:0:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"bash Bourne shell 是标准的 UNIX shell，以前常被用来做为管理系统之用。大部份的系统管理命令文件，例如 rc start、stop 与 shutdown 都是 Bourne shell 的命令档，且在单一使用者模式（single user mode）下以 root 签入时它常被系统管理者使用。 Bourne shell 是由 AT\u0026T 发展的，以简洁、快速著名。 Bourne shell 提示符号的默认值是 $。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:1:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"csh C shell 是柏克莱大学（Berkeley）所开发的，且加入了一些新特性，如命令列历程（history）、别名（alias）、内建算术、档名完成（filename completion）、和工作控制（job control）。 对于常在交谈模式下执行 shell 的使用者而言，他们较喜爱使用 C shell；但对于系统管理者而言，则较偏好以 Bourne shell 来做命令档，因为 Bourne shell 命令档比 C shell 命令档来的简单及快速。C shell 提示符号的默认值是 %。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:2:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"ksh Korn shell 是 Bourne shell 的超集（superset），由 AT\u0026T 的 David Korn 所开发。它增加了一些特色，比 C shell 更为先进。Korn shell 的特色包括了可编辑的历程、别名、函式、正规表达式万用字符（regular expression wildcard）、内建算术、工作控制（job control）、共作处理（coprocessing）、和特殊的除错功能。Bourne shell 几乎和 Korn shell 完全向上兼容（upward compatible），所以在 Bourne shell 下开发的程序仍能在 Korn shell 上执行。Korn shell 提示符号的默认值也是 $。 在 Linux 系统使用的 Korn shell 叫做 pdksh，它是指 Public Domain Korn Shell。除了执行效率稍差外，Korn shell 在许多方面都比 Bourne shell 为佳；但是，若将 Korn shell 与 C shell 相比就很困难，因为二者在许多方面都各有所长，就效率和容易使用上看，Korn shell 是优于 C shell，相信许多使用者对于 C Shell 的执行效率都有负面的印象。 在 shell 的语法方面，Korn shell 是比较接近一般程序语言，而且它具有子程序的功能及提供较多的资料型态。至于 Bourne shell，它所拥有的资料型态是三种 shell 中最少的，仅提供字符串变量和布尔型态。在整体考量下 Korn shell 是三者中表现最佳者，其次为 C shell，最后才是 Bourne shell，但是在实际使用中仍有其它应列入考虑的因素，如速度是最重要的选择时，很可能应该采用 Bourne shell，因它是最基本的 shell，执行的速度最快。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:3:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"tcsh tcsh 是近几年崛起的一个免费软件（Linux 下的 C shell 其实就是使用 tcsh）执行，它虽然不是 UNIX 的标准配备，但是从许多地方您都可以下载到它。如果您是 C shell 的拥护者，笔者建议不妨试试 tcsh，因为您至少可以将它当作是 C shell 来使用。如果您愿意花点时间学习，您还可以享受许多它新增的优越功能，例如： tcsh 提供了一个命令列（command line）编辑程序。 提供了命令列补全功能。 提供了拼字更正功能。它能够自动检测并且更正在命令列拼错的命令或是单字。 危险命令侦测并提醒的功能，避免您一个不小心执行了rm* 这种杀伤力极大的命令。 提供常用命令的快捷方式（shortcut）。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:4:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"ash 一个简单的轻量级的 Shell，占用资源少，适合运行于低内存环境，但是与下面讲到的 bash shell 完全兼容 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:5:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"Shell分类总结 在大部份的 UNIX 系统，三种著名且广被支持的 shell 是 Bourne shell（AT\u0026T shell，在 Linux 下是 BASH）、C shell（Berkeley shell，在 Linux 下是 TCSH）和 Korn shell（Bourne shell 的超集）。 这三种 shell 在交谈（interactive）模式下的表现相当类似，但作为命令文件语言时，在语法和执行效率上就有些不同了。 ","date":"2020-04-28","objectID":"/ch0_shell%E5%88%86%E7%B1%BB/:6:0","tags":["Shell"],"title":"shell 分类","uri":"/ch0_shell%E5%88%86%E7%B1%BB/"},{"categories":["Shell"],"content":"对于shell脚本而言，有些内容是专门用于处理参数的，它们都有特定的含义，例如 /home/shouwang/test.sh para1 para2 para3 $0 $1 $2 $3 其中$0代表了执行的脚本名，$1，$2分别代表了第一个，第二个参数。除此之外，还有一些其他的默认变量，例如： 符号 释义 $# 代表脚本后面跟的参数个数，前面的例子中有3个参数 $@ 代表了所有参数，并且可以被遍历 $* 代表了所有参数，且作为整体，和$@ 很像，但是有区别 $$ 代表了当前脚本的进程ID $? 代表了上一条命令的退出状态 ","date":"2020-04-27","objectID":"/ch1_%E5%85%A5%E5%8F%82%E5%92%8C%E9%BB%98%E8%AE%A4%E5%8F%98%E9%87%8F/:0:0","tags":["Shell"],"title":"shell 入参和默认变量","uri":"/ch1_%E5%85%A5%E5%8F%82%E5%92%8C%E9%BB%98%E8%AE%A4%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"给变量赋值，使用等号即可，但是等号两边千万不要有空格，等号右边有空格的字符串也必须用引号引起来 ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:0:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"变量定义 para1=\"hello world\" #字符串直接赋给变量para1 #unset用于取消变量 unset para1 定义变量类型： declare 或 typeset -r 只读(readonly一样) -i 整形 -a 数组 -f 函数 -x export declare -i n=0 ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:1:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"系统变量 command 释义 $0 脚本启动名(包括路径) $n 第n个参数,n=1,2,…9 $* 所有参数列表(不包括脚本本身) $@ 所有参数列表(独立字符串) $# 参数个数(不包括脚本本身) $$ 当前程式的PID $! 执行上一个指令的PID $? 执行上一个指令的返回值 ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:2:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"变量引用技巧 command 释义 ${name:+value} 如果设置了name,就把value显示,未设置则为空 ${name:-value} 如果设置了name,就显示它,未设置就显示value ${name:?value} 未设置提示用户错误信息value ${name:=value} 如未设置就把value设置并显示\u003c写入本地中\u003e ${#A} 可得到变量中字节数 ${A:4:9} 取变量中第4位到后面9位 ${A:(-1)} 倒叙取最后一个字符 ${A/www/http} 取变量并且替换每行第一个关键字 ${A//www/http} 取变量并且全部替换每行关键字 定义一个变量：file=/dir1/dir2/dir3/my.file.txt command 释义 ${file#*/} 去掉第一条 / 及其左边的字串：dir1/dir2/dir3/my.file.txt ${file##*/} 去掉最后一条 / 及其左边的字串：my.file.txt ${file#*.} 去掉第一个 . 及其左边的字串：file.txt ${file##*.} 去掉最后一个 . 及其左边的字串：txt ${file%/*} 去掉最后条 / 及其右边的字串：/dir1/dir2/dir3 ${file%%/*} 去掉第一条 / 及其右边的字串：(空值) ${file%.*} 去掉最后一个 . 及其右边的字串：/dir1/dir2/dir3/my.file ${file%%.*} 去掉第一个 . 及其右边的字串：/dir1/dir2/dir3/my 说明 # 是去掉左边(在键盘上 # 在 $ 之左边) % 是去掉右边(在键盘上 % 在 $ 之右边) 单一符号是最小匹配﹔两个符号是最大匹配 ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:3:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"操作变量 echo \"para1 is $para1\" #将会输出 para1 is hello world # or echo \"para1 is ${para1}!\" #将会输出 para1 is hello world! ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:4:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"变量替代 foo=\"I'm a cat.\" echo ${foo/cat/dog} # 打印 \"I'm a dog.\" 使用两个反斜线进行全力替换 foo=\"I'm a cat, and she's cat.\" echo ${foo/cat/dog} # 打印 \"I'm a dog, and she's a cat.\" echo ${foo//cat/dog} # 打印 \"I'm a dog, and she's a dog.\" 打印时不会修改变量 foo=\"hello\" echo ${foo/hello/goodbye} # 打印 \"goodbye\" echo $foo # 仍然打印 \"hello\" ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:4:1","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"变量匹配删除 没有替换的字符串则直接删除 foo=\"I like meatballs.\" echo ${foo/balls} # 打印 I like meat. ${name#pattern}操作删除${name}匹配模式的最短前缀，而##删除最长前缀： minipath=\"/usr/bin:/bin:/sbin\" echo ${minipath#/usr} # 打印 /bin:/bin:/sbin echo ${minipath#*/bin} # 打印 :/bin:/sbin echo ${minipath##*/bin} # 打印 :/sbin ,就是*/bin 匹配的/bin及之前的字符串一并删除 运算符%是相同的，只不过匹配的是后缀而不是前缀： minipath=\"/usr/bin:/bin:/sbin\" echo ${minipath%/usr*} # 打印 nothing echo ${minipath%/bin*} # 打印 /usr/bin: echo ${minipath%%/bin*} # 打印 /usr ,就是%/bin 匹配的/bin及之后的字符串一并删除 分片切割 string=\"I'm a fan of dogs.\" echo ${string:6:3} # 打印 fan ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:4:2","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"是否存在默认值 username=shuan_lu unset username echo ${username-default} # 打印 default username=admin echo ${username-default} # 打印 admin 对于测试是否设置了变量的操作，可以通过添加冒号（\":\"）来强制检查变量是否已设置且是否为空： foo=\"\" bar=\"\" echo ${foo-123} # 打印 nothing echo ${bar:-456} # 打印 456 运算符=（或:=）类似于运算符-，只是如果变量没有值，它也会设置变量： unset cache echo ${cache:=1024} # 打印 1024 echo $cache # 打印 1024 echo ${cache:=2048} # 打印 1024 echo $cache # 打印 1024 ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:5:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"单引号和双引号 shell 会忽略单引号中所有的特殊字符，其中的所有内容都会被当作一个元素 双引号几乎与单引号相似。这里之所以说“几乎”是因为他们也会忽略所有特殊字符，除了： 美元符号：$ 反引号：` 反斜杠：\\ world=Earth foo='Hello, $world!' bar=\"Hello, $world\" echo $foo # 打印 Hello, $world! echo $bar # 打印 Hello, Earth ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:6:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"总结 command 释义 A=“a b c def” 将字符串复制给变量 A=cmd 将命令结果赋给变量 A=$(cmd) 将命令结果赋给变量 eval a=$$a 间接调用 i=2\u0026\u0026echo $((i+3)) 计算后打印新变量结果 i=2\u0026\u0026echo $[i+3] 计算后打印新变量结果 a=$((2\u003e6?5:8)) 判断两个值满足条件的赋值给变量,类似三目运算符 $1 $2 $* 位置参数 *代表所有 env 查看环境变量 env grep “name” set 查看环境变量和本地变量 read name 输入变量 readonly name 把name这个变量设置为只读变量,不允许再次设置 readonly 查看系统存在的只读文件 export name 变量name由本地升为环境 export name=“RedHat” 直接定义name为环境变量 export Stat$nu=2222 变量引用变量赋值 unset name 变量清除 export -n name 去掉只读变量 shift 用于移动位置变量,调整位置变量,使$3的值赋给$2.$2的值赋予$1 name + 0 将字符串转换为数字 number \" \" 将数字转换成字符串 a=‘ee’;b=‘a’;echo ${!b} 间接引用name变量的值 : ${a=“cc”} 如果a有值则不改变,如果a无值则赋值a变量为cc ","date":"2020-04-26","objectID":"/ch2_%E5%8F%98%E9%87%8F/:7:0","tags":["Shell"],"title":"shell 变量","uri":"/ch2_%E5%8F%98%E9%87%8F/"},{"categories":["Shell"],"content":"在shell中执行命令通常只需要像在终端一样执行命令即可，不过，如果想要命令结果打印出来的时候，这样的方式就行不通了。因此，shell的命令方式常有 ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"方式一 a=`ls` #`是左上角～键，不是单引号 ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:1:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"方式二 或者使用$，后面括号内是执行的命令 echo \"current path is $(pwd)\" # ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:2:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"方式三 计算 另外，前面两种方式对于计算表达式也是行不通的，而要采取下面的方式： echo \"1+1=$((1+1))\" #打印：1+1=2 ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:3:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"方式四 命令赋值给变量 a=\"ls\" echo \"$($a)\" ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:4:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"方式五 如果字符串时多条命令的时候，上面的方式又不可行了，而要采用下面的方式 a=\"ls;pwd\" echo \"$(eval $a)\" ","date":"2020-04-26","objectID":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:5:0","tags":["Shell"],"title":"shell 命令执行","uri":"/ch3_%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"一般说明，如果命令执行成功，则其返回值为0，否则为非0，因此，可以通过下面的方式判断上条命令的执行结果： ","date":"2020-04-25","objectID":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/:0:0","tags":["Shell"],"title":"shell 条件分支","uri":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/"},{"categories":["Shell"],"content":"if 分支 if [ $? -eq 0 ] then echo \"success\" elif [ $? -eq 1 ] then echo \"failed,code is 1\" else echo \"other code\" fi ","date":"2020-04-25","objectID":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/:1:0","tags":["Shell"],"title":"shell 条件分支","uri":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/"},{"categories":["Shell"],"content":"多个条件 方式一 if [ 10 -gt 5 -o 10 -gt 4 ];then echo \"10\u003e5 or 10 \u003e4\" fi 方式二 if [ 10 -gt 5 ] || [ 10 -gt 4 ];then echo \"10\u003e5 or 10 \u003e4\" fi 总结： -o or 或者，同|| -a and 与，同\u0026\u0026 ! 非 ","date":"2020-04-25","objectID":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/:1:1","tags":["Shell"],"title":"shell 条件分支","uri":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/"},{"categories":["Shell"],"content":"case 分支 name=\"aa\" case $name in \"aa\") echo \"name is $name\" ;; \"\") echo \"name is empty\" ;; \"bb\") echo \"name is $name\" ;; *) echo \"other name\" ;; esac ```shell 注意： - []前面要有空格，它里面是逻辑表达式 - if elif后面要跟then，然后才是要执行的语句 - 如果想打印上一条命令的执行结果，最好的做法是将 $?赋给一个变量，因为一旦执行了一条命令，$?的值就可能会变。 - case每个分支最后以两个分号结尾，最后是case反过来写，即esac。 ","date":"2020-04-25","objectID":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/:2:0","tags":["Shell"],"title":"shell 条件分支","uri":"/ch4_%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF/"},{"categories":["Shell"],"content":"for 循环 ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:1:0","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"for 循环一 #遍历输出脚本的参数 for i in $@; do echo $i done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:1:1","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"for 循环方式二 for ((i = 0 ; i \u003c 10 ; i++)); do echo $i done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:1:2","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"for 循环方式三 for i in {1..5}; do echo \"Welcome $i\" done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:1:3","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"for 循环方式四 for i in {5..15..3}; do echo \"number is $i\" done 每隔3打印一次，即打印5,8,11,14 示例 for f in *.c do gcc -o ${f%.c} $f done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:1:4","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"while 循环 while [ \"$ans\" != \"yes\" ] do read -p \"please input yes to exit loop:\" ans done # 只有当ans不是yes时，循环就终止。 # or num=1 while [ $num -lt 10 ] do echo $num ((num=$num+2)) done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:2:0","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"until 循环 num=1 # 当command不为0时循环 until [ $num -gt 10 ] do echo until $num ((num=$num+2)) done ","date":"2020-04-24","objectID":"/ch5_%E5%BE%AA%E7%8E%AF/:3:0","tags":["Shell"],"title":"shell 循环","uri":"/ch5_%E5%BE%AA%E7%8E%AF/"},{"categories":["Shell"],"content":"为了完成某一功能的程序指令（语句）的集合，称为函数。Shell 函数的本质是一段可以重复使用的脚本代码，这段代码被提前编写好了，放在了指定的位置，使用时直接调取即可 在程序中，编写函数的主要目的是将一个需要很多行代码的复杂问题分解为一系列简单的任务来解决，而且，同一个任务（函数）可以被多次调用，有助于代码重用。 ","date":"2020-04-23","objectID":"/ch6_%E5%87%BD%E6%95%B0/:0:0","tags":["Shell"],"title":"shell 函数","uri":"/ch6_%E5%87%BD%E6%95%B0/"},{"categories":["Shell"],"content":"定义函数 function myfunc() { echo \"hello world $1\" } function myfunc { echo \"hello world $1\" } 或者 myfunc() { echo \"hello world $1\" } 说明 可以省略 function 关键词 如果写了 function 关键字，也可以省略函数名后面的小括号 ","date":"2020-04-23","objectID":"/ch6_%E5%87%BD%E6%95%B0/:1:0","tags":["Shell"],"title":"shell 函数","uri":"/ch6_%E5%87%BD%E6%95%B0/"},{"categories":["Shell"],"content":"函数参数及调用 在 Shell 中，我们定义 函数 时，不像 C 语言、 C++、 Python、 Java 和 Golang 那样，需要传递参数，Shell 中的函数在定义时不能指明参数，但是在调用时却可以传递参数。 函数参数是 Shell 位置参数的一种，在函数内部可以使用 $n 来接收，例如，$1 表示第一个参数，$2 表示第二个参数，依次类推。除了 n，还有另外三个比较重要的变量，# 可以获取传递的参数的个数，$@ 或者 $* 可以一次性获取所有的参数。 #!/bin/bash function show(){ echo \"Name is: $1\" echo \"Site is: $2\" echo \"Age is: $3\" } show shuanlu https://lu_shuan.gitee.io/gitbook 109 ","date":"2020-04-23","objectID":"/ch6_%E5%87%BD%E6%95%B0/:2:0","tags":["Shell"],"title":"shell 函数","uri":"/ch6_%E5%87%BD%E6%95%B0/"},{"categories":["Shell"],"content":"通常函数的return返回值只支持0-255，因此想要获得返回值，可以通过下面的方式。 function myfunc() { local myresult='some value' echo $myresult } val=$(myfunc) #val的值为some value 通过return的方式适用于判断函数的执行是否成功： function myfunc() { #do something return 0 } if myfunc;then echo \"success\" else echo \"failed\" fi ","date":"2020-04-22","objectID":"/ch7_%E8%BF%94%E5%9B%9E%E5%80%BC/:0:0","tags":["Shell"],"title":"shell 返回值","uri":"/ch7_%E8%BF%94%E5%9B%9E%E5%80%BC/"},{"categories":["Shell"],"content":"shell通过#来注释一行内容，前面我们已经看到过了 #!/bin/bash # 这是一行注释 :' 这是 多行 注释 ' ls :\u003c\u003cEOF 这也可以 达到 多行注释 的目的 EOF ","date":"2020-04-21","objectID":"/ch8_%E6%B3%A8%E9%87%8A/:0:0","tags":["Shell"],"title":"shell 注释","uri":"/ch8_%E6%B3%A8%E9%87%8A/"},{"categories":["Shell"],"content":"脚本执行后免不了要记录日志，最常用的方法就是重定向。以下面的脚本为例： #!/bin/bash #test.sh lll #这个命令是没有的，因此会报错 date ","date":"2020-04-20","objectID":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/:0:0","tags":["Shell"],"title":"shell 日志保存","uri":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/"},{"categories":["Shell"],"content":"方式一 将标准输出保存到文件中，打印标准错误： ./test.sh \u003e log.dat 这种情况下，如果命令执行出错，错误将会打印到控制台。所以如果你在程序中调用，这样将不会讲错误信息保存在日志中。 ","date":"2020-04-20","objectID":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/:1:0","tags":["Shell"],"title":"shell 日志保存","uri":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/"},{"categories":["Shell"],"content":"方式二 ./test.sh \u003e log.dat 2\u003e\u00261 标准输出和标准错误都保存到日志文件中 这里的2\u003e\u00261是什么意思？ 表明将./test.sh的输出重定向到log.txt文件中，同时将标准错误也重定向到log.txt文件中。 ","date":"2020-04-20","objectID":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/:2:0","tags":["Shell"],"title":"shell 日志保存","uri":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/"},{"categories":["Shell"],"content":"方式三 保存日志文件的同时，也输出到控制台 ./test.sh |tee log.dat ","date":"2020-04-20","objectID":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/:3:0","tags":["Shell"],"title":"shell 日志保存","uri":"/ch9_%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98/"},{"categories":["Shell"],"content":"常见执行方式 ./test.sh ","date":"2020-04-19","objectID":"/ch10_%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C/:1:0","tags":["Shell"],"title":"shell 脚本执行","uri":"/ch10_%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"其它执行方式 sh test.sh #在子进程中执行 sh -x test.sh #会在终端打印执行到命令，适合调试 source test.sh #test.sh在父进程中执行 . test.sh #不需要赋予执行权限，临时执行 ","date":"2020-04-19","objectID":"/ch10_%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C/:2:0","tags":["Shell"],"title":"shell 脚本执行","uri":"/ch10_%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C/"},{"categories":["Shell"],"content":"很多时候我们需要获取脚本的执行结果，即退出状态，通常0表示执行成功，而非0表示失败。为了获得退出码，我们需要使用exit #!/bin/bash function myfun() { if [ $# -lt 2 ] then echo \"para num error\" exit 1 fi echo \"ok\" exit 2 } if [ $# -lt 1 ] then echo \"para num error\" exit 1 fi returnVal=`myfun aa` echo \"end shell\" exit 0 ","date":"2020-04-18","objectID":"/ch11_%E8%84%9A%E6%9C%AC%E9%80%80%E5%87%BA%E7%A0%81/:0:0","tags":["Shell"],"title":"shell 脚本退出码","uri":"/ch11_%E8%84%9A%E6%9C%AC%E9%80%80%E5%87%BA%E7%A0%81/"},{"categories":["Ansible"],"content":"问题描述 通过ansible命令直接ping多台机器的网络状态，提示报错 失败\r172.16.24.220 | UNREACHABLE! =\u003e { “changed”: false, “msg”: “Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\\r\\n”, “unreachable”: true }\r","date":"2020-04-17","objectID":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:1:0","tags":["Ansible"],"title":"Ansible 权限认证报错问题记录","uri":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["Ansible"],"content":"问题处理 解决方式：单向的ssh验证 ssh-keygen一路回车,主要是用来免密通信的 ssh-copy-id 172.16.24.220 需要输入对应主节的root密码 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 7f:69:87:cf:28:fe:8b:19:55:a7:d0:c9:aa:6d:05:0c root@chm The key's randomart image is: +--[ RSA 2048]----+ | E | | o o . | | + = .| | = o | | S o o | | . + + | | + B . | | .B = | | .+o+.o | +-----------------+ [root@chm log]# [root@chm log]# ssh-copy-id 172.16.24.220 /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@172.16.24.220's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh '172.16.24.220'\" and check to make sure that only the key(s) you wanted were added. ","date":"2020-04-17","objectID":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:2:0","tags":["Ansible"],"title":"Ansible 权限认证报错问题记录","uri":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["Ansible"],"content":"验证 再次验证，成功 [root@chm log]# ansible 172.16.24.220 -m ping 172.16.24.220 | SUCCESS =\u003e { \"changed\": false, \"failed\": false, \"ping\": \"pong\" } ","date":"2020-04-17","objectID":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:3:0","tags":["Ansible"],"title":"Ansible 权限认证报错问题记录","uri":"/ansible%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["Shell"],"content":"要给某个环境变量设置多个值，可以把值放在括号里，值与值之间用空格分隔。 ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:0:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"声明 mytest=(one two three four five) echo ${mytest[2]} # 输出 three echo ${mytest[*]} # 输出 one two three four five ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:1:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"修改数组值 mytest=(one two three four five) mytest[2]=seven ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:2:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"删除数组中的值 mytest=(one two three four five) unset mytest[2] # 删除单个元素，索引下标保留映射的值被置空 echo ${mytest[2]} # 输出为空 unset mytest # 删除整个数组 ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:3:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"示例 docker 中的应用启动后再进行健康检查是一个启动脚本 #!/bin/bash APP=(\"java\" \"health_check\") java=( \"java --add-opens java.base/java.lang=ALL-UNNAMED -DAPP_NAME=zcmMonitor -XX:MaxRAMPercentage=70.0 -Dspring.config.location=/app/conf/monitorConfig.properties -Dlogging.config=/app/conf/logback.xml -cp /app/lib/zcm-monitor-9.1.3-sec-SNAPSHOT.jar:/app/lib/run/* com.ztesoft.zsmart.zcm.monitor.App\" # start command \"APP_NAME=zcmMonitor\" # process key \"echo OK\" # liveness check command \"OK\" # liveness successful code \"curl -k -m 10 -s https://127.0.0.1:${NMS_MONITOR_SSL_PORT}/app/health 2\u003e/dev/null\" # readiness check command \"UP\" # readiness successful code ) health_check=( \"sh /app/health_check.sh\" # start command \"health_check.sh\" # process key \"echo OK\" # liveness check command \"OK\" # liveness successful code \"echo OK\" # readiness check command \"OK\" # readiness successful code ) 然后解析该数组配置设置启动顺序 ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:4:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"总结 有时数组变量会让事情很麻烦，所以在shell脚本编程时并不常用。对其他shell而言，数组变 量的可移植性并不好，如果需要在不同的shell环境下从事大量的脚本编写工作，这会带来很多不 便 command 释义 A=(a b c def) 将变量定义为数組 ${#A[*]} 数组个数 ${A[*]} 数组所有元素,大字符串 ${A[@]} 数组所有元素,类似列表可迭代 ${A[2]} 脚本的一个参数或数组第三位 ","date":"2020-04-17","objectID":"/ch12_%E6%95%B0%E7%BB%84/:5:0","tags":["Shell"],"title":"shell 数组","uri":"/ch12_%E6%95%B0%E7%BB%84/"},{"categories":["Shell"],"content":"在shell编程中，字典是一种非常有用的数据结构，用于存储键值对。字典可以用于存储和检索数据，它类似于其他编程语言中的关联数组或哈希表。 在shell中，可以使用关联数组来实现字典。关联数组是一种有序的集合，它将唯一的键映射到值。键可以是字符串或整数，而值可以是任意类型的数据。 字典的用法如下： 创建字典：可以使用关联数组的方式来创建字典，例如： declare -A my_dict my_dict[key1]=value1 my_dict[key2]=value2 访问字典值：可以通过键来访问字典中的值，例如： echo ${my_dict[key1]} # 输出：value1 遍历字典：可以使用循环来遍历字典中的所有键和值，例如： for key in \"${!my_dict[@]}\"; do echo \"Key: $key, Value: ${my_dict[$key]}\" done 修改字典值：可以通过键来修改字典中的值，例如： my_dict[key1]=new_value1 删除键值对：可以使用unset命令来删除字典中的键值对，例如： unset my_dict[key1] 字典长度：可以使用#运算符来获取字典的长度，即键值对的数量，例如： echo ${#my_dict[@]} # 输出字典的长度 字典在shell编程中非常有用，可以用于各种场景，如配置文件解析、数据存储和传递等。它提供了一种便捷的方式来处理和组织数据，提高了编程效率。 ","date":"2020-04-16","objectID":"/ch13_%E5%AD%97%E5%85%B8/:0:0","tags":["Shell"],"title":"shell 字典","uri":"/ch13_%E5%AD%97%E5%85%B8/"},{"categories":["Shell"],"content":"介绍 test 是 Shell 内置命令，用来检测某个条件是否成立。test 通常和 if 语句一起使用，并且大部分 if 语句都依赖 test。 test 命令有很多选项，可以进行数值、字符串和文件三个方面的检测。 Shell test 命令的用法为： test expression 当 test 判断 expression 成立时，退出状态为 0，否则为非 0 值。 test 命令也可以简写为[]，它的用法为： [ expression ] 注意[]和expression之间的空格，这两个空格是必须的，否则会导致语法错误。[]的写法更加简洁，比 test 使用频率高。 test 和 [] 是等价的，后续我们会交替使用 test 和 []，以让读者尽快熟悉。 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:1:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"字符串操作 command 释义 -z “$str1” str1是否为空字符串 -n “$str1” str1是否不是空字符串 “$str1” == “$str2” str1是否与str2相等 “$str1” != “$str2” str1是否与str2不等 “$str1” =~ “str2” str1是否包含str2 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"整数操作 command 释义 -eq 两数是否相等 -ne 两数是否不等 -gt 前者是否大于后者（greater then） -lt 前面是否小于后者（less than） -ge 前者是否大于等于后者（greater then or equal） -le 前者是否小于等于后者（less than or equal） ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:3:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"文件操作 command 释义 -a 并且，两条件为真 -b 是否块文件 -p 文件是否为一个命名管道 -c 是否字符文件 -r 文件是否可读 -d 是否一个目录 -s 文件的长度是否不为零 -e 文件是否存在 -S 是否为套接字文件 -f 是否普通文件 -x 文件是否可执行，则为真 -g 是否设置了文件的 SGID 位 -u 是否设置了文件的 SUID 位 -G 文件是否存在且归该组所有 -w 文件是否可写，则为真 -k 文件是否设置了的粘贴位 -o 或，一个条件为真 -O 文件是否存在且归该用户所有 ! 取反 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:4:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"示例 command 释义 test 10 -lt 5 判断大小 echo $? 查看上句test命令返回状态 # 结果0为真,1为假 test -n “hello” 判断字符串长度是否为0 [ $? -eq 0 ] \u0026\u0026 echo “success” || exit　# 判断成功提示,失败则退出 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:5:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"判断 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:6:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"整数判断 -eq 两数是否相等 -ne 两数是否不等 -gt 前者是否大于后者（greater then） -lt 前面是否小于后者（less than） -ge 前者是否大于等于后者（greater then or equal） -le 前者是否小于等于后者（less than or equal） ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:6:1","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"字符串判断str1 exp str2： -z “$str1” str1是否为空字符串 -n “$str1” str1是否不是空字符串 “$str1” == “$str2” str1是否与str2相等 “$str1” != “$str2” str1是否与str2不等 “$str1” =~ “str2” str1是否包含str2 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:6:2","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"文件目录判断 -f $filename 是否为文件 -e $filename 是否存在 -d $filename 是否为目录 -s $filename 文件存在且不为空 ! -s $filename 文件是否为空 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:6:3","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"流程控制 break N # 跳出几层循环 continue N # 跳出几层循环，循环次数不变 continue # 重新循环次数不变 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:7:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"示例 #!/bin/bash read age if test $age -le 2; then echo \"婴儿\" elif test $age -ge 3 \u0026\u0026 test $age -le 8; then echo \"幼儿\" elif [ $age -ge 9 ] \u0026\u0026 [ $age -le 17 ]; then echo \"少年\" elif [ $age -ge 18 ] \u0026\u0026 [ $age -le 25 ]; then echo \"成年\" elif test $age -ge 26 \u0026\u0026 test $age -le 40; then echo \"青年\" elif test $age -ge 41 \u0026\u0026 [ $age -le 60 ]; then echo \"中年\" else echo \"老年\" fi ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:8:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"总结 test 命令有点特别，\u003e、\u003c、== 只能用来比较字符串，不能用来比较数字，比较数字需要使用 -eq、-gt 等选项；不管是比较字符串还是数字，test 都不支持 \u003e= 和 \u003c=。有经验的程序员需要慢慢习惯 test 命令的这些奇葩用法 ","date":"2020-04-15","objectID":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:9:0","tags":["Shell"],"title":"shell test 条件判断","uri":"/ch14_test%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Shell"],"content":"Shell 参数处理是指在 Shell 脚本中，对命令行传入的参数进行处理和操作的技术。这在编写 Shell 脚本时非常重要，因为它允许脚本根据不同的参数执行不同的操作，增强了脚本的灵活性和适用性。 在 Shell 脚本中，可以使用特殊变量 “$1”、\"$2\"、\"$3\" 等来引用命令行传入的参数，其中 “$1” 表示第一个参数，\"$2\" 表示第二个参数，依此类推。这些参数可以根据脚本需要进行操作，比如作为文件名、目录名、网址等。 以下是一些示例，演示了如何在 Shell 脚本中处理参数： ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:0:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"显示脚本名称和参数： #!/bin/bash echo \"脚本名称：$0\" echo \"第一个参数：$1\" echo \"第二个参数：$2\" 运行 ./script.sh argument1 argument2，将会输出： 脚本名称：./script.sh 第一个参数：argument1 第二个参数：argument2 ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:1:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"判断参数个数是否正确： #!/bin/bash if [ $# -ne 2 ]; then echo \"需要两个参数\" exit 1 fi echo \"参数个数正确\" 运行 ./script.sh argument1，将会输出：需要两个参数 ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:2:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"使用参数作为文件名： #!/bin/bash filename=\"$1\" if [ -f \"$filename\" ]; then echo \"文件存在\" else echo \"文件不存在\" fi 运行 ./script.sh myfile.txt，将会输出：文件存在 ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:3:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"循环处理多个参数： #!/bin/bash for arg in \"$@\" do echo \"参数: $arg\" done 运行 ./script.sh argument1 argument2 argument3，将会输出： 参数: argument1 参数: argument2 参数: argument3 ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:4:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"特别的参数 注意参数超过个位数时的处理 echo $0 # 打印脚本名称 echo $1 # 打印第一个参数 echo $2 # 打印第二个参数 echo $9 # 打印第九个参数 echo $10 # 打印第一个参数后面跟一个0 echo ${10} # 打印第十个参数 echo $# # 打印参数的数量 这些示例展示了 Shell 参数处理的一些基本用法，可以根据实际需求灵活运用。 ","date":"2020-04-14","objectID":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/:5:0","tags":["Shell"],"title":"shell 参数处理","uri":"/ch15_%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"categories":["Shell"],"content":"方式一 命令expr 命令expr打印算术表达式的结果，但必须小心 * 号 expr 3 + 12 # 打印 15 expr 3 * 12 # (probably) crashes: * 需要进行转义，这行语句会执行报错 expr 3 \\* 12 # 打印 36 ","date":"2020-04-13","objectID":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/:1:0","tags":["Shell"],"title":"shell 算术表达式","uri":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/"},{"categories":["Shell"],"content":"方式二 (( assignable = expression )) (( x = 3 + 12 )); echo $x # 打印 15 (( x = 3 * 12 )); echo $x # 打印 36 ","date":"2020-04-13","objectID":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/:2:0","tags":["Shell"],"title":"shell 算术表达式","uri":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/"},{"categories":["Shell"],"content":"方式三 echo $(( 3 + 12 )) # 打印 15 echo $(( 3 * 12 )) # 打印 36 ","date":"2020-04-13","objectID":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/:3:0","tags":["Shell"],"title":"shell 算术表达式","uri":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/"},{"categories":["Shell"],"content":"指定类型 虽然隐式声明变量是bash中的规范，但可以显式声明变量并为其指定类型 指定整型 declare -i number number=2+4*10 echo $number # 打印 42 another=2+4*10 echo $another # 打印 2+4*10 number=\"foobar\" echo $number # 打印 0 ","date":"2020-04-13","objectID":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/:4:0","tags":["Shell"],"title":"shell 算术表达式","uri":"/ch16_%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E7%AE%97%E6%9C%AF/"},{"categories":["Shell"],"content":"Unix中的每个进程默认都可以访问三个输入/输出通道：STDIN（标准输入）、STDOUT（标准输出）和STDERR（标准错误）。 ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:0:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"打印myfile中包含单词foo的行 grep foo \u003c myfile ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:1:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"文件合并 一般配合文件切割使用 将文件file1、file2 合并至新文件combined cat file1 file2 \u003e combined ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:2:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"文件追加 date \u003e\u003e log ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:3:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"endmarker 要在脚本中从字面上指定STDIN的内容，请使用«endmarker表示法： cat \u003e file1 \u003c\u003cUNTILHERE All of this will be printed out. Since all of this is going into cat on STDIN. UNTILHERE # \u003e\u003e 追加 cat \u003e\u003e file1 \u003c\u003cUNTILHERE All of this will be printed out. Since all of this is going into cat on STDIN. UNTILHERE # 一般使用EOF cat \u003e\u003e file1 \u003c\u003cEOF All of this will be printed out. Since all of this is going into cat on STDIN. EOF ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:4:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"输出错误日志至文件 httpd 2\u003e error.log ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:5:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"chanel 输出类型 STDIN is channel 0, STDOUT is channel 1, while STDERR is channel 2. grep foo nofile 2\u003e\u00261 # errors will appear on STDOUT，既正常输出也输出错误日志 ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:6:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"总结 重定向 command 释义 cmd 1\u003e fiel 把 标准输出 重定向到 file 文件中 cmd \u003e file 2\u003e\u00261 把 标准输出 和 标准错误 一起重定向到 file 文件中 cmd 2\u003e file 把 标准错误 重定向到 file 文件中 cmd 2» file 把 标准错误 重定向到 file 文件中(追加) cmd » file 2\u003e\u00261 把 标准输出 和 标准错误 一起重定向到 file 文件中(追加) cmd \u003c file \u003efile2 cmd 命令以 file 文件作为 stdin(标准输入)，以 file2 文件作为 标准输出 cat \u003c\u003efile 以读写的方式打开 file ","date":"2020-04-12","objectID":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/:7:0","tags":["Shell"],"title":"shell 文件和重定向","uri":"/ch17_%E6%96%87%E4%BB%B6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["Shell"],"content":"一些生产中常用到的片段脚本 ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:0:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"字符串分割模板 IFS 默认是空格进行分割 oldIFS=$IFS IFS=\":\" data=\"大牛:二狗:三驴\" for item in $data; do echo $item done IFS=$oldIFS ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:1:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"进程探测 #!/bin/bash PROC_NAME=nms-prometheus ProcNumber=`ps -ef |grep -w $PROC_NAME|grep -v grep|wc -l` if [ $ProcNumber -le 0 ];then echo \"nmsprometheus is not run\" sh /home/zoms/monitor/start.sh else echo \"nmsprometheus is running..\" fi ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:2:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"目录循环 #!/bin/sh dirlist=\"ls\" for dir in `$dirlist` do if [ -d $dir ]; then helm install $dir $dir -n zcm9 -f ../values.yaml fi done ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:3:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"进程检测 判断进程是否存在，如果不存在则进行手动重启，如果重启还不存在则做另外的动作 #!/bin/sh nginxpid=$(ps -C nginx --no-header|wc -l) #1.判断Nginx是否存活,如果不存活则尝试启动Nginx if [ $nginxpid -eq 0 ];then systemctl start nginx sleep 3 #2.等待3秒后再次获取一次Nginx状态 nginxpid=$(ps -C nginx --no-header|wc -l) #3.再次进行判断, 如Nginx还不存活则停止Keepalived,让地址进行漂移,并退出脚本 if [ $nginxpid -eq 0 ];then systemctl stop keepalived fi fi ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:4:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"定时清空文件内容 结合cron 使用 #!/bin/bash logfile=/tmp/`date +%H-%F`.log n=`date +%H` if [ $n -eq 00 ] || [ $n -eq 12 ] then #通过for循环，以find命令作为遍历条件，将目标目录下的所有文件进行遍历并做相应操作 for i in `find /data/log/ -type f` do true \u003e $i done else for i in `find /data/log/ -type f` do du -sh $i \u003e\u003e $logfile done fi ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:5:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["Shell"],"content":"探测主机端口是否处于监听状态 #!/bin/bash ip_list=\"10.1.1.81 10.1.1.83 10.1.11.159\" port=9100 function main() { for ip in $ip_list do result=`echo -e \"\\n\" |timeout --signal=9 2 telnet $ip $port 2\u003e/dev/null | grep Connected | wc -l` if [ $result -ne 1 ] then echo $ip \u003e\u003e $HOME/ip_refused.txt fi done } main ","date":"2020-04-11","objectID":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/:6:0","tags":["Shell"],"title":"shell 常用脚本","uri":"/ch18_%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/"},{"categories":["linux"],"content":"Linux服务器运行久时，系统时间就会存在一定的误差，一般情况下可以使用date命令进行时间设置，但在做数据库集群分片等操作时对多台机器的时间差是有要求的，此时就需要使用ntpdate进行时间同步 ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:0:0","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"手动修改 手动设置时间，需要使用 sudo 权限用户 # 当前时区具体的时间 date -s \"2022-12-31 23:59:59\" # 写入修改后的时间到硬件时钟（RTC）中，将确保设置的时间在下次启动时保持不变 hwclock --systohc 手动修改时间会有误差，建议使用下面的时间服务器进行同步更新 ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:1:0","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"通过时间服务器校正 sudo yum install ntpdate -y ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:2:0","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"同步时间 sudo ntpdate -b time1.aliyun.com ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:2:1","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"配置启动ntpd $ vi /etc/ntp.conf ... # For more information about this file, see the man pages # ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5). driftfile /var/lib/ntp/drift # Permit time synchronization with our time source, but do not # permit the source to query or modify the service on this system. restrict default nomodify notrap nopeer noquery # Permit all access over the loopback interface. This could # be tightened as well, but to do so would effect some of # the administrative functions. restrict 127.0.0.1 restrict ::1 # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server time1.aliyun.com #broadcast 192.168.1.255 autokey # broadcast server #broadcastclient # broadcast client #broadcast 224.0.1.1 autokey # multicast server #multicastclient 224.0.1.1 # multicast client #manycastserver 239.255.254.254 # manycast server #manycastclient 239.255.254.254 autokey # manycast client # Enable public key cryptography. #crypto includefile /etc/ntp/crypto/pw # Key file containing the keys and key identifiers used when operating # with symmetric key cryptography. keys /etc/ntp/keys # Specify the key identifiers which are trusted. #trustedkey 4 8 42 # Specify the key identifier to use with the ntpdc utility. #requestkey 8 # Specify the key identifier to use with the ntpq utility. #controlkey 8 # Enable writing of statistics records. #statistics clockstats cryptostats loopstats peerstats # Disable the monitoring facility to prevent amplification attacks using ntpdc # monlist command when default restrict does not include the noquery flag. See # CVE-2013-5211 for more details. # Note: Monitoring will not be disabled with the limited restriction flag. ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:2:2","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"设置开机自启 sudo systemctl status ntpd; sudo systemctl start ntpd; sudo systemctl enable ntpd; ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:2:3","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":["linux"],"content":"ntp 常用服务器 国内 cn.pool.ntp.org 中国开源免费NTP服务器 ntp1.aliyun.com 阿里云NTP服务器 ntp2.aliyun.com 阿里云NTP服务器 time1.aliyun.com 阿里云NTP服务器 time2.aliyun.com 阿里云NTP服务器 国外 time1.apple.com 苹果NTP服务器 time2.apple.com 苹果NTP服务器 time3.apple.com 苹果NTP服务器 time4.apple.com 苹果NTP服务器 time5.apple.com 苹果NTP服务器 time1.google.com 谷歌NTP服务器 time2.google.com 谷歌NTP服务器 time3.google.com 谷歌NTP服务器 time4.google.com 谷歌NTP服务器 pool.ntp.org 开源免费NTP服务器 ","date":"2019-06-29","objectID":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/:2:4","tags":["linux"],"title":"Linux 时间校正","uri":"/linux%E6%97%B6%E9%97%B4%E6%A0%A1%E6%AD%A3/"},{"categories":null,"content":"友链 Hugo LoveIt 官方文档 ","date":"0001-01-01","objectID":"/friends/:1:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"资料 云原生资料库 Istio中文文档 ","date":"0001-01-01","objectID":"/friends/:2:0","tags":null,"title":"友链墙","uri":"/friends/"}]