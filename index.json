[{"categories":["Kubernetes"],"content":"资源对象概述 Kubernetes中的基本概念和术语大多是围绕资源对象（Resource Object）来说的，而资源对象在总体上可分为以下两类。 某种资源的对象，例如节点（Node）、Pod、服务（Service）、存储卷（Volume） 与资源对象相关的事物与动作，例如标签（Label）、注解（Annotation）、命名空间（Namespace）、部署（Deployment）、HPA、PVC。 集群类 集群（Cluster）表示一个由Master和Node组成的Kubernetes集群。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:0:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Master Master指的是集群的控制节点。在每个Kubernetes集群中都需要有一个或一组被称为Master的节点，来负责整个集群的管理和控制。Master通常占据一个独立的服务器（在高可用部署中建议至少使用3台服务器），是整个集群的\"大脑\"，如果它发生宕机或者不可用，那么对集群内容器应用的管理都将无法实施。 在Master上运行着以下关键进程。 Kubernetes API Server（kube-apiserver）：提供HTTP RESTfulAPI接口的主要服务，是Kubernetes里对所有资源进行增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager）：Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的\"大总管\"。 Kubernetes Scheduler（kube-scheduler）：负责资源调度（Pod调度）的进程，相当于公交公司的调度室。 另外，在Master上通常还需要部署etcd服务 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:1:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Node Kubernetes集群中除Master外的其他服务器被称为Node，Node在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他Node上。 在每个Node上都运行着以下关键进程。 kubelet：负责Pod对应容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy：实现Kubernetes Service的通信与负载均衡机制的服务。 容器运行时（如Docker）：负责本机的容器创建和管理。Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个Node上已正确安装、配置和启动了上述关键进程。在默认情况下，kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范畴，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、主机CPU和内存使用情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。而某个Node在超过指定时间不上报信息时，会被Master判定为\"失联\"，该Node的状态就被标记为不可用（NotReady），Master随后会触发\"工作负载大转移\"的自动流程。 应用类 Kubernetes中属于应用类的概念和相应的资源对象类型最多，所以应用类也是需要重点学习的一类。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:2:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service与Pod 应用类相关的资源对象主要是围绕Service（服务）和Pod这两个核心对象展开的。 一般说来，Service指的是无状态服务，通常由多个程序副本提供服务，在特殊情况下也可以是有状态的单实例服务，比如MySQL这种数据存储类的服务。与我们常规理解的服务不同，Kubernetes里的Service具有一个全局唯一的虚拟ClusterIP地址，Service一旦被创建，Kubernetes就会自动为它分配一个可用的ClusterIP地址，而且在Service的整个生命周期中，它的ClusterIP地址都不会改变，客户端可以通过这个虚拟IP地址+服务的端口直接访问该服务，再通过部署Kubernetes集群的DNS服务，就可以实现Service Name（域名）到ClusterIP地址的DNS映射功能，我们只要使用服务的名称（DNS名称）即可完成到目标服务的访问请求。“服务发现\"这个传统架构中的棘手问题在这里首次得以完美解决，同时，凭借ClusterIP地址的独特设计，Kubernetes进一步实现了Service的透明负载均衡和故障自动恢复的高级特性。 通过分析、识别并建模系统中的所有服务为微服务——Kubernetes Service，我们的系统最终由多个提供不同业务能力而又彼此独立的微服务单元组成，服务之间通过TCP/IP进行通信，从而形成强大又灵活的弹性网格，拥有强大的分布式能力、弹性扩展能力、容错能力，程序架构也变得简单和直观许多 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:3:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Pod 为什么Kubernetes会设计出一个全新的Pod概念并且Pod有这样特殊的组成结构？原因如下。 为多进程之间的协作提供一个抽象模型，使用Pod作为基本的调度、复制等管理工作的最小单位，让多个应用进程能一起有效地调度和伸缩。 Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术实现，例如Flannel、OpenvSwitch等，因此我们需要牢记一点：在Kubernetes里，一个Pod里的容器与另外主机上的Pod容器能够直接通信。 Pod其实有两种类型：普通的Pod及静态Pod（Static Pod）。后者比较特殊，它并没被存放在Kubernetes的etcd中，而是被存放在某个具体的Node上的一个具体文件中，并且只能在此Node上启动、运行。而普通的Pod一旦被创建，就会被放入etcd中存储，随后被Kubernetes Master调度到某个具体的Node上并绑定（Binding），该Pod被对应的Node上的kubelet进程实例化成一组相关的Docker容器并启动。在默认情况下，当Pod里的某个容器停止时，Kubernetes会自动检测到这个问题并且重新启动这个Pod（重启Pod里的所有容器），如果Pod所在的Node宕机，就会将这个Node上的所有Pod都重新调度到其他节点上。 Pod、容器与Node的关系 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:4:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Label与标签选择器 Label（标签）是Kubernetes系统中的另一个核心概念，相当于我们熟悉的\"标签”。一个Label是一个key=value的键值对，其中的key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、Deployment等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作，例如，部署不同版本的应用到不同的环境中，以及监控、分析应用（日志记录、监控、告警）等。一些常用的Label示例如下。 版本标签：release：stable和release：canary。 环境标签：environment：dev、environment：qa和environment：production。 架构标签：tier：frontend、tier：backend和tier：middleware。 分区标签：partition：customerA和partition：customerB。 质量管控标签：track：daily和track：weekly Label也是Pod的重要属性之一，其重要性仅次于Pod的端口，我们几乎见不到没有Label的Pod Service很重要的一个属性就是标签选择器，如果我们不小心把标签选择器写错了，就会出现指鹿为马的闹剧。如果恰好匹 配到了另一种Pod实例，而且对应的容器端口恰好正确，服务可以正常连接，则很难排查问题，特别是在有众多Service的复杂系统中。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:5:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Pod与Deployment 前面提到，大部分Service都是无状态的服务，可以由多个Pod副本实例提供服务。通常情况下，每个Service对应的Pod服务实例数量都是固定的，如果一个一个地手工创建Pod实例，就太麻烦了，最好是用模板的思路，即提供一个Pod模板（Template），然后由程序根据我们指定的模板自动创建指定数量的Pod实例。这就是Deployment这个资源对象所要完成的事情了。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:6:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service的ClusterIP地址 既然每个Pod都会被分配一个单独的IP地址，而且每个Pod都提供了一个独立的Endpoint（Pod IP+containerPort）以被客户端访问，那么现在多个Pod副本组成了一个集群来提供服务，客户端如何访问它们呢？传统的做法是部署一个负载均衡器（软件或硬件），为这组Pod开启一个对外的服务端口如8000端口，并且将这些Pod的Endpoint列表加入8000端口的转发列表中，客户端就可以通过负载均衡器的对外IP地址+8000端口来访问此服务了。Kubernetes也是类似的做法，Kubernetes内部在每个Node上都运行了一套全局的虚拟负载均衡器，自动注入并自动实时更新集群中所有Service的路由表，通过iptables或者IPVS机制，把对Service的请求转发到其后端对应的某个Pod实例上，并在内部实现服务的负载均衡与会话保持机制。不仅如此，Kubernetes还采用了一种很巧妙又影响深远的设计——ClusterIP地址。我们知道，Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变，因为新Pod的IP地址与之前旧Pod的不同。Service一旦被创建，Kubernetes就会自动为它分配一个全局唯一的虚拟IP地址——ClusterIP地址，而且在Service的整个生命周期内，其ClusterIP地址不会发生改变，这样一来，每个服务就变成了具备唯一IP地址的通信节点，远程服务之间的通信问题就变成了基础的TCP网络通信问题。 之所以说ClusterIP地址是一种虚拟IP地址，原因有以下几点。 ClusterIP地址仅仅作用于Kubernetes Service这个对象，并由Kubernetes管理和分配IP地址（来源于ClusterIP地址池），与Node和Master所在的物理网络完全无关。 因为没有一个\"实体网络对象\"来响应，所以ClusterIP地址无法被Ping通。ClusterIP地址只能与Service Port组成一个具体的服务访问端点，单独的ClusterIP不具备TCP/IP通信的基础。 ClusterIP属于Kubernetes集群这个封闭的空间，集群外的节点要访问这个通信端口，则需要做一些额外的工作 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:7:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"Service的外网访问问题 前面提到，服务的ClusterIP地址在Kubernetes集群内才能被访问，那么如何让集群外的应用访问我们的服务呢？这也是一个相对复杂的问题。要弄明白这个问题的解决思路和解决方法，我们需要先弄明白 Kubernetes的三种IP，这三种IP分别如下。 Node IP：Node的IP地址。 Pod IP：Pod的IP地址。 Service IP：Service的IP地址。 首先，Node IP是Kubernetes集群中每个节点的物理网卡的IP地址，是一个真实存在的物理网络，所有属于这个网络的服务器都能通过这个网络直接通信，不管其中是否有部分节点不属于这个Kubernetes集群。这也表明Kubernetes集群之外的节点访问Kubernetes集群内的某个节点或者TCP/IP服务时，都必须通过Node IP通信。 其次，Pod IP是每个Pod的IP地址，在使用Docker作为容器支持引擎的情况下，它是Docker Engine根据docker0网桥的IP地址段进行分配的，通常是一个虚拟二层网络。前面说过，Kubernetes要求位于不同Node上的Pod都能够彼此直接通信，所以Kubernetes中一个Pod里的容器访问另外一个Pod里的容器时，就是通过Pod IP所在的虚拟二层网络进行通信的，而真实的TCP/IP流量是通过Node IP所在的物理网卡流出的。 在Kubernetes集群内，Service的ClusterIP地址属于集群内的地址，无法在集群外直接使用这个地址。为了解决这个问题，Kubernetes首先引入了NodePort这个概念，NodePort也是解决集群外的应用访问集群内服务的直接、有效的常见做法 NodePort的实现方式是，在Kubernetes集群的每个Node上都为需要外部访问的Service开启一个对应的TCP监听端口，外部系统只要用任意一个Node的IP地址+NodePort端口号即可访问此服务，在任意Node上运行netstat命令，就可以看到有NodePort端口被监听。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:8:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"NodePort 存在的一问题引出了Ingress对象 NodePort的确功能强大且通用性强，但也存在一个问题，即每个Service都需要在Node上独占一个端口，而端口又是有限的物理资源，那能不能让多个Service共用一个对外端口呢？这就是后来增加的Ingress资源对象所要解决的问题。在一定程度上，我们可以把Ingress的实现机制理解为基于Nginx的支持虚拟主机的HTTP代理。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:9:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"有状态的应用集群 我们知道，Deployment对象是用来实现无状态服务的多副本自动控制功能的，那么有状态的服务，比如ZooKeeper集群、MySQL高可用集群（3节点集群）、Kafka集群等是怎么实现自动部署和管理的呢？这个问题就复杂多了，这些一开始是依赖StatefulSet解决的，但后来发现对于一些复杂的有状态的集群应用来说，StatefulSet还是不够通用和强大，所以后面又出现了Kubernetes Operator。 我们先说说StatefulSet。StatefulSet之前曾用过PetSet这个名称，很多人都知道，在IT世界里，有状态的应用被类比为宠物（Pet），无状态的应用则被类比为牛羊，每个宠物在主人那里都是\"唯一的存在\"，宠物生病了，我们是要花很多钱去治疗的，需要我们用心照料，而无差别的牛羊则没有这个待遇。总结下来，在有状态集群中一般有如下特殊共性。 每个节点都有固定的身份ID，通过这个ID，集群中的成员可以相互发现并通信。 集群的规模是比较固定的，集群规模不能随意变动。 集群中的每个节点都是有状态的，通常会持久化数据到永久存储中，每个节点在重启后都需要使用原有的持久化数据。 集群中成员节点的启动顺序（以及关闭顺序）通常也是确定的。 如果磁盘损坏，则集群里的某个节点无法正常运行，集群功能受损 StatefulSet从本质上来说，可被看作Deployment/RC的一个特殊变种，它有如下特性。 StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群内的其他成员。假设StatefulSet的名称为kafka，那么第1个Pod叫kafka-0，第2个叫kafka-1，以此类推。 StatefulSet控制的Pod副本的启停顺序是受控的，操作第n个Pod时，前n-1个Pod已经是运行且准备好的状态。 StatefulSet里的Pod采用稳定的持久化存储卷，通过PV或PVC来实现，删除Pod时默认不会删除与StatefulSet相关的存储卷（为了保证数据安全）。 StatefulSet除了要与PV卷捆绑使用，以存储Pod的状态数据，还要与Headless Service配合使用，即在每个StatefulSet定义中都要声明它属于哪个Headless Service。StatefulSet在Headless Service的基础上又为StatefulSet控制的每个Pod实例都创建了一个DNS域名，这个域名的格式 如下： ${podname}.${headless service name} StatefulSet的建模能力有限，面对复杂的有状态集群时显得力不从心，所以就有了后来的Kubernetes Operator框架和众多的Operator实现了。需要注意的是，Kubernetes Operator框架并不是面向普通用户的，而是面向Kubernetes平台开发者的。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:10:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"批处理应用 除了无状态服务、有状态集群、常见的第三种应用，还有批处理应用。批处理应用的特点是一个或多个进程处理一组数据（图像、文件、视频等），在这组数据都处理完成后，批处理任务自动结束。为了支持这类应用，Kubernetes引入了新的资源对象——Job。 Jobs控制器提供了两个控制并发数的参数：completions和parallelism，completions表示需要运行任务数的总数，parallelism表示并发运行的个数，例如设置parallelism为1，则会依次运行任务，在前面的任务运行后再运行后面的任务。Job所控制的Pod副本是短暂运行的，可以将其视为一组容器，其中的每个容器都仅运行一次。当Job控制的所有Pod副本都运行结束时，对应的Job也就结束了。Job在实现方式上与Deployment等副本控制器不同，Job生成的Pod副本是不能自动重启的，对应Pod副本的restartPolicy都被设置为Never，因此，当对应的Pod副本都执行完成时，相应的Job也就完成了控制使命。后来，Kubernetes增加了CronJob，可以周期性地执行某个任务。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:11:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"应用的配置问题 通过前面的学习，我们初步理解了三种应用建模的资源对象，总结如下。 无状态服务的建模：Deployment。 有状态集群的建模：StatefulSet。 批处理应用的建模：Job。 在进行应用建模时，应该如何解决应用需要在不同的环境中修改配置的问题呢？这就涉及ConfigMap和Secret两个对象。 ConfigMap顾名思义，就是保存配置项（key=value）的一个Map，如果你只是把它理解为编程语言中的一个Map，那就大错特错了。ConfigMap是分布式系统中\"配置中心\"的独特实现之一。我们知道，几乎所有应用都需要一个静态的配置文件来提供启动参数，当这个应用是一个分布式应用，有多个副本部署在不同的机器上时，配置文件的分发就成为一个让人头疼的问题，所以很多分布式系统都有一个配置中心组件，来解决这个问题。但配置中心通常会引入新的API，从而导致应用的耦合和侵入。 用户将配置文件的内容保存到ConfigMap中，文件名可作为key，value就是整个文件的内容，多个配置文件都可被放入同一个ConfigMap。 在建模用户应用时，在Pod里将ConfigMap定义为特殊的Volume进行挂载。在Pod被调度到某个具体Node上时，ConfigMap里的配置文件会被自动还原到本地目录下，然后映射到Pod里指定的配置目录下，这样用户的程序就可以无感知地读取配置了。 在ConfigMap的内容发生修改后，Kubernetes会自动重新获取ConfigMap的内容，并在目标节点上更新对应的文件。 接下来说说Secret。Secret也用于解决应用配置的问题，不过它解决的是对敏感信息的配置问题，比如数据库的用户名和密码、应用的数字证书、Token、SSH密钥及其他需要保密的敏感配置。对于这类敏感信息，我们可以创建一个Secret对象，然后被Pod引用。Secret中的数据要求以BASE64编码格式存放。注意，BASE64编码并不是加密的，在Kubernetes 1.7版本以后，Secret中的数据才可以以加密的形式进行保存，更加安全。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:12:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"应用的运维问题 最后说说与应用的自动运维相关的几个重要对象。 首先就是HPA（Horizontal Pod Autoscaler），如果我们用Deployment来控制Pod的副本数量，则可以通过手工运行kubectl scale命令来实现Pod扩容或缩容。如果仅仅到此为止，则显然不符合谷歌对Kubernetes的定位目标——自动化、智能化。在谷歌看来，分布式系统要能够根据当前负载的变化自动触发水平扩容或缩容，因为这一过程可能是频繁发生、不可预料的，所以采用手动控制的方式是不现实的，因此就有了后来的HPA这个高级功能。我们可以将HPA理解为Pod横向自动扩容，即自动控制Pod数量的增加或减少。通过追踪分析指定Deployment控制的所有目标Pod的负载变化情况，来确定是否需要有针对性地调整目标Pod的副本数量，这是HPA的实现原理。Kubernetes内置了基于Pod的CPU利用率进行自动扩缩容的机制，应用开发者也可以自定义度量指标如每秒请求数，来实现自定义的HPA功能。 存储类 存储类的资源对象主要包括Volume、Persistent Volume、PVC和StorageClass。 首先看看基础的存储类资源对象——Volume（存储卷） Volume是Pod中能够被多个容器访问的共享目录。Kubernetes中的Volume概念、用途和目的与Docker中的Volume比较类似，但二者不能等价。首先，Kubernetes中的Volume被定义在Pod上，被一个Pod里的多个容器挂载到具体的文件目录下；其次，Kubernetes中的Volume与Pod的生命周期相同，但与容器的生命周期不相关，当容器终止或者重启时，Volume中的数据也不会丢失；最后，Kubernetes支持多种类型的Volume，例如GlusterFS、Ceph等分布式文件系统。Volume的使用也比较简单，在大多数情况下，我们先在Pod上声明一个Volume，然后在容器里引用该Volume并将其挂载（Mount）到容器里的某个目录下。举例来说，若我们要给之前的Tomcat Pod增加一个名为datavol的Volume，并将其挂载到容器的某个路径/mydata-data目录下，则只对Pod的定义文件做下修正即可。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:13:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"emptyDir 一个emptyDir是在Pod分配到Node时创建的。从它的名称就可以看出，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为这是Kubernetes自动分配的一个目录，当Pod从Node上移除时，emptyDir中的数据也被永久移除。emptyDir的一些用途如下。 临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留。 长时间任务执行过程中使用的临时目录。 一个容器需要从另一个容器中获取数据的目录（多容器共享目录）。 在默认情况下，emptyDir使用的是节点的存储介质，例如磁盘或者网络存储。还可以使用emptyDir.medium属性，把这个属性设置为\"Memory\"，就可以使用更快的基于内存的后端存储了。需要注意的是，这种情况下的emptyDir使用的内存会被计入容器的内存消耗，将受到资源限制和配额机制的管理。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:14:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"hostPath hostPath为在Pod上挂载宿主机上的文件或目录，通常可以用于以下几方面。 在容器应用程序生成的日志文件需要永久保存时，可以使用宿主机的高速文件系统对其进行存储。 需要访问宿主机上Docker引擎内部数据结构的容器应用时，可以通过定义hostPath为宿主机/var/lib/docker目录，使容器内部的应用可以直接访问Docker的文件系统。 在使用这种类型的Volume时，需要注意以下几点。 在不同的Node上具有相同配置的Pod，可能会因为宿主机上的目录和文件不同，而导致对Volume上目录和文件的访问结果不一致。 如果使用了资源配额管理，则Kubernetes无法将hostPath在宿主机上使用的资源纳入管理。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:15:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"公有云Volume 公有云提供的Volume类型包括谷歌公有云提供的GCEPersistentDisk、亚马逊公有云提供的AWS Elastic Block Store（EBSVolume）等。当我们的Kubernetes集群运行在公有云上或者使用公有云厂家提供的Kubernetes集群时，就可以使用这类Volume。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:16:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":["Kubernetes"],"content":"其他类型的Volume iscsi：将iSCSI存储设备上的目录挂载到Pod中。 nfs：将NFS Server上的目录挂载到Pod中。 glusterfs：将开源GlusterFS网络文件系统的目录挂载到Pod中。 rbd：将Ceph块设备共享存储（Rados Block Device）挂载到Pod中。 gitRepo：通过挂载一个空目录，并从Git库克隆（clone）一个git repository以供Pod使用。 configmap：将配置数据挂载为容器内的文件。 secret：将Secret数据挂载为容器内的文件。 安全类 安全始终是Kubernetes发展过程中的一个关键领域。 从本质上来说，Kubernetes可被看作一个多用户共享资源的资源管理系统，这里的资源主要是各种Kubernetes里的各类资源对象，比如Pod、Service、Deployment等。只有通过认证的用户才能通过Kubernetes的API Server查询、创建及维护相应的资源对象，理解这一点很关键。 Kubernetes里的用户有两类：我们开发的运行在Pod里的应用；普通用户，如典型的kubectl命令行工具，基本上由指定的运维人员（集群管理员）使用。在更多的情况下，我们开发的Pod应用需要通过API Server查询、创建及管理其他相关资源对象，所以这类用户才是Kubernetes的关键用户。为此，Kubernetes设计了Service Account这个特殊的资源对象，代表Pod应用的账号，为Pod提供必要的身份认证。在此基础上，Kubernetes进一步实现和完善了基于角色的访问控制权限系统——RBAC（Role-Based Access Control）。 在默认情况下，Kubernetes在每个命名空间中都会创建一个默认的名称为default的Service Account，因此Service Account是不能全局使用的，只能被它所在命名空间中的Pod使用。通过以下命令可以查看集群中的所有Service Account： sudo kubectl get sa -A Service Account是通过Secret来保存对应的用户（应用）身份凭证的，这些凭证信息有CA根证书数据（ca.crt）和签名后的Token信息（Token）。在Token信息中就包括了对应的Service Account的名称，因此API Server通过接收到的Token信息就能确定Service Account的身份。在默认情况下，用户创建一个Pod时，Pod会绑定对应命名空间中的default这个Service Account作为其\"公民身份证\"。当Pod里的容器被创建时，Kubernetes会把对应的Secret对象中的身份信息（ca.crt、Token等）持久化保存到容器里固定位置的本地文件中，因此当容器里的用户进程通过Kubernetes提供的客户端API去访问API Server时，这些API会自动读取这些身份信息文件，并将其附加到HTTPS请求中传递给API Server以完成身份认证逻辑。在身份认证通过以后，就涉及\"访问授权\"的问题，这就是RBAC要解决的问题了。 首先我们要学习的是Role这个资源对象，包括Role与ClusterRole两种类型的角色。角色定义了一组特定权限的规则，比如可以操作某类资源对象。局限于某个命名空间的角色由Role对象定义，作用于整个Kubernetes集群范围内的角色则通过ClusterRole对象定义。 在RoleBinding中使用subjects（目标主体）来表示要授权的对象，这是因为我们可以授权三类目标账号：Group（用户组）、User（某个具体用户）和Service Account（Pod应用所使用的账号）。 在安全领域，除了以上针对API Server访问安全相关的资源对象，还有一种特殊的资源对象——NetworkPolicy（网络策略），它是网络安全相关的资源对象，用于解决用户应用之间的网络隔离和授权问题。NetworkPolicy是一种关于Pod间相互通信，以及Pod与其他网络端点间相互通信的安全规则设定。 NetworkPolicy资源使用标签选择Pod，并定义选定Pod所允许的通信规则。在默认情况下，Pod间及Pod与其他网络端点间的访问是没有限制的，这假设了Kubernetes集群被一个厂商（公司/租户）独占，其中部署的应用都是相互可信的，无须相互防范。但是，如果存在多个厂商共同使用一个Kubernetes集群的情况，则特别是在公有云环境中，不同厂商的应用要相互隔离以增加安全性，这就可以通过NetworkPolicy来实现了。 ","date":"2024-06-26","objectID":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/:17:0","tags":["Kubernetes"],"title":"Kubernetes的基本概念和术语","uri":"/kubernetes%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%9C%AF%E8%AF%AD/"},{"categories":[""],"content":"前言 [info] About Life 我们在人的一生中最为辉煌的一天，并不是功成名就的那一天，而是从悲叹和绝望中产生对人生挑战的欲望，并且勇敢的迈向这种挑战的那一天。 人生当中成功只是一时的，失败却是主旋律。但是如何面对失败却把人分成了不同的样子。有的人会被失败击垮，有的人能够不断的爬起来，继续向前。 我想真正的成熟，应该并不是追求完美，而是直面自己的缺憾，这才是生活的本质。 也许他们会明白莫泊桑的一句话：生活可能不像你想象的那么好，但是也不会像你想象的那么糟。人的脆弱和坚强都超乎了自己的想象。有时候，可能脆弱的一句话就泪流满面，有时候，你发现自己咬着牙已经走过了很长的路， 人的一生中最大的问题不是找不到正确的方法而是在实践中长久的悖逆人性 [success] About Persistence(最淡的墨水也胜过最强的记忆) Nothing in the world can take the place of Persistence. Talent will not; nothing is more common than unsuccessful men with talent. Genius will not; unrewarded genius is almost a proverb. Education will not; the world is full of educated derelicts. Persistence and Determination alone are omnipotent. The slogan “Press On” has solved and will always solve the problems of the human race. 个人介绍 简要介绍：人间大白,目前居住南京，目前在一家云计算公司从事DevOps相关的工作，喜欢云原生并通过了CKA,CKS认证,对监控落地有相关经验， 熟练使用Docker、K8s，有生产k8s集群的构建、运维、优化、排错经验，熟悉各种开源中间件的部署和优化，有运维自动化、监控系统 相关开发经验。 个人信息：卢栓 拿手菜：清蒸鲈鱼、酸辣土豆丝、西红柿炒蛋、炒花蛤、香辣小炒肉 兴趣爱好：篮球、音乐、阅读、掼蛋 微信交流：shuanlu0614 邮箱：lushuan2071@126.com 工具链: Kubernetes Prometheus InfluxDB Grafana Ansible Docker Helm Linux GoLang Shell MySQL ","date":"2023-09-15","objectID":"/about/:0:0","tags":[""],"title":"About","uri":"/about/"},{"categories":null,"content":"test test LoveIt提供了admonition shortcode，支持 12 种样式，可以在页面中插入提示的横幅。代码如下 ","date":"2023-09-14","objectID":"/first_post/:1:0","tags":null,"title":"First_post","uri":"/first_post/"},{"categories":null,"content":"主题自带的admonition样式 注意\r一个 注意 横幅\r摘要\r一个 摘要 横幅\r信息\r一个 信息 横幅\r技巧\r一个 技巧 横幅\r成功\r一个 成功 横幅\r问题\r一个 问题 横幅\r警告\r一个 警告 横幅\r失败\r一个 失败 横幅\r危险\r一个 危险 横幅\rBug\r一个 Bug 横幅\r示例\r一个 示例 横幅\r引用\r一个 引用 横幅\r注意\r一个 注意 横幅\r摘要\r一个 摘要 横幅\r信息\r一个 信息 横幅\r技巧\r一个 技巧 横幅\r成功\r一个 成功 横幅\r问题\r一个 问题 横幅\r警告\r一个 警告 横幅\r失败\r一个 失败 横幅\r危险\r一个 危险 横幅\rBug\r一个 Bug 横幅\r示例\r一个 示例 横幅\r引用\r一个 引用 横幅\r","date":"2023-09-14","objectID":"/first_post/:2:0","tags":null,"title":"First_post","uri":"/first_post/"},{"categories":["docker"],"content":"介绍 Dockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction)，每一条指令 构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 一个简单Dockerfile文件 # VERSION 0.0.1 FROM ubuntu MAINTAINER James Turnbull \"james@example.com\" RUN echo \"deb http://archive.ubuntu.com/ubuntu precise main ↩ universe\" \u003e /etc/apt/sources.list RUN apt-get update RUN apt-get install -y openssh-server RUN mkdir /var/run/sshd RUN echo \"root:password\" | chpasswd EXPOSE 22 可以看的出来Dockerfile 包含一系列命令并附上参数 每个命令都是大写开头，后面是跟着参数 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:0:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"Dockerfile 命令 命令 解释 FROM 指定基础镜像 RUN Dockerfile中的每个指令都会创建一个新的镜像层 CMD 在容器中执行的命令 EXPOSE 暴露端口 ENV 设置环境变量 COPY 拷贝本地文件和目录至镜像 ADD 功能更丰富的添加拷贝指令，COPY优先于ADD ENTRYPOINT ENTRYPOINT指令并不是必须的，ENTRYPOINT是一个脚本 VOLUME 定义镜像中的某个目录为容器卷，会随机生成一个容器卷名 WORKDIR 指定工作目录 ARG 定义了可以通过docker build –build-arg命令传递并在Dockerfile中使用的变量。 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:1:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"Dockerfile 小建议 要使用 tag，但不要 latest。 Debian 挺好的，不要总 Ubuntu。 apt-get update 在前，rm -rf /var/lib/apt/lists/* 在后。 yum install，不忘 yum clean。 多 RUN 要合并，来减少层数。 无用的软件，不要乱安装。 COPY 放最后，缓存很开心。 善用 dockerignore，不浪费传输。 不忘 MAINTAINER，这都是我的。 容器只运行一个应用 小结：（FROM）选择合适的基础镜像(alpine版本最好)，(RUN)在安装更新时勿忘删除缓存和安装包， 多个命令聚合在一起减少构建时的层数，用不到的软件不要安装，(ADD和COPY)选COPY,（LABEL）添加镜像元数据， (MAINTAINER)让我知道是谁维护我，(ENV)设置默认的环境变量，（EXPOSE）说一下暴露的映射端口 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:2:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"示例 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:3:0","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"nginx FROM centos MAINTAINER xianchao RUN yum install wget -y RUN yum install nginx -y # COPY index.html /usr/share/nginx/html/ EXPOSE 80 ENTRYPOINT [\"/usr/sbin/nginx\",\"-g\",\"daemon off;\"] ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:3:1","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["docker"],"content":"tomcat FROM centos MAINTAINER xianchao RUN yum install wget -y ADD jdk-8u45-linux-x64.rpm /usr/local/ ADD apache-tomcat-8.0.26.tar.gz /usr/local/ RUN cd /usr/local \u0026\u0026 rpm -ivh jdk-8u45-linux-x64.rpm RUN mv /usr/local/apache-tomcat-8.0.26 /usr/local/tomcat8 ENTRYPOINT /usr/local/tomcat8/bin/startup.sh \u0026\u0026 tail -F /usr/local/tomcat8/logs/catalina.out EXPOSE 8080 ","date":"2023-06-26","objectID":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/:3:2","tags":["docker"],"title":"Dockerfile介绍及优化","uri":"/dockerfile%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["Kubernetes"],"content":"k8s namespace 无法删除记录 名字空间yaml 文件 kind: Namespace apiVersion: v1 metadata: name: kube-logging 删除卡住 $ sudo kubectl delete -f kube-logging.yaml --wait=true namespace \"kube-logging\" deleted # 长久的等待 强制删除（无效果） sudo kubectl delete ns kube-logging --grace-period=0 --force 排查思路 查看命名空间下的所有资源 kubectl api-resources -o name --verbs=list --namespaced | xargs -n 1 kubectl get --show-kind --ignore-not-found -n kube-logging 输出结果该命名空间下无关联的相关资源 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:0","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"解决方式 一行命令解决，注意替换两处待删命名空间字样 kubectl get namespace \"待删命名空间\" -o json \\ | tr -d \"\\n\" | sed \"s/\\\"finalizers\\\": \\[[^]]\\+\\]/\\\"finalizers\\\": []/\" \\ | kubectl replace --raw /api/v1/namespaces/待删命名空间/finalize -f - ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:1","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"总结 创建namesapce时注入finalizers会导致namespace无法 可以通过edit ns 的方式将finalizers 置空或者上面的一行命令解决的方式，本质是一致的 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:2","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"补充 K8s Finalizers Finalizers 字段属于 Kubernetes GC 垃圾收集器，是一种删除拦截机制，能够让控制器实现异步的删除前（Pre-delete）回调。其存在于任何一个资源对象的 Meta[1] 中，在 k8s 源码中声明为 []string，该 Slice 的内容为需要执行的拦截器名称。 对带有 Finalizer 的对象的第一个删除请求会为其 metadata.deletionTimestamp 设置一个值，但不会真的删除对象。一旦此值被设置，finalizers 列表中的值就只能被移除。 当 metadata.deletionTimestamp 字段被设置时，负责监测该对象的各个控制器会通过轮询对该对象的更新请求来执行它们所要处理的所有 Finalizer。当所有 Finalizer 都被执行过，资源被删除。 metadata.deletionGracePeriodSeconds 的取值控制对更新的轮询周期 当 finalizers 字段为空时，k8s 认为删除已完成。 ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:0:3","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"参考 k8s 如何让 ns 无法删除 kubernetes_Namespace无法删除的解决方法 K8S从懵圈到熟练 - 我们为什么会删除不了集群的命名空间？ k8s问题解决 - 删除命名空间长时间处于terminating状态 熟悉又陌生的 k8s 字段：finalizers ","date":"2023-05-27","objectID":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/:1:0","tags":["Kubernetes排障"],"title":"K8s删除Namesapce一直处于Terminating状态处理","uri":"/k8s%E5%88%A0%E9%99%A4namesapce%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Eterminating%E7%8A%B6%E6%80%81%E5%A4%84%E7%90%86/"},{"categories":["Kubernetes"],"content":"故障描述 PVC 显示创建不成功：kubectl get pvc -n efk 显示 Pending，这是由于版本太高导致的。k8sv1.20 以上版本默认禁止使用 selfLink。(selfLink：通过 API 访问资源自身的 URL，例如一个 Pod 的 link 可能是 /api/v1/namespaces/ns36aa8455/pods/sc-cluster-test-1-6bc58d44d6-r8hld)。 ","date":"2023-05-26","objectID":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes v1.20创建PVC报错","uri":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/"},{"categories":["Kubernetes"],"content":"故障解决 $ vi /etc/kubernetes/manifests/kube-apiserver.yaml apiVersion: v1 ··· - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key - --feature-gates=RemoveSelfLink=false # 添加这个配置 重启下kube-apiserver.yaml # 如果是二进制安装的 k8s，执行 systemctl restart kube-apiserver # 如果是 kubeadm 安装的 k8s $ ps aux|grep kube-apiserver $ kill -9 [Pid] $ kubectl apply -f /etc/kubernetes/manifests/kube-apiserver.yaml ... $ kubectl get pvc # 查看 pvc 显示 Bound NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE my-pvc Bound pvc-ae9f6d4b-fc4c-4e19-8854-7bfa259a3a04 1Gi RWX example-nfs 13m ","date":"2023-05-26","objectID":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes v1.20创建PVC报错","uri":"/k8s_v1.20.x%E5%88%9B%E5%BB%BApvc%E6%8A%A5%E9%94%99/"},{"categories":["Kubernetes"],"content":" 当Kubernetes创建Pod时发生了什么-全景图 https://github.com/jamiehannaford/what-happens-when-k8s/tree/master/zh-cn ","date":"2023-03-26","objectID":"/%E5%BD%93-kubernetes-%E5%88%9B%E5%BB%BA-pod-%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/:0:0","tags":["Kubernetes"],"title":"当 Kubernetes 创建 Pod 时发生了什么","uri":"/%E5%BD%93-kubernetes-%E5%88%9B%E5%BB%BA-pod-%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"记录一下kuberntes 遇到的问题场景及排查方向 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:0:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"DNS 解析异常 5 秒延时 如果DNS查询经常延时5秒才返回，通常是遇到内核 conntrack 冲突导致的丢包 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"解析超时 如果容器内报 DNS 解析超时，先检查下集群 DNS 服务 (kube-dns/coredns) 的 Pod 是否 Ready，如果不是，查看日志信息。如果运行正常，再具体看下超时现象。 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:1:1","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"Service 无法解析 集群 DNS 没有正常运行(kube-dns或CoreDNS) 检查集群 DNS 是否运行正常: kubelet 启动参数 –cluster-dns 可以看到 dns 服务的 cluster ip: $ ps -ef | grep kubelet ... /usr/bin/kubelet --cluster-dns=172.16.14.217 ... 或者放置配置文件中 $ cat /var/lib/kubelet/config.yaml|grep clusterDNS -A 2 clusterDNS: - 172.16.0.10 clusterDomain: cluster.local 找到 dns 的 service: $ kubectl get svc -n kube-system | grep 172.16.14.217 kube-dns ClusterIP 172.16.14.217 \u003cnone\u003e 53/TCP,53/UDP 47d 看是否存在 endpoint: $ kubectl -n kube-system describe svc kube-dns | grep -i endpoints Endpoints: 172.16.0.156:53,172.16.0.167:53 Endpoints: 172.16.0.156:53,172.16.0.167:53 检查 endpoint 的 对应 pod 是否正常: $ kubectl -n kube-system get pod -o wide | grep 172.16.0.156 kube-dns-898dbbfc6-hvwlr 3/3 Running 0 8d 172.16.0.156 10.0.0.3 ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"Pod 与 DNS 服务之间网络不通 检查下 pod 是否连不上 dns 服务，可以在 pod 里 telnet 一下 dns 的 53 端口: # 连 dns service 的 cluster ip $ telnet 172.16.14.217 53 如果检查到是网络不通，就需要排查下网络设置: 检查节点的安全组设置，需要放开集群的容器网段 检查是否还有防火墙规则，检查 iptables ","date":"2022-09-28","objectID":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/:2:1","tags":["Kubernetes排障"],"title":"Kubernetes 网络排障","uri":"/kubernetes-%E7%BD%91%E7%BB%9C%E6%8E%92%E9%94%99/"},{"categories":["Kubernetes"],"content":"背景 项目现场通过 kubeadm 部署一套 k8s 临时环境 版本是v1.22, 因为是临时环境，部署方式是一主两从的模式， 部署后十天客户直接将主节点的内存进行了扩容，导致现场的应用服务无法访问。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"现象 打开访问应用门户，提示 nginx 网关访问报错 503 Service Temporarily Unavailable ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"定位 通过 kubectl 查看 pod 状态发现很多应用是 CrashLoopBackOff,猜测是系统基础组件出现异常,查看应用日志提示 jdbc 连接 MySQL 异常，查看MySQL 日志发现端口52306被占用。 排查为 apiserver和etcd连接的随机端口占用了52306 # sudo netstat -nap|grep 52306 tcp 0 0 127.0.0.1:52306 127.0.0.1:2379 ESTABLISHED 30166/kube-apiserve tcp 0 0 127.0.0.1:2379 127.0.0.1:52306 ESTABLISHED 23788/etcd ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"问题处理 确认端口占用情况：执行 sudo netstat -lnp | grep 命令查看指定端口是否被占用 释放端口：如果该端口已被占用，可以通过 sudo lsof -i: 命令查找占用端口的进程 临时处理，pod 重建 kill 掉 etcd 的静态 pod，端口可能还是会重新被占用 永久处理，主机 k8s.conf 预留端口 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:4:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"保留预留端口 $ cat /etc/sysctl.d/k8s.conf net.ipv4.ip_forward = 1 kernel.core_pattern=/tmp/zcore/core.%h~%e fs.inotify.max_user_watches = 1048576 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_local_reserved_ports = 52000-52999 net.ipv4.ip_local_reserved_ports新增预留端口配置，保留端口范围不被占用，告诉内核保留端口范围从 52000 到 52999，以便这些端口不会被普通应用程序占用 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:4:1","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"/etc/sysctl.d/k8s.conf 配置项说明 在 Kubernetes 1.22 版本的 /etc/sysctl.d/k8s.conf 配置文件中，可能包含以下一些配置项： 1、 net.bridge.bridge-nf-call-ip6tables： 含义：控制是否将 IPv6 数据包传递给 iptables 的 netfilter 框架进行处理。如果设置为 1，则表示启用；如果设置为 0，则表示禁用。 默认值：1 2、 net.bridge.bridge-nf-call-iptables： 含义：控制是否将数据包传递给 iptables 的 netfilter 框架进行处理。如果设置为 1，则表示启用；如果设置为 0，则表示禁用。 默认值：1 3、 net.ipv4.ip_forward： 含义：控制 Linux 内核是否允许 IP 数据包转发。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 4、 net.ipv4.conf.all.forwarding： 含义：控制所有网络接口的 IP 转发功能。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 5、 net.ipv4.conf.default.forwarding： 含义：控制默认网络接口的 IP 转发功能。如果设置为 1，则表示启用 IP 转发；如果设置为 0，则表示禁用 IP 转发。 默认值：0 以上是常见的示例配置项和默认值，但实际的配置项和默认值可能会根据操作系统和 Kubernetes 版本而有所不同。在实际使用中，请根据文档和操作系统的要求进行正确配置。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/:5:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次 Apiserver 和 Etcd 连接的随机端口占用冲突问题","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1apiserver%E5%92%8Cetcd%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"问题现象 生产环境无法访问，这里主要是梳理遇到问题应该有的一个排查思路 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"问题排查 登录节点查看namespace 下各pod状态 kubectl get pod -o wide -n prod 发现portal cmdb application等均处于异常状态 由于portal启动会依赖cmdb 优先查看cmdb的日志，发现报错连接redis异常 查看redis状态 处于正常状态 kubectl get pod -o wide -n prod|grep redis 进入cmdb 容器进行redis 连接测试 telnet redis 6379 发现解析域名 redis 有问题 因此怀疑coredns存在问题 查看 coredns 状态 kubectl get pod -o wide -n kube-system|grep coredns 发现pod处于terminating以及pending 由于coredns配置有节点选择器，只会调度到k8s master节点 此外对master做了taint ,—-防止其它的各种系统组件向Master调度，导致master资源受压缩。（此污点对已经调度在该节点的pod不会产生驱逐，但是新建pod的将无法调度） $ kubectl describe node 10.10.xxx Name: 10.10.xxx Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=10.10.xxx kubernetes.io/os=linux kubernetes.io/role=master zcm.role=k8s Annotations: node.alpha.kubernetes.io/ttl: 0 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sat, 25 Mar 2023 10:08:15 +0800 Taints: scheduler=custom:NoSchedule Unschedulable: false 导致coredns pending 临时处理,将节点选择器移除 coredns调度成功，启动完成 portal cmdb等依赖redis的服务自行恢复 生产环境恢复访问 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"问题分析 问题发生前，集成对10.10.xxx等k8s master机器进行了迁移操作，主机发生了重启。 因此coredns发生重新调度，此时由于节点选择器以及taint的缘故，coredns无法成功调度启动， 进而影响了容器内对redis的解析 ，导致依赖redis的容器不断重启，生产环境无法访问。 后续对各个k8s集群的coredns配置了对污点的容忍，避免类似问题的再次发生。 ","date":"2022-05-18","objectID":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 记录一次项目生产环境故障分析","uri":"/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90/"},{"categories":["Kubernetes"],"content":"背景 statefulset 通过nfs 动态创建pv，发现无法创建成功 ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["Kubernetes"],"content":"报错日志 Warning FailedMount 2m50s (x6 over 6m4s) kubelet Unable to attach or mount volumes: unmounted volumes=[data], unattached volumes=[kube-api-access-8p8wf data]: error processing PVC kube-logging/data-es-cluster-0: PVC is not bound 通过报错日志可以看的出来pvc 无法绑定pv,通过命令查看pvc创建成功，pv 则没有进行创建 StatefulSet 挂载 NFS 存储卷时出现了问题,导致 PVC 没有被成功绑定到 PV的原因 常见原因有: PVC 和 PV 不匹配 PVC 的 storage class、访问模式、大小资源请求等需要和 PV 定义一致,否则不会被匹配到合适的 PV。 NFS 服务器配置问题 NFS 服务器需要正常启动、导出共享目录,并且 Kubernetes 节点能够访问到 NFS 服务器。 RBAC 鉴权问题 Kubernetes 节点上的 kubelet 需要有获取、挂载 PV 的权限。 NFS Client 配置问题 Kubernetes 节点上需要安装 NFS Client,并且配置可以访问 NFS 服务器。 StatefulSet 配置错误 StatefulSet 的 volumeClaimTemplates 需要与 PVC 的定义相匹配。 存储卷读写权限问题 存储卷需要有读写权限,避免因权限问题无法挂载。 ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["Kubernetes"],"content":"nfs 在kubernetes中动态创建pv和版本的关系 在早期的 Kubernetes 版本中(如 v1.11 之前),NFS provisioner 并不包含在默认部署中,这会导致通过 NFS 存储类无法动态创建 PV。 从 Kubernetes v1.11 开始,NFS 动态供应功能成为了默认部署的一部分,但也需要进行额外的配置,主要步骤包括: 安装 NFS 客户端组件 部署 NFS 动态供应器 external-provisioner 创建 StorageClass,指定 nfs 作为 provisioner 创建 PersistentVolumeClaim, 引用该 StorageClass 此时,NFS 供应器就可以根据 PVC 的请求动态创建 PV 来绑定 PVC。 所以简单来说,Kubernetes 低版本中需要手动安装和配置 NFS 动态供应器; 高版本中已内置但也需要显式配置才能启用该功能。正确配置后就可以通过 NFS StorageClass 来动态创建 PV。 这里的高版本指的是v1.20 之后，在 kube-apiserver 的启动参数中不移除 API 对象中的 selfLink 字段。 selfLink 是 Kubernetes 中每个 API 对象的一个字段,用于表示对象自身的 URL 地址 从 Kubernetes 1.20 版本开始,该字段默认被移除了。但可以通过设置 RemoveSelfLink=false 来保留该字段 原因是 selfLink 字段已很少被用到,但删去后可能会影响部分老版本的客户端。所以提供了这个特性开关来向后兼容 一般来说,除非确实需要兼容老版本客户端,否则不建议保留 selfLink 字段 显式开启方式： $ vi /etc/kubernetes/manifests/kube-apiserver.yaml .... spec: containers: - command: - kube-apiserver - --feature-gates=RemoveSelfLink=false ","date":"2022-05-18","objectID":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes 通过 nfs 动态创建 pv 异常","uri":"/kubernetes%E9%80%9A%E8%BF%87nfs%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BApv%E5%BC%82%E5%B8%B8/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 ContainerCreating 或 Waiting 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 配置错误 检查是否打包了正确的镜像 检查配置了正确的容器参数 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"磁盘爆满 启动 Pod 会调 CRI 接口创建容器，容器运行时创建容器时通常会在数据目录下为新建的容器创建一些目录和文件，如果数据目录所在的磁盘空间满了就会创建失败并报错: Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \"apigateway-6dc48bf8b6-l8xrw\": Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"limit 设置太小或者单位不对 如果 limit 设置过小以至于不足以成功运行 Sandbox 也会造成这种状态，常见的是因为 memory limit 单位设置不对造成的 limit 过小，比如误将 memory 的 limit 单位像 request 一样设置为小 m，这个单位在 memory 不适用，会被 k8s 识别成 byte， 应该用 Mi 或 M。， 举个例子: 如果 memory limit 设为 1024m 表示限制 1.024 Byte，这么小的内存， pause 容器一起来就会被 cgroup-oom kill 掉，导致 pod 状态一直处于 ContainerCreating。 这种情况通常会报下面的 event: Pod sandbox changed, it will be killed and re-created。 kubelet报错 to start sandbox container for pod ... Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused \"process_linux.go:301: running exec setns process for init caused \\\"signal: killed\\\"\": unknown ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"拉取镜像失败 镜像拉取失败也分很多情况，这里列举下: 配置了错误的镜像 Kubelet 无法访问镜像仓库（比如默认 pause 镜像在 gcr.io 上，国内环境访问需要特殊处理） 拉取私有镜像的 imagePullSecret 没有配置或配置有误 镜像太大，拉取超时（可以适当调整 kubelet 的 —image-pull-progress-deadline 和 —runtime-request-timeout 选项） ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"controller-manager 异常 查看 master 上 kube-controller-manager 状态，异常的话尝试重启。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:1:5","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Error 状态 通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括： 依赖的 ConfigMap、Secret 或者 PV 等不存在 请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等 违反集群的安全策略 容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:2:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 ImagePullBackOff 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"http 类型 registry，地址未加入到 insecure-registry dockerd 默认从 https 类型的 registry 拉取镜像，如果使用 https 类型的 registry，则必须将它添加到 insecure-registry 参数中，然后重启或 reload dockerd 生效。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"https 自签发类型 resitry，没有给节点添加 ca 证书 如果 registry 是 https 类型，但证书是自签发的，dockerd 会校验 registry 的证书，校验成功才能正常使用镜像仓库， 要想校验成功就需要将 registry 的 ca 证书放置到 /etc/docker/certs.d/\u003cregistry:port\u003e/ca.crt 位置。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"私有镜像仓库认证失败 如果 registry 需要认证，但是 Pod 没有配置 imagePullSecret，配置的 Secret 不存在或者有误都会认证失败。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像文件损坏 如果 push 的镜像文件损坏了，下载下来也用不了，需要重新 push 镜像文件 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像拉取超时 如果节点上新起的 Pod 太多就会有许多可能会造成容器镜像下载排队，如果前面有许多大镜像需要下载很长时间，后面排队的 Pod 就会报拉取超时。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:5","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"镜像不存在 kubelet 日志： PullImage \"imroc/test:v0.2\" from image service failed: rpc error: code = Unknown desc = Error response from daemon: manifest for imroc/test:v0.2 not found ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:3:6","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Pending 状态 Pending 状态说明 Pod 还没有被调度到某个节点上，需要看下 Pod 事件进一步判断原因，比如: $ kubectl describe pod tikv-0 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 3m (x106 over 33m) default-scheduler 0/4 nodes are available: 1 node(s) had no available volume zone, 2 Insufficient cpu, 3 Insufficient memory. 下面列举下可能原因和解决方法。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"节点资源不够 节点资源不够有以下几种情况: CPU 负载过高 剩余可以被分配的内存不够 如果判断某个 Node 资源是否足够？ 通过 kubectl describe node 查看 node 资源情况，关注以下信息： Allocatable: 表示此节点能够申请的资源总和 Allocated resources: 表示此节点已分配的资源 (Allocatable 减去节点上所有 Pod 总的 Request) $ sudo kubectl describe node 10.10.192.220|grep Allo -A 6 Allocatable: cpu: 8 ephemeral-storage: 33806352329 hugepages-2Mi: 0 memory: 24543516Ki pods: 110 System Info: -- Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 3650m (45%) 50150m (626%) memory 5092Mi (21%) 81290Mi (339%) ephemeral-storage 0 (0%) 0 (0%) 可以看到能够申请的资源总和，当前节点可以创建110个pods，cpu 8核，cpu requests占比45% 前者与后者相减，可得出剩余可申请的资源。如果这个值小于 Pod 的 request，就不满足 Pod 的资源要求，Scheduler 在 Predicates (预选) 阶段就会剔除掉这个 Node，也就不会调度上去 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"不满足 nodeSelector 与 affinity 如果 Pod 包含 nodeSelector 指定了节点需要包含的 label，调度器将只会考虑将 Pod 调度到包含这些 label 的 Node 上，如果没有 Node 有这些 label 或者有这些 label 的 Node 其它条件不满足也将会无法调度。参考官方文档： https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/ 如果 Pod 包含 affinity（亲和性）的配置，调度器根据调度算法也可能算出没有满足条件的 Node，从而无法调度。affinity 有以下几类: nodeAffinity: 节点亲和性，可以看成是增强版的 nodeSelector，用于限制 Pod 只允许被调度到某一部分 Node。 podAffinity: Pod 亲和性，用于将一些有关联的 Pod 调度到同一个地方，同一个地方可以是指同一个节点或同一个可用区的节点等。 podAntiAffinity: Pod 反亲和性，用于避免将某一类 Pod 调度到同一个地方避免单点故障，比如将集群 DNS 服务的 Pod 副本都调度到不同节点，避免一个节点挂了造成整个集群 DNS 解析失败，使得业务中断。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Node 存在 Pod 没有容忍的污点 如果节点上存在污点 (Taints)，而 Pod 没有响应的容忍 (Tolerations)，Pod 也将不会调度上去。通过 describe node 可以看下 Node 有哪些 Taints: $ kubectl describe nodes host1 ... Taints: special=true:NoSchedule ... 污点既可以是手动添加也可以是被自动添加 手动添加污点 $ kubectl taint node host1 special=true:NoSchedule node \"host1\" tainted 另外，有些场景下希望新加的节点默认不调度 Pod，直到调整完节点上某些配置才允许调度，就给新加的节点都加上 node.kubernetes.io/unschedulable 这个污点 自动添加污点 如果节点运行状态不正常，污点也可以被自动添加，从 v1.12 开始，TaintNodesByCondition 特性进入 Beta 默认开启，controller manager 会检查 Node 的 Condition，如果命中条件就自动为 Node 加上相应的污点，这些 Condition 与 Taints 的对应关系如下: Conditon Value Taints -------- ----- ------ OutOfDisk True node.kubernetes.io/out-of-disk Ready False node.kubernetes.io/not-ready Ready Unknown node.kubernetes.io/unreachable MemoryPressure True node.kubernetes.io/memory-pressure PIDPressure True node.kubernetes.io/pid-pressure DiskPressure True node.kubernetes.io/disk-pressure NetworkUnavailable True node.kubernetes.io/network-unavailable 解释下上面各种条件的意思: OutOfDisk 为 True 表示节点磁盘空间不够了 Ready 为 False 表示节点不健康 Ready 为 Unknown 表示节点失联，在 node-monitor-grace-period 这么长的时间内没有上报状态 controller-manager 就会将 Node 状态置为 Unknown (默认 40s) MemoryPressure 为 True 表示节点内存压力大，实际可用内存很少 PIDPressure 为 True 表示节点上运行了太多进程，PID 数量不够用了 DiskPressure 为 True 表示节点上的磁盘可用空间太少了 NetworkUnavailable 为 True 表示节点上的网络没有正确配置，无法跟其它 Pod 正常通信 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"kube-scheduler 没有正常运行 检查 maser 上的 kube-scheduler 是否运行正常，异常的话可以尝试重启临时恢复。 $ sudo kubectl -n kube-system get pod|grep kube-scheduler kube-scheduler-10.10.192.220 1/1 Running 183 (40d ago) 424d ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:4:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Terminating 状态 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"磁盘爆满 如果 docker 的数据目录所在磁盘被写满，docker 无法正常运行，无法进行删除和创建操作，所以 kubelet 调用 docker 删除容器没反应，看 event 类似这样： Normal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"存在 “i” 文件属性 如果容器的镜像本身或者容器启动后写入的文件存在 “i” 文件属性，此文件就无法被修改删除，而删除 Pod 时会清理容器目录，但里面包含有不可删除的文件，就一直删不了，Pod 状态也将一直保持 Terminating，kubelet 报错: Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.922965 14109 remote_runtime.go:250] RemoveContainer \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\" from runtime service failed: rpc error: code = Unknown desc = failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \"overlay2\" failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.923027 14109 kuberuntime_gc.go:126] Failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": rpc error: code = Unknown desc = failed to remove container \"19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\": Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \"overlay2\" failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted 通过 man chattr 查看 “i” 文件属性描述: A file with the 'i' attribute cannot be modified: it cannot be deleted or renamed, no link can be created to this file and no data can be written to the file. Only the superuser or a process possessing the CAP_LINUX_IMMUTABLE capability can set or clear this attribute. 彻底解决当然是不要在容器镜像中或启动后的容器设置 “i” 文件属性，临时恢复方法： 复制 kubelet 日志报错提示的文件路径，然后执行 chattr -i : chattr -i /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash 执行完后等待 kubelet 自动重试，Pod 就可以被自动删除了。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"docker 17 的 bug docker hang 住，没有任何响应，看 event: Warning FailedSync 3m (x408 over 1h) kubelet, 10.179.80.31 error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded 怀疑是17版本dockerd的BUG。可通过 kubectl -n cn-staging delete pod apigateway-6dc48bf8b6-clcwk –force –grace-period=0 强制删除pod，但 docker ps 仍看得到这个容器 处置建议： 升级到docker 18. 该版本使用了新的 containerd，针对很多bug进行了修复。 如果出现terminating状态的话，可以提供让容器专家进行排查，不建议直接强行删除，会可能导致一些业务上问题。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"存在 Finalizers k8s 资源的 metadata 里如果存在 finalizers，那么该资源一般是由某程序创建的，并且在其创建的资源的 metadata 里的 finalizers 加了一个它的标识，这意味着这个资源被删除时需要由创建资源的程序来做删除前的清理，清理完了它需要将标识从该资源的 finalizers 中移除，然后才会最终彻底删除资源。比如 Rancher 创建的一些资源就会写入 finalizers 标识。 处理建议：kubectl edit 手动编辑资源定义，删掉 finalizers，这时再看下资源，就会发现已经删掉了。通过prometheus-operator 创建prometheus时，最后无法删除namespace 也是此原因。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:5:4","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 一直处于 Unknown 状态 通常是节点失联，没有上报状态给 apiserver，到达阀值后 controller-manager 认为节点失联并将其状态置为 Unknown。 可能原因: 节点高负载导致无法上报 节点宕机 节点被关机 网络不通 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:6:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 健康检查失败 Kubernetes 健康检查包含就绪检查(readinessProbe)和存活检查(livenessProbe) pod 如果就绪检查失败会将此 pod ip 从 service 中摘除，通过 service 访问，流量将不会被转发给就绪检查失败的 pod pod 如果存活检查失败，kubelet 将会杀死容器并尝试重启 健康检查失败的可能原因有多种，除了业务程序BUG导致不能响应健康检查导致 unhealthy，还能有有其它原因，下面我们来逐个排查。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"健康检查配置不合理 initialDelaySeconds 太短，容器启动慢，导致容器还没完全启动就开始探测，如果 successThreshold 是默认值 1，检查失败一次就会被 kill，然后 pod 一直这样被 kill 重启。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"节点负载高 cpu 占用高（比如跑满）会导致进程无法正常发包收包，通常会 timeout，导致 kubelet 认为 pod 不健康。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"容器内进程端口监听挂掉 使用 netstat -tunlp 检查端口监听是否还在，如果不在了，抓包可以看到会直接 reset 掉健康检查探测的连接: 20:15:17.890996 IP 172.16.2.1.38074 \u003e 172.16.2.23.8888: Flags [S], seq 96880261, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.891021 IP 172.16.2.23.8888 \u003e 172.16.2.1.38074: Flags [R.], seq 0, ack 96880262, win 0, length 0 20:15:17.906744 IP 10.0.0.16.54132 \u003e 172.16.2.23.8888: Flags [S], seq 1207014342, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.906766 IP 172.16.2.23.8888 \u003e 10.0.0.16.54132: Flags [R.], seq 0, ack 1207014343, win 0, length 0 连接异常，从而健康检查失败。发生这种情况的原因可能在一个节点上启动了多个使用 hostNetwork 监听相同宿主机端口的 Pod，只会有一个 Pod 监听成功，但监听失败的 Pod 的业务逻辑允许了监听失败，并没有退出，Pod 又配了健康检查，kubelet 就会给 Pod 发送健康检查探测报文，但 Pod 由于没有监听所以就会健康检查失败。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:7:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"Pod 处于 CrashLoopBackOff 状态 Pod 如果处于 CrashLoopBackOff 状态说明之前是启动了，只是又异常退出了，应用实例状态为CrashLoopBackOff， 表现为实例不断重启，由ready状态变为Complete再变成CrashLoopBackOff。 一般由于应用实例容器异常退出导致的实例异常，需要排查应用日志确定异常退出原因。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:0","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"容器进程主动退出 如果是容器进程主动退出，退出状态码一般在 0-128 之间，除了可能是业务程序 BUG，还有其它许多可能原因 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:1","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"系统OOM 如果发生系统 OOM，可以看到 Pod 中容器退出状态码是 137，表示被 SIGKILL 信号杀死，同时内核会报错: Out of memory: Kill process …。大概率是节点上部署了其它非 K8S 管理的进程消耗了比较多的内存，或者 kubelet 的 –kube-reserved 和 –system-reserved 配的比较小，没有预留足够的空间给其它非容器进程，节点上所有 Pod 的实际内存占用总量不会超过 /sys/fs/cgroup/memory/kubepods 这里 cgroup 的限制，这个限制等于 capacity - “kube-reserved” - “system-reserved”，如果预留空间设置合理，节点上其它非容器进程（kubelet, dockerd, kube-proxy, sshd 等) 内存占用没有超过 kubelet 配置的预留空间是不会发生系统 OOM 的，可以根据实际需求做合理的调整。 ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:2","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"cgroup OOM 如果是 cgroup OOM 杀掉的进程，从 Pod 事件的下 Reason 可以看到是 OOMKilled，说明容器实际占用的内存超过 limit 了，同时内核日志会报: ``。 可以根据需求调整下 limit ","date":"2021-07-28","objectID":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/:8:3","tags":["Kubernetes排障"],"title":"Kubernetes Pod 排障指南","uri":"/kubernetes-pod%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"},{"categories":["Kubernetes"],"content":"背景 通过 kubeadm 安装k8s集群报错 操作系统环境信息 $ cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"18.04.5 LTS (Bionic Beaver)\" ID=ubuntu ID_LIKE=debian PRETTY_NAME=\"Ubuntu 18.04.5 LTS\" VERSION_ID=\"18.04\" HOME_URL=\"https://www.ubuntu.com/\" SUPPORT_URL=\"https://help.ubuntu.com/\" BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\" PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" VERSION_CODENAME=bionic UBUNTU_CODENAME=bionic kubeadm init 安装报错信息 [kubelet-check] It seems like the kubelet isn't running or healthy. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get \"http://localhost:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - 'systemctl status kubelet' - 'journalctl -xeu kubelet' Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - 'docker ps -a | grep kube | grep -v pause' Once you have found the failing container, you can inspect its logs with: - 'docker logs CONTAINERID' ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:1:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"排查思路 查看官网介绍为 docker 和 kubelet 服务中的 cgroup 驱动不一致，有两种方法 方式一：驱动向 docker 看齐 方式二：驱动为向 kubelet 看齐 如果docker 不方便重启则统一向 kubelet看齐，并重启对应的服务即可 ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:2:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"解决方式 ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"docker 配置文件 这里采取的是方式二，docker 默认驱动为 cgroupfs ,只需要添加 \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], 修改后配置文件 $ cat /etc/docker/daemon.json { \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], \"bip\":\"172.12.0.1/24\", \"registry-mirrors\": [ \"http://docker-registry-mirror.kodekloud.com\" ] } 重启docker systemctl restart docker ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:1","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"kublete 配置文件 grep 截取一下,可以看得出来kubelet默认 cgoup 驱动为systemd $ cat /var/lib/kubelet/config.yaml |grep group cgroupDriver: systemd 重启kubelet （optional） systemctl restart kubelet ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:3:2","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":["Kubernetes"],"content":"参考 配置cgroup驱动 Docker中的Cgroup Driver:Cgroupfs 与 Systemd 为什么要修改docker的cgroup driver ","date":"2021-05-28","objectID":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/:4:0","tags":["Kubernetes排障"],"title":"Kubeadm 安装k8s集群报错提示 kubelet 未运行","uri":"/kubeadm%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%E6%8F%90%E7%A4%BAkubelet%E6%9C%AA%E8%BF%90%E8%A1%8C/"},{"categories":null,"content":"友联 test ","date":"0001-01-01","objectID":"/friends/:0:0","tags":null,"title":"友链墙","uri":"/friends/"}]